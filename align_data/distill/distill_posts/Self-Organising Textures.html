<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><script src="Self-Organising%20Textures_files/template.js"></script><style>body {transition: opacity ease-in 0.2s; } 
body[unresolved] {opacity: 0; display: block; overflow: hidden; position: relative; } 
</style><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><script async="" src="Self-Organising%20Textures_files/analytics.js"></script><script>
window.addEventListener('WebComponentsReady', function() {
  console.warn('WebComponentsReady');
  const loaderTag = document.createElement('script');
  loaderTag.src = 'https://distill.pub/template.v2.js';
  document.head.insertBefore(loaderTag, document.head.firstChild);
});
</script><script src="Self-Organising%20Textures_files/webcomponents-loader.js"></script><script src="Self-Organising%20Textures_files/webcomponents-hi.js"></script>
  
  
  <style id="distill-prerendered-styles" type="text/css">/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

html {
  font-size: 14px;
	line-height: 1.6em;
  /* font-family: "Libre Franklin", "Helvetica Neue", sans-serif; */
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  /*, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";*/
  text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}

@media(min-width: 768px) {
  html {
    font-size: 16px;
  }
}

body {
  margin: 0;
}

a {
  color: #004276;
}

figure {
  margin: 0;
}

table {
	border-collapse: collapse;
	border-spacing: 0;
}

table th {
	text-align: left;
}

table thead {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

table thead th {
  padding-bottom: 0.5em;
}

table tbody :first-child td {
  padding-top: 0.5em;
}

pre {
  overflow: auto;
  max-width: 100%;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}

sup, sub {
  vertical-align: baseline;
  position: relative;
  top: -0.4em;
  line-height: 1em;
}

sub {
  top: 0.4em;
}

.kicker,
.marker {
  font-size: 15px;
  font-weight: 600;
  color: rgba(0, 0, 0, 0.5);
}


/* Headline */

@media(min-width: 1024px) {
  d-title h1 span {
    display: block;
  }
}

/* Figure */

figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

figcaption+figure {

}

figure img {
  width: 100%;
}

figure svg text,
figure svg tspan {
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@supports not (display: grid) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    display: block;
    padding: 8px;
  }
}

.base-grid,
distill-header,
d-title,
d-abstract,
d-article,
d-appendix,
distill-appendix,
d-byline,
d-footnote-list,
d-citation-list,
distill-footer {
  display: grid;
  justify-items: stretch;
  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
  grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}




.base-grid {
  grid-column: screen;
}

/* .l-body,
d-article > *  {
  grid-column: text;
}

.l-page,
d-title > *,
d-figure {
  grid-column: page;
} */

.l-gutter {
  grid-column: gutter;
}

.l-text,
.l-body {
  grid-column: text;
}

.l-page {
  grid-column: page;
}

.l-body-outset {
  grid-column: middle;
}

.l-page-outset {
  grid-column: page;
}

.l-screen {
  grid-column: screen;
}

.l-screen-inset {
  grid-column: screen;
  padding-left: 16px;
  padding-left: 16px;
}


/* Aside */

d-article aside {
  grid-column: gutter;
  font-size: 12px;
  line-height: 1.6em;
  color: rgba(0, 0, 0, 0.6)
}

@media(min-width: 768px) {
  aside {
    grid-column: gutter;
  }

  .side {
    grid-column: gutter;
  }
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-title {
  padding: 2rem 0 1.5rem;
  contain: layout style;
  overflow-x: hidden;
}

@media(min-width: 768px) {
  d-title {
    padding: 4rem 0 1.5rem;
  }
}

d-title h1 {
  grid-column: text;
  font-size: 40px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

@media(min-width: 768px) {
  d-title h1 {
    font-size: 50px;
  }
}

d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  grid-column: text;
}

d-title .status {
  margin-top: 0px;
  font-size: 12px;
  color: #009688;
  opacity: 0.8;
  grid-column: kicker;
}

d-title .status span {
  line-height: 1;
  display: inline-block;
  padding: 6px 0;
  border-bottom: 1px solid #80cbc4;
  font-size: 11px;
  text-transform: uppercase;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}


d-byline .byline {
  grid-template-columns: 1fr 1fr;
  grid-column: text;
}

@media(min-width: 768px) {
  d-byline .byline {
    grid-template-columns: 1fr 1fr 1fr 1fr;
  }
}

d-byline .authors-affiliations {
  grid-column-end: span 2;
  grid-template-columns: 1fr 1fr;
  margin-bottom: 1em;
}

@media(min-width: 768px) {
  d-byline .authors-affiliations {
    margin-bottom: 0;
  }
}

d-byline h3 {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  margin: 0;
  text-transform: uppercase;
}

d-byline p {
  margin: 0;
}

d-byline a,
d-article d-byline a {
  color: rgba(0, 0, 0, 0.8);
  text-decoration: none;
  border-bottom: none;
}

d-article d-byline a:hover {
  text-decoration: underline;
  border-bottom: none;
}

d-byline p.author {
  font-weight: 500;
}

d-byline .affiliations {

}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-article {
  contain: layout style;
  overflow-x: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  padding-top: 2rem;
  color: rgba(0, 0, 0, 0.8);
}

d-article > * {
  grid-column: text;
}

@media(min-width: 768px) {
  d-article {
    font-size: 16px;
  }
}

@media(min-width: 1024px) {
  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
}


/* H2 */


d-article .marker {
  text-decoration: none;
  border: none;
  counter-reset: section;
  grid-column: kicker;
  line-height: 1.7em;
}

d-article .marker:hover {
  border: none;
}

d-article .marker span {
  padding: 0 3px 4px;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  position: relative;
  top: 4px;
}

d-article .marker:hover span {
  color: rgba(0, 0, 0, 0.7);
  border-bottom: 1px solid rgba(0, 0, 0, 0.7);
}

d-article h2 {
  font-weight: 600;
  font-size: 24px;
  line-height: 1.25em;
  margin: 2rem 0 1.5rem 0;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding-bottom: 1rem;
}

@media(min-width: 1024px) {
  d-article h2 {
    font-size: 36px;
  }
}

/* H3 */

d-article h3 {
  font-weight: 700;
  font-size: 18px;
  line-height: 1.4em;
  margin-bottom: 1em;
  margin-top: 2em;
}

@media(min-width: 1024px) {
  d-article h3 {
    font-size: 20px;
  }
}

/* H4 */

d-article h4 {
  font-weight: 600;
  text-transform: uppercase;
  font-size: 14px;
  line-height: 1.4em;
}

d-article a {
  color: inherit;
}

d-article p,
d-article ul,
d-article ol,
d-article blockquote {
  margin-top: 0;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
}

d-article blockquote {
  border-left: 2px solid rgba(0, 0, 0, 0.2);
  padding-left: 2em;
  font-style: italic;
  color: rgba(0, 0, 0, 0.6);
}

d-article a {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  text-decoration: none;
}

d-article a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.8);
}

d-article .link {
  text-decoration: underline;
  cursor: pointer;
}

d-article ul,
d-article ol {
  padding-left: 24px;
}

d-article li {
  margin-bottom: 1em;
  margin-left: 0;
  padding-left: 0;
}

d-article li:last-child {
  margin-bottom: 0;
}

d-article pre {
  font-size: 14px;
  margin-bottom: 20px;
}

d-article hr {
  grid-column: screen;
  width: 100%;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article section {
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article span.equation-mimic {
  font-family: georgia;
  font-size: 115%;
  font-style: italic;
}

d-article > d-code,
d-article section > d-code  {
  display: block;
}

d-article > d-math[block],
d-article section > d-math[block]  {
  display: block;
}

@media (max-width: 768px) {
  d-article > d-code,
  d-article section > d-code,
  d-article > d-math[block],
  d-article section > d-math[block] {
      overflow-x: scroll;
      -ms-overflow-style: none;  // IE 10+
      overflow: -moz-scrollbars-none;  // Firefox
  }

  d-article > d-code::-webkit-scrollbar,
  d-article section > d-code::-webkit-scrollbar,
  d-article > d-math[block]::-webkit-scrollbar,
  d-article section > d-math[block]::-webkit-scrollbar {
    display: none;  // Safari and Chrome
  }
}

d-article .citation {
  color: #668;
  cursor: pointer;
}

d-include {
  width: auto;
  display: block;
}

d-figure {
  contain: layout style;
}

/* KaTeX */

.katex, .katex-prerendered {
  contain: style;
  display: inline-block;
}

/* Tables */

d-article table {
  border-collapse: collapse;
  margin-bottom: 1.5rem;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table th {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table td {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

d-article table tr:last-of-type td {
  border-bottom: none;
}

d-article table th,
d-article table td {
  font-size: 15px;
  padding: 2px 8px;
}

d-article table tbody :first-child td {
  padding-top: 2px;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

span.katex-display {
  text-align: left;
  padding: 8px 0 8px 0;
  margin: 0.5em 0 0.5em 1em;
}

span.katex {
  -webkit-font-smoothing: antialiased;
  color: rgba(0, 0, 0, 0.8);
  font-size: 1.18em;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@media print {

  @page {
    size: 8in 11in;
    @bottom-right {
      content: counter(page) " of " counter(pages);
    }
  }

  html {
    /* no general margins -- CSS Grid takes care of those */
  }

  p, code {
    page-break-inside: avoid;
  }

  h2, h3 {
    page-break-after: avoid;
  }

  d-header {
    visibility: hidden;
  }

  d-footer {
    display: none!important;
  }

}
</style>
  <!-- <script src="/template.v2.js"></script> -->
  <style>
  </style>
  <script src="Self-Organising%20Textures_files/twgl.js"></script>
  <script type="module" src="Self-Organising%20Textures_files/ca.js"></script>
  <script type="module" src="Self-Organising%20Textures_files/demo.js"></script>
<link rel="stylesheet" href="Self-Organising%20Textures_files/katex.css" crossorigin="anonymous">
    
    <link rel="icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=">
    <link href="https://distill.pub/rss.xml" rel="alternate" type="application/rss+xml" title="Articles from Distill">
  
    <title>Self-Organising Textures</title>
    
    <link rel="canonical" href="https://distill.pub/selforg/2021/textures">
    
    <!--  https://schema.org/Article -->
    <meta property="description" itemprop="description" content="Neural Cellular Automata learn to generate textures, exhibiting surprising properties.">
    <meta property="article:published" itemprop="datePublished" content="2021-02-11">
    <meta property="article:created" itemprop="dateCreated" content="2021-02-11">
    
    <meta property="article:modified" itemprop="dateModified" content="2021-05-07T17:13:43.000Z">
    
    <meta property="article:author" content="Eyvind Niklasson">
    <meta property="article:author" content="Alexander Mordvintsev">
    <meta property="article:author" content="Ettore Randazzo">
    <meta property="article:author" content="Michael Levin">
    <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Self-Organising Textures">
    <meta property="og:description" content="Neural Cellular Automata learn to generate textures, exhibiting surprising properties.">
    <meta property="og:url" content="https://distill.pub/selforg/2021/textures">
    <meta property="og:image" content="https://distill.pub/selforg/2021/textures/thumbnail.jpg">
    <meta property="og:locale" content="en_US">
    <meta property="og:site_name" content="Distill">
  
    <!--  https://dev.twitter.com/cards/types/summary -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Self-Organising Textures">
    <meta name="twitter:description" content="Neural Cellular Automata learn to generate textures, exhibiting surprising properties.">
    <meta name="twitter:url" content="https://distill.pub/selforg/2021/textures">
    <meta name="twitter:image" content="https://distill.pub/selforg/2021/textures/thumbnail.jpg">
    <meta name="twitter:image:width" content="560">
    <meta name="twitter:image:height" content="295">
  
      <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
    <meta name="citation_title" content="Self-Organising Textures">
    <meta name="citation_fulltext_html_url" content="https://distill.pub/selforg/2021/textures">
    <meta name="citation_volume" content="6">
    <meta name="citation_issue" content="2">
    <meta name="citation_firstpage" content="e00027.003">
    <meta name="citation_doi" content="10.23915/distill.00027.003">
    <meta name="citation_journal_title" content="Distill">
    <meta name="citation_journal_abbrev" content="Distill">
    <meta name="citation_issn" content="2476-0757">
    <meta name="citation_fulltext_world_readable" content="">
    <meta name="citation_online_date" content="2021/02/11">
    <meta name="citation_publication_date" content="2021/02/11">
    <meta name="citation_author" content="Niklasson, Eyvind">
    <meta name="citation_author_institution" content="Google">
    <meta name="citation_author" content="Mordvintsev, Alexander">
    <meta name="citation_author_institution" content="Google">
    <meta name="citation_author" content="Randazzo, Ettore">
    <meta name="citation_author_institution" content="Google">
    <meta name="citation_author" content="Levin, Michael">
    <meta name="citation_author_institution" content="Tufts">
    <meta name="citation_reference" content="citation_title=Growing Neural Cellular Automata;citation_author=Alexander Mordvintsev;citation_author=Ettore Randazzo;citation_author=Eyvind Niklasson;citation_author=Michael Levin;citation_publication_date=2020;citation_journal_title=Distill;citation_volume=5;citation_number=2;">
    <meta name="citation_reference" content="citation_title=Image segmentation via Cellular Automata;citation_author=Mark Sandler;citation_author=Andrey Zhmoginov;citation_author=Liangcheng Luo;citation_author=Alexander Mordvintsev;citation_author=Ettore Randazzo;citation_author=Blaise Agúera y. Arcas;citation_publication_date=2020;citation_arxiv_id=2008.04965;">
    <meta name="citation_reference" content="citation_title=Self-classifying MNIST Digits;citation_author=Ettore Randazzo;citation_author=Alexander Mordvintsev;citation_author=Eyvind Niklasson;citation_author=Michael Levin;citation_author=Sam Greydanus;citation_publication_date=2020;citation_journal_title=Distill;citation_volume=5;citation_number=8;">
    <meta name="citation_reference" content="citation_title=Differentiable Image Parameterizations;citation_author=Alexander Mordvintsev;citation_author=Nicola Pezzotti;citation_author=Ludwig Schubert;citation_author=Chris Olah;citation_publication_date=2018;citation_journal_title=Distill;citation_volume=3;citation_number=7;">
    <meta name="citation_reference" content="citation_title=The chemical basis of morphogenesis;citation_author=Alan Mathison Turing;citation_publication_date=1952;citation_journal_title=Philosophical transactions of the Royal Society of London. Series B, Biological sciences;citation_volume=237;citation_number=641;">
    <meta name="citation_reference" content="citation_title=Turing patterns in development: what about the horse part?;citation_author=Luciano Marcon;citation_author=James Sharpe;citation_publication_date=2012;citation_journal_title=Current opinion in genetics &amp;amp; development;citation_volume=22;citation_number=6;">
    <meta name="citation_reference" content="citation_title=A unified design space of synthetic stripe-forming networks;citation_author=Yolanda Schaerli;citation_author=Andreea Munteanu;citation_author=Magüi Gili;citation_author=James Cotterell;citation_author=James Sharpe;citation_author=Mark Isalan;citation_publication_date=2014;citation_journal_title=Nature communications;citation_volume=5;">
    <meta name="citation_reference" content="citation_title=On the Formation of Digits and Joints during Limb Development;citation_author=Tom W. Hiscock;citation_author=Patrick Tschopp;citation_author=Clifford J. Tabin;citation_publication_date=2017;citation_journal_title=Developmental cell;citation_volume=41;citation_number=5;">
    <meta name="citation_reference" content="citation_title=Modeling digits. Digit patterning is controlled by a Bmp-Sox9-Wnt Turing network modulated by morphogen gradients;citation_author=J. Raspopovic;citation_author=L. Marcon;citation_author=L. Russo;citation_author=J. Sharpe;citation_publication_date=2014;citation_journal_title=Science;citation_volume=345;citation_number=6196;">
    <meta name="citation_reference" content="citation_title=Pattern formation mechanisms of self-organizing reaction-diffusion systems;citation_author=Amit N. Landge;citation_author=Benjamin M. Jordan;citation_author=Xavier Diego;citation_author=Patrick Müller;citation_publication_date=2020;citation_journal_title=Developmental biology;citation_volume=460;citation_number=1;">
    <meta name="citation_reference" content="citation_title=Bioelectric gene and reaction networks: computational modelling of genetic, biochemical and bioelectrical dynamics in pattern regulation;citation_author=Alexis Pietak;citation_author=Michael Levin;citation_publication_date=2017;citation_journal_title=Journal of the Royal Society, Interface / the Royal Society;citation_volume=14;citation_number=134;">
    <meta name="citation_reference" content="citation_title=Turing-like patterns can arise from purely bioelectric mechanisms;citation_author=Micah Brodsky;citation_journal_title=Draft;">
    <meta name="citation_reference" content="citation_title=Dissipative structures in biological systems: bistability, oscillations, spatial patterns and waves;citation_author=Albert Goldbeter;citation_publication_date=2018;citation_journal_title=Philosophical transactions. Series A, Mathematical, physical, and engineering sciences;citation_volume=376;citation_number=2124;">
    <meta name="citation_reference" content="citation_title=Gene networks and liar paradoxes;citation_author=Mark Isalan;citation_publication_date=2009;citation_journal_title=BioEssays: news and reviews in molecular, cellular and developmental biology;citation_volume=31;citation_number=10;">
    <meta name="citation_reference" content="citation_title=Texture Synthesis Using Convolutional Neural Networks;citation_author=Leon A. Gatys;citation_author=Alexander S. Ecker;citation_author=Matthias Bethge;citation_publication_date=2015;citation_arxiv_id=1505.07376;">
    <meta name="citation_reference" content="citation_title=The chemical basis of morphogenesis. 1953;citation_author=A. M. Turing;citation_publication_date=1990;citation_journal_title=Bulletin of mathematical biology;citation_volume=52;citation_number=1-2;">
    <meta name="citation_reference" content="citation_title=Pattern formation by interacting chemical fronts;citation_author=K. J. Lee;citation_author=W. D. McCormick;citation_author=Q. Ouyang;citation_author=H. L. Swinney;citation_publication_date=1993;citation_journal_title=Science;citation_volume=261;citation_number=5118;">
    <meta name="citation_reference" content="citation_title=Complex patterns in a simple system;citation_author=J. E. Pearson;citation_publication_date=1993;citation_journal_title=Science;citation_volume=261;citation_number=5118;">
    <meta name="citation_reference" content="citation_title=Very Deep Convolutional Networks for Large-Scale Image Recognition;citation_author=Karen Simonyan;citation_author=Andrew Zisserman;citation_publication_date=2014;citation_arxiv_id=1409.1556;">
    <meta name="citation_reference" content="citation_title=Adam: A Method for Stochastic Optimization;citation_author=Diederik P. Kingma;citation_author=Jimmy Ba;citation_publication_date=2014;citation_arxiv_id=1412.6980;">
    <meta name="citation_reference" content="citation_title=Describing Textures in the Wild;citation_author=Mircea Cimpoi;citation_author=Subhransu Maji;citation_author=Iasonas Kokkinos;citation_author=Sammy Mohamed;citation_author=Andrea Vedaldi;citation_publication_date=2013;citation_arxiv_id=1311.3618;">
    <meta name="citation_reference" content="citation_title=The texture lexicon: Understanding the categorization of visual texture terms and their relationship to texture images;citation_author=Nalini Bhushan;citation_author=A. Ravishankar Rao;citation_author=Gerald L. Lohse;citation_publication_date=1997;citation_journal_title=Cognitive science;citation_volume=21;citation_number=2;">
    <meta name="citation_reference" content="citation_title=Re-membering the body: applications of computational neuroscience to the top-down control of regeneration of limbs and other complex organs;citation_author=G. Pezzulo;citation_author=M. Levin;citation_publication_date=2015;citation_journal_title=Integrative biology: quantitative biosciences from nano to macro;citation_volume=7;citation_number=12;">
    <meta name="citation_reference" content="citation_title=Embryonic Development and Induction;citation_author=Hans Speman;citation_publication_date=1938;citation_journal_title=The American Journal of the Medical Sciences;citation_volume=196;citation_number=5;">
    <meta name="citation_reference" content="citation_title=Communication, Memory, and Development;citation_author=Stephen Grossberg;citation_publication_date=1978;">
    <meta name="citation_reference" content="citation_title=WaveFunctionCollapse;citation_author=Maxim Gumin;">
    <meta name="citation_reference" content="citation_title=Texture Networks: Feed-forward Synthesis of Textures and Stylized Images;citation_author=Dmitry Ulyanov;citation_author=Vadim Lebedev;citation_author=Andrea Vedaldi;citation_author=Victor Lempitsky;citation_publication_date=2016;citation_arxiv_id=1603.03417;">
    <meta name="citation_reference" content="citation_title=TextureGAN: Controlling deep image synthesis with texture patches;citation_author=Wenqi Xian;citation_author=Patsorn Sangkloy;citation_author=Varun Agrawal;citation_author=Amit Raj;citation_author=Jingwan Lu;citation_author=Chen Fang;citation_author=Fisher Yu;citation_author=James Hays;citation_publication_date=2018;">
    <meta name="citation_reference" content="citation_title=Interactive evolution of camouflage;citation_author=Craig Reynolds;citation_publication_date=2011;citation_journal_title=Artificial life;citation_volume=17;citation_number=2;">
    <meta name="citation_reference" content="citation_title=A parametric texture model based on joint statistics of complex wavelet coefficients;citation_author=Javier Portilla;citation_author=Eero P. Simoncelli;citation_publication_date=2000;">
    <meta name="citation_reference" content="citation_title=Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration;citation_author=Yunjin Chen;citation_author=Thomas Pock;citation_publication_date=2017;citation_journal_title=IEEE transactions on pattern analysis and machine intelligence;citation_volume=39;citation_number=6;">
    <meta name="citation_reference" content="citation_title=The evolutionary significance of butterfly eyespots;citation_author=Ullasa Kodandaramaiah;citation_publication_date=2011;citation_journal_title=Behavioral ecology: official journal of the International Society for Behavioral Ecology;citation_volume=22;citation_number=6;">
    <meta name="citation_reference" content="citation_title=Live Cell Imaging of Butterfly Pupal and Larval Wings In Vivo;citation_author=Yoshikazu Ohno;citation_author=Joji M. Otaki;citation_publication_date=2015;citation_journal_title=PloS one;citation_volume=10;citation_number=6;">
    <meta name="citation_reference" content="citation_title=Focusing on butterfly eyespot focus: uncoupling of white spots from eyespot bodies in nymphalid butterflies;citation_author=Masaki Iwata;citation_author=Joji M. Otaki;citation_publication_date=2016;citation_journal_title=SpringerPlus;citation_volume=5;citation_number=1;">
    <meta name="citation_reference" content="citation_title=OpenAI Microscope;citation_author=Ludwig Schubert;citation_author=Michael Petrov;citation_author=Shan Carter;citation_author=Nick Cammarata;citation_author=Gabriel Goh;citation_author=Chris Olah;citation_publication_date=2020;">
    <meta name="citation_reference" content="citation_title=The neural origins of shell structure and pattern in aquatic mollusks;citation_author=Alistair Boettiger;citation_author=Bard Ermentrout;citation_author=George Oster;citation_publication_date=2009;citation_journal_title=Proceedings of the National Academy of Sciences of the United States of America;citation_volume=106;citation_number=16;">
    <meta name="citation_reference" content="citation_title=Emergent complexity in simple neural systems;citation_author=Alistair N. Boettiger;citation_author=George Oster;citation_publication_date=2009;citation_journal_title=Communicative &amp;amp; integrative biology;citation_volume=2;citation_number=6;">
    <meta name="citation_reference" content="citation_title=Going deeper with convolutions;citation_author=Christian Szegedy;citation_author=Wei Liu;citation_author=Yangqing Jia;citation_author=Pierre Sermanet;citation_author=Scott Reed;citation_author=Dragomir Anguelov;citation_author=Dumitru Erhan;citation_author=Vincent Vanhoucke;citation_author=Andrew Rabinovich;citation_publication_date=2015;citation_arxiv_id=1409.4842;">
    <meta name="citation_reference" content="citation_title=Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses;citation_author=Eric Risser;citation_author=Pierre Wilmot;citation_author=Connelly Barnes;citation_publication_date=2017;citation_arxiv_id=1701.08893;">
    <meta name="citation_reference" content="citation_title=Stem cell migration and mechanotransduction on linear stiffness gradient hydrogels;citation_author=William J. Hadden;citation_author=Jennifer L. Young;citation_author=Andrew W. Holle;citation_author=Meg L. McFetridge;citation_author=Du Yong Kim;citation_author=Philip Wijesinghe;citation_author=Hermes Taylor-Weiner;citation_author=Jessica H. Wen;citation_author=Andrew R. Lee;citation_author=Karen Bieback;citation_author=et al.;citation_publication_date=2017;citation_journal_title=Proceedings of the National Academy of Sciences of the United States of America;citation_volume=114;citation_number=22;">
<style type="text/css">.dg ul{list-style:none;margin:0;padding:0;width:100%;clear:both}.dg.ac{position:fixed;top:0;left:0;right:0;height:0;z-index:0}.dg:not(.ac) .main{overflow:hidden}.dg.main{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear}.dg.main.taller-than-window{overflow-y:auto}.dg.main.taller-than-window .close-button{opacity:1;margin-top:-1px;border-top:1px solid #2c2c2c}.dg.main ul.closed .close-button{opacity:1 !important}.dg.main:hover .close-button,.dg.main .close-button.drag{opacity:1}.dg.main .close-button{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear;border:0;line-height:19px;height:20px;cursor:pointer;text-align:center;background-color:#000}.dg.main .close-button.close-top{position:relative}.dg.main .close-button.close-bottom{position:absolute}.dg.main .close-button:hover{background-color:#111}.dg.a{float:right;margin-right:15px;overflow-y:visible}.dg.a.has-save>ul.close-top{margin-top:0}.dg.a.has-save>ul.close-bottom{margin-top:27px}.dg.a.has-save>ul.closed{margin-top:0}.dg.a .save-row{top:0;z-index:1002}.dg.a .save-row.close-top{position:relative}.dg.a .save-row.close-bottom{position:fixed}.dg li{-webkit-transition:height .1s ease-out;-o-transition:height .1s ease-out;-moz-transition:height .1s ease-out;transition:height .1s ease-out;-webkit-transition:overflow .1s linear;-o-transition:overflow .1s linear;-moz-transition:overflow .1s linear;transition:overflow .1s linear}.dg li:not(.folder){cursor:auto;height:27px;line-height:27px;padding:0 4px 0 5px}.dg li.folder{padding:0;border-left:4px solid rgba(0,0,0,0)}.dg li.title{cursor:pointer;margin-left:-4px}.dg .closed li:not(.title),.dg .closed ul li,.dg .closed ul li>*{height:0;overflow:hidden;border:0}.dg .cr{clear:both;padding-left:3px;height:27px;overflow:hidden}.dg .property-name{cursor:default;float:left;clear:left;width:40%;overflow:hidden;text-overflow:ellipsis}.dg .c{float:left;width:60%;position:relative}.dg .c input[type=text]{border:0;margin-top:4px;padding:3px;width:100%;float:right}.dg .has-slider input[type=text]{width:30%;margin-left:0}.dg .slider{float:left;width:66%;margin-left:-5px;margin-right:0;height:19px;margin-top:4px}.dg .slider-fg{height:100%}.dg .c input[type=checkbox]{margin-top:7px}.dg .c select{margin-top:5px}.dg .cr.function,.dg .cr.function .property-name,.dg .cr.function *,.dg .cr.boolean,.dg .cr.boolean *{cursor:pointer}.dg .cr.color{overflow:visible}.dg .selector{display:none;position:absolute;margin-left:-9px;margin-top:23px;z-index:10}.dg .c:hover .selector,.dg .selector.drag{display:block}.dg li.save-row{padding:0}.dg li.save-row .button{display:inline-block;padding:0px 6px}.dg.dialogue{background-color:#222;width:460px;padding:15px;font-size:13px;line-height:15px}#dg-new-constructor{padding:10px;color:#222;font-family:Monaco, monospace;font-size:10px;border:0;resize:none;box-shadow:inset 1px 1px 1px #888;word-wrap:break-word;margin:12px 0;display:block;width:440px;overflow-y:scroll;height:100px;position:relative}#dg-local-explain{display:none;font-size:11px;line-height:17px;border-radius:3px;background-color:#333;padding:8px;margin-top:10px}#dg-local-explain code{font-size:10px}#dat-gui-save-locally{display:none}.dg{color:#eee;font:11px 'Lucida Grande', sans-serif;text-shadow:0 -1px 0 #111}.dg.main::-webkit-scrollbar{width:5px;background:#1a1a1a}.dg.main::-webkit-scrollbar-corner{height:0;display:none}.dg.main::-webkit-scrollbar-thumb{border-radius:5px;background:#676767}.dg li:not(.folder){background:#1a1a1a;border-bottom:1px solid #2c2c2c}.dg li.save-row{line-height:25px;background:#dad5cb;border:0}.dg li.save-row select{margin-left:5px;width:108px}.dg li.save-row .button{margin-left:5px;margin-top:1px;border-radius:2px;font-size:9px;line-height:7px;padding:4px 4px 5px 4px;background:#c5bdad;color:#fff;text-shadow:0 1px 0 #b0a58f;box-shadow:0 -1px 0 #b0a58f;cursor:pointer}.dg li.save-row .button.gears{background:#c5bdad url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAANCAYAAAB/9ZQ7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAQJJREFUeNpiYKAU/P//PwGIC/ApCABiBSAW+I8AClAcgKxQ4T9hoMAEUrxx2QSGN6+egDX+/vWT4e7N82AMYoPAx/evwWoYoSYbACX2s7KxCxzcsezDh3evFoDEBYTEEqycggWAzA9AuUSQQgeYPa9fPv6/YWm/Acx5IPb7ty/fw+QZblw67vDs8R0YHyQhgObx+yAJkBqmG5dPPDh1aPOGR/eugW0G4vlIoTIfyFcA+QekhhHJhPdQxbiAIguMBTQZrPD7108M6roWYDFQiIAAv6Aow/1bFwXgis+f2LUAynwoIaNcz8XNx3Dl7MEJUDGQpx9gtQ8YCueB+D26OECAAQDadt7e46D42QAAAABJRU5ErkJggg==) 2px 1px no-repeat;height:7px;width:8px}.dg li.save-row .button:hover{background-color:#bab19e;box-shadow:0 -1px 0 #b0a58f}.dg li.folder{border-bottom:0}.dg li.title{padding-left:16px;background:#000 url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlI+hKgFxoCgAOw==) 6px 10px no-repeat;cursor:pointer;border-bottom:1px solid rgba(255,255,255,0.2)}.dg .closed li.title{background-image:url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlGIWqMCbWAEAOw==)}.dg .cr.boolean{border-left:3px solid #806787}.dg .cr.color{border-left:3px solid}.dg .cr.function{border-left:3px solid #e61d5f}.dg .cr.number{border-left:3px solid #2FA1D6}.dg .cr.number input[type=text]{color:#2FA1D6}.dg .cr.string{border-left:3px solid #1ed36f}.dg .cr.string input[type=text]{color:#1ed36f}.dg .cr.function:hover,.dg .cr.boolean:hover{background:#111}.dg .c input[type=text]{background:#303030;outline:none}.dg .c input[type=text]:hover{background:#3c3c3c}.dg .c input[type=text]:focus{background:#494949;color:#fff}.dg .c .slider{background:#303030;cursor:ew-resize}.dg .c .slider-fg{background:#2FA1D6;max-width:100%}.dg .c .slider:hover{background:#3c3c3c}.dg .c .slider:hover .slider-fg{background:#44abda}
</style><style type="text/css">.dg ul{list-style:none;margin:0;padding:0;width:100%;clear:both}.dg.ac{position:fixed;top:0;left:0;right:0;height:0;z-index:0}.dg:not(.ac) .main{overflow:hidden}.dg.main{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear}.dg.main.taller-than-window{overflow-y:auto}.dg.main.taller-than-window .close-button{opacity:1;margin-top:-1px;border-top:1px solid #2c2c2c}.dg.main ul.closed .close-button{opacity:1 !important}.dg.main:hover .close-button,.dg.main .close-button.drag{opacity:1}.dg.main .close-button{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear;border:0;line-height:19px;height:20px;cursor:pointer;text-align:center;background-color:#000}.dg.main .close-button.close-top{position:relative}.dg.main .close-button.close-bottom{position:absolute}.dg.main .close-button:hover{background-color:#111}.dg.a{float:right;margin-right:15px;overflow-y:visible}.dg.a.has-save>ul.close-top{margin-top:0}.dg.a.has-save>ul.close-bottom{margin-top:27px}.dg.a.has-save>ul.closed{margin-top:0}.dg.a .save-row{top:0;z-index:1002}.dg.a .save-row.close-top{position:relative}.dg.a .save-row.close-bottom{position:fixed}.dg li{-webkit-transition:height .1s ease-out;-o-transition:height .1s ease-out;-moz-transition:height .1s ease-out;transition:height .1s ease-out;-webkit-transition:overflow .1s linear;-o-transition:overflow .1s linear;-moz-transition:overflow .1s linear;transition:overflow .1s linear}.dg li:not(.folder){cursor:auto;height:27px;line-height:27px;padding:0 4px 0 5px}.dg li.folder{padding:0;border-left:4px solid rgba(0,0,0,0)}.dg li.title{cursor:pointer;margin-left:-4px}.dg .closed li:not(.title),.dg .closed ul li,.dg .closed ul li>*{height:0;overflow:hidden;border:0}.dg .cr{clear:both;padding-left:3px;height:27px;overflow:hidden}.dg .property-name{cursor:default;float:left;clear:left;width:40%;overflow:hidden;text-overflow:ellipsis}.dg .c{float:left;width:60%;position:relative}.dg .c input[type=text]{border:0;margin-top:4px;padding:3px;width:100%;float:right}.dg .has-slider input[type=text]{width:30%;margin-left:0}.dg .slider{float:left;width:66%;margin-left:-5px;margin-right:0;height:19px;margin-top:4px}.dg .slider-fg{height:100%}.dg .c input[type=checkbox]{margin-top:7px}.dg .c select{margin-top:5px}.dg .cr.function,.dg .cr.function .property-name,.dg .cr.function *,.dg .cr.boolean,.dg .cr.boolean *{cursor:pointer}.dg .cr.color{overflow:visible}.dg .selector{display:none;position:absolute;margin-left:-9px;margin-top:23px;z-index:10}.dg .c:hover .selector,.dg .selector.drag{display:block}.dg li.save-row{padding:0}.dg li.save-row .button{display:inline-block;padding:0px 6px}.dg.dialogue{background-color:#222;width:460px;padding:15px;font-size:13px;line-height:15px}#dg-new-constructor{padding:10px;color:#222;font-family:Monaco, monospace;font-size:10px;border:0;resize:none;box-shadow:inset 1px 1px 1px #888;word-wrap:break-word;margin:12px 0;display:block;width:440px;overflow-y:scroll;height:100px;position:relative}#dg-local-explain{display:none;font-size:11px;line-height:17px;border-radius:3px;background-color:#333;padding:8px;margin-top:10px}#dg-local-explain code{font-size:10px}#dat-gui-save-locally{display:none}.dg{color:#eee;font:11px 'Lucida Grande', sans-serif;text-shadow:0 -1px 0 #111}.dg.main::-webkit-scrollbar{width:5px;background:#1a1a1a}.dg.main::-webkit-scrollbar-corner{height:0;display:none}.dg.main::-webkit-scrollbar-thumb{border-radius:5px;background:#676767}.dg li:not(.folder){background:#1a1a1a;border-bottom:1px solid #2c2c2c}.dg li.save-row{line-height:25px;background:#dad5cb;border:0}.dg li.save-row select{margin-left:5px;width:108px}.dg li.save-row .button{margin-left:5px;margin-top:1px;border-radius:2px;font-size:9px;line-height:7px;padding:4px 4px 5px 4px;background:#c5bdad;color:#fff;text-shadow:0 1px 0 #b0a58f;box-shadow:0 -1px 0 #b0a58f;cursor:pointer}.dg li.save-row .button.gears{background:#c5bdad url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAANCAYAAAB/9ZQ7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAQJJREFUeNpiYKAU/P//PwGIC/ApCABiBSAW+I8AClAcgKxQ4T9hoMAEUrxx2QSGN6+egDX+/vWT4e7N82AMYoPAx/evwWoYoSYbACX2s7KxCxzcsezDh3evFoDEBYTEEqycggWAzA9AuUSQQgeYPa9fPv6/YWm/Acx5IPb7ty/fw+QZblw67vDs8R0YHyQhgObx+yAJkBqmG5dPPDh1aPOGR/eugW0G4vlIoTIfyFcA+QekhhHJhPdQxbiAIguMBTQZrPD7108M6roWYDFQiIAAv6Aow/1bFwXgis+f2LUAynwoIaNcz8XNx3Dl7MEJUDGQpx9gtQ8YCueB+D26OECAAQDadt7e46D42QAAAABJRU5ErkJggg==) 2px 1px no-repeat;height:7px;width:8px}.dg li.save-row .button:hover{background-color:#bab19e;box-shadow:0 -1px 0 #b0a58f}.dg li.folder{border-bottom:0}.dg li.title{padding-left:16px;background:#000 url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlI+hKgFxoCgAOw==) 6px 10px no-repeat;cursor:pointer;border-bottom:1px solid rgba(255,255,255,0.2)}.dg .closed li.title{background-image:url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlGIWqMCbWAEAOw==)}.dg .cr.boolean{border-left:3px solid #806787}.dg .cr.color{border-left:3px solid}.dg .cr.function{border-left:3px solid #e61d5f}.dg .cr.number{border-left:3px solid #2FA1D6}.dg .cr.number input[type=text]{color:#2FA1D6}.dg .cr.string{border-left:3px solid #1ed36f}.dg .cr.string input[type=text]{color:#1ed36f}.dg .cr.function:hover,.dg .cr.boolean:hover{background:#111}.dg .c input[type=text]{background:#303030;outline:none}.dg .c input[type=text]:hover{background:#3c3c3c}.dg .c input[type=text]:focus{background:#494949;color:#fff}.dg .c .slider{background:#303030;cursor:ew-resize}.dg .c .slider-fg{background:#2FA1D6;max-width:100%}.dg .c .slider:hover{background:#3c3c3c}.dg .c .slider:hover .slider-fg{background:#44abda}
</style></head>

<body distill-prerendered="" data-new-gr-c-s-check-loaded="8.899.0" data-gr-ext-installed="" class="vsc-initialized"><distill-header distill-prerendered="">
<style>
distill-header {
  position: relative;
  height: 60px;
  background-color: hsl(200, 60%, 15%);
  width: 100%;
  box-sizing: border-box;
  z-index: 2;
  color: rgba(0, 0, 0, 0.8);
  border-bottom: 1px solid rgba(0, 0, 0, 0.08);
  box-shadow: 0 1px 6px rgba(0, 0, 0, 0.05);
}
distill-header .content {
  height: 70px;
  grid-column: page;
}
distill-header a {
  font-size: 16px;
  height: 60px;
  line-height: 60px;
  text-decoration: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 22px 0;
}
distill-header a:hover {
  color: rgba(255, 255, 255, 1);
}
distill-header svg {
  width: 24px;
  position: relative;
  top: 4px;
  margin-right: 2px;
}
@media(min-width: 1080px) {
  distill-header {
    height: 70px;
  }
  distill-header a {
    height: 70px;
    line-height: 70px;
    padding: 28px 0;
  }
  distill-header .logo {
  }
}
distill-header svg path {
  fill: none;
  stroke: rgba(255, 255, 255, 0.8);
  stroke-width: 3px;
}
distill-header .logo {
  font-size: 17px;
  font-weight: 200;
}
distill-header .nav {
  float: right;
  font-weight: 300;
}
distill-header .nav a {
  font-size: 12px;
  margin-left: 24px;
  text-transform: uppercase;
}
</style>
<div class="content">
  <a href="https://distill.pub/" class="logo">
    <svg viewBox="-607 419 64 64">
  <path d="M-573.4,478.9c-8,0-14.6-6.4-14.6-14.5s14.6-25.9,14.6-40.8c0,14.9,14.6,32.8,14.6,40.8S-565.4,478.9-573.4,478.9z"></path>
</svg>

    Distill
  </a>
  <nav class="nav">
    <a href="https://distill.pub/about/">About</a>
    <a href="https://distill.pub/prize/">Prize</a>
    <a href="https://distill.pub/journal/">Submit</a>
  </nav>
</div>
</distill-header>

  <d-front-matter>
    <script type="text/json">{
      "title": "Self-Organising Textures",
      "description": "Neural Cellular Automata learn to generate textures, exhibiting surprising properties.",
      "authors": [
        {
          "author": "Eyvind Niklasson",
          "authorURL": "https://eyvind.me/",
          "affiliation": "Google",
          "affiliationURL": "https://ai.google/"
        },
        {
          "author": "Alexander Mordvintsev",
          "authorURL": "https://znah.net/",
          "affiliation": "Google",
          "affiliationURL": "https://ai.google/"
        },
        {
          "author": "Ettore Randazzo",
          "authorURL": "",
          "affiliation": "Google",
          "affiliationURL": "https://ai.google/"
       },
       {
          "author": "Michael Levin",
          "authorURL": "https://ase.tufts.edu/biology/labs/levin/",
          "affiliation": "Tufts",
          "affiliationURL": "https://tufts.edu/"
	}
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>

  </d-front-matter>

  <style>
   /* ****************************************
    * Thread Info
    ******************************************/

    .thread-info {
      background-color: hsl(54, 78%, 96%);
      border-left: solid hsl(54, 33%, 67%) 1px;
      padding: 1em;
      color: hsla(0, 0%, 0%, 0.67);
    }

    #thread-nav {
      margin-top: 20;
      margin-bottom: 1.5rem;
      display: grid;
      grid-template-columns: 45px 2fr 3fr;
      grid-template-areas:
        'thread-icon explanation explanation '
        'thread-icon prev next';
      grid-column-gap: 1.5em;
    }

    @media (min-width: 768px) {
      #thread-nav {
        grid-template-columns: 65px 3fr 2fr;
      }
    }

    #thread-nav .thread-icon {
      grid-area: thread-icon;
      padding: 0.5em;
      justify-self: center;
    }

    #thread-nav .explanation {
      grid-area: explanation;
      font-size: 85%;
      color: hsl(0, 0%, 0.33);
    }

    #thread-nav .prev {
      grid-area: prev;
    }

    #thread-nav .prev::before {
      content: '← Previous Article';
    }

    #thread-nav .overview {
      scroll-behavior: smooth;
    }

    #thread-nav .overview::before {
      content: '↑';
      white-space: nowrap;
      margin-right: 0.5em;
    }

    #thread-nav .next {
      grid-area: next;
      scroll-behavior: smooth;
    }

    #thread-nav .next::before {
      content: 'Next Article →';
    }

    #thread-nav .next::before,
    #thread-nav .prev::before {
      display: block;
      white-space: nowrap;
      padding: 0.5em 0;
      font-size: 80%;
      font-weight: bold;
      margin-top: 0px;
      margin-right: 0.5em;
      text-transform: uppercase;
    }

    #thread-nav .prev,
    #thread-nav .next,
    #thread-nav .overview {
      font-size: 80%;
      line-height: 1.5em;
      font-weight: 600;
      border-bottom: none;
      color: #2e6db7;
      /* margin-top: 0.25em; */
      letter-spacing: 0.25px;
    }

    figure {
      text-align: center;
      margin-bottom: 0.5em;
      margin-top: 0.5em;
    }
    figure img {
      max-width: 100%;
      width: unset;
    }
    video {
      max-width: 100%;
    }
    .colab-root {
      display: inline-block;
      background: rgba(255, 255, 255, 0.75);
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 11px!important;
      text-decoration: none;
      color: #aaa;
      border: none;
      font-weight: 300;
      border: solid 1px rgba(0, 0, 0, 0.08);
      border-bottom-color: rgba(0, 0, 0, 0.15);
      text-transform: uppercase;
      line-height: 16px;
    }

   span.colab-span {
      background-image: url(images/colab.svg);
      background-repeat: no-repeat;
      background-size: 20px;
      background-position-y: 2px;
      display: inline-block;
      padding-left: 24px;
      border-radius: 4px;
      text-decoration: none;
    }

    span.tf-span {
      background-image: url(images/tf.svg);
      background-repeat: no-repeat;
      background-size: 15px;
      background-position-y: 0px;
      display: inline-block;
      padding-left: 19px;
      border-radius: 4px;
      text-decoration: none;
    }

    span.pytorch-span {
      background-image: url(images/pytorch.svg);
      background-repeat: no-repeat;
      background-size: 83px;
      background-position-x: -32px;
      background-position-y: -1px;
      display: inline-block;
      padding-left: 19px;
      border-radius: 4px;
      text-decoration: none;
    }


    a.colab-root:hover{
      color: #666;
      background: white;
      border-color: rgba(0, 0, 0, 0.2);
    }

    /* TOC */
    @media(max-width: 1000px){
      d-contents {
        justify-self: start;
        align-self: start;
        grid-column-start: 2;
        grid-column-end: 6;
        padding-bottom: 0.5em;
        margin-bottom: 1em;
        padding-left: 0.25em;
        border-bottom: 1px solid rgba(0, 0, 0, 0.1);
        border-bottom-width: 1px;
        border-bottom-style: solid;
        border-bottom-color: rgba(0, 0, 0, 0.1);
      }
    } 
    
    @media (min-width: 1000px){
      d-contents {
        align-self: start;
        grid-column-start: 1;
        grid-column-end: 4;
        justify-self: end;
        padding-right: 3em;
        padding-left: 2em;
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    @media (min-width: 1180px){
      d-contents {
        grid-column-start: 1;
        grid-column-end: 4;
        justify-self: end;
        padding-right: 3em;
        padding-left: 2em;
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    d-contents nav h3 {
      margin-top: 0;
      margin-bottom: 1em;
    }

    d-contents nav a {
      color: rgba(0, 0, 0, 0.8);
      border-bottom: none;
      text-decoration: none;
    }

    d-contents li {
      list-style-type: none;
    }

    d-contents ul {
      padding-left: 1em;
    }
    
    d-contents nav ul li {
      margin-bottom: .25em;
    }

    d-contents nav a:hover {
      text-decoration: underline solid rgba(0, 0, 0, 0.6);
    }

    d-contents nav ul {
      margin-top: 0;
      margin-bottom: 6px;
    }


    d-contents nav>div {
      display: block;
      outline: none;
      margin-bottom: 0.5em;
    }

    d-contents nav>div>a {
      font-size: 13px;
      font-weight: 600;
    }

    d-contents nav>div>a:hover,
    d-contents nav>ul>li>a:hover {
        text-decoration: none;
    }

    /* code blocks to margins */
    @media (min-width: 1600px) {
      d-code {
        margin-top: -10px;
        grid-column-start: 12;
        grid-column-end: 14; 
      }
    }
    /* so title is on one line */
    d-title h1, d-title p {
      grid-column: middle;
    }

    /*remove h4 header uppercase (present in distill template)*/
    d-article h4 {
      text-transform:none;
    }

    /* so the headings in the appendix are on one line in narrow screens */
    @media(max-width: 1000px) {
      d-appendix h3 {
        grid-column: text !important; 
      } 
    }

  </style>
  <script>
  // hack to edit font size in code snippets. guaranteed a better way to do 
  // this, but I'm not a webdev
  window.onload = function() {
    setTimeout(() => { document.querySelectorAll("d-code").forEach(function(e) {e.shadowRoot.querySelector('#code-container').style.fontSize = "0.7em"}); }, 3000);
  }
  </script>
  <script>
    //Autoplay videos when they're in view
  </script>
  <d-title>
    <h1>Self-Organising Textures</h1>
    <p>Neural Cellular Automata Model of Pattern Formation</p>

  
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
    <symbol id="playIcon" viewBox="0 0 24 24"><path d="M8 5v14l11-7z"></path><path d="M0 0h24v24H0z" fill="none"></path></symbol>
    <symbol id="pauseIcon" viewBox="0 0 24 24"><path d="M6 19h4V5H6v14zm8-14v14h4V5h-4z"></path><path d="M0 0h24v24H0z" fill="none"></path></symbol>
    <symbol id="resetIcon" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 5V1L7 6l5 5V7c3.31 0 6 2.69 6 6s-2.69 6-6 6-6-2.69-6-6H4c0 4.42 3.58 8 8 8s8-3.58 8-8-3.58-8-8-8z"></path></symbol>
    <symbol id="zoomInIcon" viewBox="0 0 24 24"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2v1z"></path></symbol>
    <symbol id="zoomOutIcon" viewBox="0 0 24 24"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14zM7 9h5v1H7z"></path></symbol>
    <symbol id="mouse" viewBox="0 0 100 100"><path d="M32,41v18c0,9.9,8.1,18,18,18c9.9,0,18-8.1,18-18V41c0-9.9-8.1-18-18-18C40.1,23,32,31.1,32,41z M50,27c7.7,0,14,6.3,14,14  v18c0,7.7-6.3,14-14,14s-14-6.3-14-14V41C36,33.3,42.3,27,50,27z"></path><path d="M50,44c1.1,0,2-0.9,2-2v-6c0-1.1-0.9-2-2-2s-2,0.9-2,2v6C48,43.1,48.9,44,50,44z"></path><path d="M48.6,92.4C49,92.8,49.5,93,50,93s1-0.2,1.4-0.6l5-5c0.8-0.8,0.8-2,0-2.8s-2-0.8-2.8,0L50,88.2l-3.6-3.6  c-0.8-0.8-2-0.8-2.8,0c-0.8,0.8-0.8,2,0,2.8L48.6,92.4z"></path><path d="M48.6,7.6l-5,5c-0.8,0.8-0.8,2,0,2.8C44,15.8,44.5,16,45,16s1-0.2,1.4-0.6l3.6-3.6l3.6,3.6C54,15.8,54.5,16,55,16  s1-0.2,1.4-0.6c0.8-0.8,0.8-2,0-2.8l-5-5C50.6,6.8,49.4,6.8,48.6,7.6z"></path></symbol>
</svg>

<style>
#demo {
    font-size: 14px;
    user-select: none;
    grid-template-columns: auto;
    grid-template-rows: auto auto;
    grid-auto-flow: column;
    row-gap: 10px;
}

.hint a {
  color: inherit;
}

@media (min-width: 1180px) {
  #demo {
    grid-template-columns: 512px 1fr;
    grid-template-rows: auto;
  }
  #pattern-controls {
    grid-row: 1;
  }
}

#demo-canvas {
    border: 1px solid lightgrey;
    image-rendering: pixelated;
    touch-action: none;
    width: 100%;
}

#pattern-controls {
    display: grid;
    grid-template-columns: 1fr;
    grid-template-rows: min-content minmax(0, 0.3fr) min-content minmax(0, 0.3fr) minmax(0, 0.32fr) minmax(0, 0.1fr);
    /*row-gap: 20px;*/
    overflow: hidden;
}

@media (max-width: 1180px) {
  #pattern-controls {
    grid-template-rows: min-content minmax(0, 0.4fr) min-content minmax(0, 0.4fr) min-content minmax(0, 0.1fr);
  }
}


.pattern-selector::-webkit-scrollbar {
    display: none;
}

#demo-tip{
    display: grid;
    grid-template-columns: 40px auto;
    align-items: center;
    column-gap: 10px;
    margin-bottom: 20px;
}
#pointer {
    width: 40px;
}
#status {
    font-size: 12px;
    color: rgba(0, 0, 0, 0.6);
    font-family: monospace;
}
#model-hints {
    color: rgba(0, 0, 0, 0.6);
    grid-column: 1/3;
}
#model-hints span {
    display: none;
}
.hint {
    color: rgba(0, 0, 0, 0.6);
    line-height: 1.4em;
    user-select: text;
}

input[type=range] {
  -webkit-appearance: none; /* Hides the slider so that custom slider can be made */
  width: 95%; /* Specific width is required for Firefox. */
  background: transparent; /* Otherwise white in Chrome */
  margin-bottom: 8px;
}

.hint a {
  font-size: 90%;
}

@media (max-width: 350px) {
  .hint a {
    font-size: 75%;
  }
}

input[type=range]::-webkit-slider-thumb {
  -webkit-appearance: none;
}

input[type=range]:focus {
  outline: none; /* Removes the blue border. You should probably do some kind of focus styling for accessibility reasons though. */
}

input[type=range]::-ms-track {
  width: 100%;
  cursor: pointer;

  /* Hides the slider so custom styles can be added */
  background: transparent;
  border-color: transparent;
  color: transparent;
}

/* Thumb */

/* Special styling for WebKit/Blink */
input[type=range]::-webkit-slider-thumb {
  -webkit-appearance: none;
  height: 14px;
  width: 14px;
  border-radius: 50%;
  background: steelblue;
  cursor: pointer;
  margin-top: -6px; /* You need to specify a margin in Chrome, but in Firefox and IE it is automatic */
}

/* All the same stuff for Firefox */
input[type=range]::-moz-range-thumb {
  height: 14px;
  width: 14px;
  border-radius: 50%;
  background: steelblue;
  cursor: pointer;
  border: none;
}

/* All the same stuff for IE */
input[type=range]::-ms-thumb {
  height: 14px;
  width: 14px;
  border-radius: 50%;
  background: grey;
  cursor: pointer;
}

/* Track */

input[type=range]::-webkit-slider-runnable-track {
  width: 100%;
  height: 3px;
  cursor: pointer;
  background: rgba(0, 0, 0, 0.1);
  border-radius: 2px;
  border: none;
}

input[type=range]:focus::-webkit-slider-runnable-track {
  background: rgba(0, 0, 0, 0.15);
}

input[type=range]::-moz-range-track {
  width: 100%;
  height: 3px;
  cursor: pointer;
  background: rgba(0, 0, 0, 0.1);
  border-radius: 2px;
  border: none;
}

input[type=range]::-ms-track {
  width: 100%;
  height: 3px;
  cursor: pointer;
  background: rgba(0, 0, 0, 0.1);
  border-radius: 2px;
  border: none;
}
input[type=range]::-ms-fill-lower {
  background: rgba(0, 0, 0, 0.1);
}
input[type=range]:focus::-ms-fill-lower {
  background: rgba(0, 0, 0, 0.1);
}
input[type=range]::-ms-fill-upper {
  background: rgba(0, 0, 0, 0.1);
}
input[type=range]:focus::-ms-fill-upper {
  background: rgba(0, 0, 0, 0.1);
}

input[type="radio"] {
    background-color: steelblue;
}

#colab-hero-div { 
  /*grid-column: 1/3;*/
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-top-width: 1px;
  border-top-style: solid;
  border-top-color: rgba(0, 0, 0, 0.1);
  padding-top: 15px;
  text-align: center;
}

#colab-hero {
  margin: auto;
  /*display: block;*/
  text-align: center;
  /*width: 200px;*/
  height: 16px;
}

.pattern-selector {
    grid-column: 1/3;
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(64px, 1fr));
    justify-items: center;
    overflow-x: hidden;
    scroll-snap-type: x mandatory;
    overscroll-behavior-y: contain;
    padding-top: 5px;
}

/*.pattern-selector > :last-child {*/
    /*margin-bottom: 100%;*/
/*}*/

.pattern-selector-title{
  grid-column: 1/3;
  text-align: center;
  font-weight: bold;
  /*padding-bottom: 3%;*/
  /*padding-top: 3px;*/
}

#inception_selector {
  padding-top: 3%;
}

.overlaygrad {
  z-index: 1;
  pointer-events: none;
  height: 100%;
  background: linear-gradient(to bottom, rgb(255,255,255) 0%, rgba(255,255,255,0.0) 10%, rgba(255,255,255,0.0) 90%, rgb(255,255,255) 100%);
}

.overlayicon {
  z-index: 1;
  pointer-events: none;
  height: 100%;
  background: url(images/mouse.svg) rgba(255, 255, 255, 0.4);
  background-size: contain;
  background-position: center;
  background-repeat: no-repeat;
  opacity: 1.0;
  transition: opacity 1.0s ease-out;
}

#origtex {
  margin: auto;
  margin-top: 10px;
  height: 128px;
  width: 128px;
}

#texhint{
  height: 170px;
  grid-column: 1/3;
  margin-top: 10px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-top-width: 1px;
  border-top-style: solid;
  border-top-color: rgba(0, 0, 0, 0.1);
  text-align: center;
  line-height: 2em;
}

.whitespace {
  grid-column: 1/-1;
  height: 5px;
  width: 1px;
}

/* PHONES */
@media (max-width: 500px) {
  .whitespace {
    grid-column: auto;
    height: 1px;
    width: 1px;
    /* Also a hack - indends the point at which scroll starts... */
    margin-right: 55px;
  }
  #pattern-controls {
    grid-template-rows: min-content 64px min-content 64px 0.25fr 0.1fr;
  }
  .pattern-selector {
    grid-template-columns: repeat(100, minmax(64px, 1fr));
    grid-template-rows: auto;
    overflow-x: scroll;
    overflow-y: hidden;
    padding-top: 0%;
    padding-left: 2%;
    overscroll-behavior-y: auto;
  }
  .overlaygrad {
    z-index: 1;
    pointer-events: none;
    height: 100%;
    background: linear-gradient(to right, rgb(255,255,255) 0%, rgba(255,255,255,0.0) 5%, rgba(255,255,255,0.0) 95%, rgb(255,255,255) 100%);
  }

  .overlayicon {
    z-index: 1;
    pointer-events: none;
    height: 100%;
    background: url(images/touch.svg) rgba(255, 255, 255, 0.4);
    background-size: 55px;
    background-position: center;
    background-repeat: no-repeat;
    opacity: 1.0;
    transition: opacity 1.0s ease-out;
  }

  .pattern-selector-title {
    padding-bottom: 0%;
  }
  #texhint {
    height: 135px;
  }
  #origtex {
    height: 96px;
    width: 96px;
  }
}

.pattern-selector * {
    cursor: pointer;
}

.texture-square {
  /*background-image: url('textures/banded.png');*/
  /*background-position:center;
  background-repeat:no-repeat;
  background-size:cover;
  */
  /* some weird kludge to allow same width as height */
  --border-width: 5px;
  border-style: solid;
  box-sizing: border-box;
  border-width: var(--border-width);
  border-color: white;
  width: 100%;
  height: 0;
  padding-top: calc(100% - 2*var(--border-width));
  scroll-snap-align: center;
}

.dtd-overlay, #dtd{
  grid-column: 1;
  grid-row: 2;
}

.inception-overlay, #inception{
  grid-column: 1;
  grid-row: 4;
}

.demo-controls {
  display: grid;
  grid-template-columns: max-content 1fr max-content;
  grid-template-rows: min-content min-content;
  gap: 0px 5px;
  text-align: center;
  line-height: 1.4em;

}

.icon {
    width: 30px; height: 30px;
    background: steelblue;
    fill: white;
    border-radius: 20px;
    padding: 5px;
    margin: 2px;
    cursor: pointer;
}

.disabled {
    background: grey;
    cursor: default;
}

/* radio button groups */

.button-group {
  border-radius: 4px;
  padding: 4px;
  background: #eee;
}
.button-group input {
  display: none;
}
.button-group img {
  cursor: pointer;
  border: 2px solid white;
}
.button-group input:checked + img{
  border: 2px solid goldenrod;
}


</style>

<!-- 
<view id="alignRegular" viewBox="0 0 480 480"/>
<view id="alignPolar" viewBox="480 0 480 480"/>
<view id="alignDipole" viewBox="960 0 480 480"/>
<view id="gridSquare" viewBox="1440 0 480 480"/>
<view id="gridHex" viewBox="1920 0 480 480"/>
<view id="rotation" viewBox="2400 0 480 480"/>
-->

<div class="l-body-outset grid" id="demo">

  <div>
    <canvas id="demo-canvas" width="1536" height="1536"></canvas>

    <div class="demo-controls">
      <div class="play-reset" style="text-align: left;">
        <span id="play-pause">
          <svg class="icon" id="play" style="display: none;"><use xlink:href="#playIcon"></use></svg>
          <svg class="icon" id="pause" style="display: inline;"><use xlink:href="#pauseIcon"></use></svg>
        </span>
        <svg class="icon" id="reset"><use xlink:href="#resetIcon"></use></svg>
      </div>
      <div class="speed">
        <input type="range" id="speed" min="-3" max="3" step="1" value="0"><br>Speed: <label id="speedLabel">1x</label>
      </div>
      <div style="text-align: right;">
        <svg class="icon" id="zoomIn"><use xlink:href="#zoomInIcon"></use></svg>
        <svg class="icon disabled" id="zoomOut"><use xlink:href="#zoomOutIcon"></use></svg>
      </div>
      <div id="alignSelect" class="button-group">
        <label>
          <input type="radio" checked="checked" name="align"><img src="Self-Organising%20Textures_files/icons_003.svg">
        </label>
        <label>
          <input type="radio" name="align"><img src="Self-Organising%20Textures_files/icons_005.svg">
        </label>
        <label>
          <input type="radio" name="align"><img src="Self-Organising%20Textures_files/icons.svg">
        </label>
        <br>Cell alignment
      </div>
      <div>
        <input type="range" id="rotation" min="0" max="360" step="1" value="0"><br>Rotation: <label id="rotationLabel">0 deg</label><br>
      </div>
      <div id="gridSelect" class="button-group">
        <label>
          <input type="radio" checked="checked" name="grid"><img src="Self-Organising%20Textures_files/icons_004.svg">
        </label>
        <label>
          <input type="radio" name="grid" id="gridHex"><img src="Self-Organising%20Textures_files/icons_002.svg">
        </label>
        <br>Grid type
      </div>
    </div>
  </div>


    <!-- <div id="status">
      
          Step <span id="stepCount"></span>
          (<span id="ips"></span> step/s)
    </div> -->


  <div id="pattern-controls">
    <div class="pattern-selector-title">
      <span>Textures</span>
    </div>
    <div class="dtd-overlay overlaygrad">
    </div>
    <div class="dtd-overlay overlayicon">
    </div>
    <div id="dtd" class="pattern-selector"><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 28.5714% / 900% 800%; border-color: rgb(245, 140, 44);" id="interlaced_0172" class="texture-square"></div>
      <!-- a hacky way to add some padding, so the fadeout doesn't cover items in the scroll. -->
      <div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 0% / 900% 800%;" id="bubbly_0101" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 0% / 900% 800%;" id="dotted_0201" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 0% / 900% 800%;" id="interlaced_0081" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 0% / 900% 800%;" id="honeycombed_0171" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 0% / 900% 800%;" id="honeycombed_0061" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 0% / 900% 800%;" id="crosshatched_0121" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 0% / 900% 800%;" id="bumpy_0081" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 0% / 900% 800%;" id="cobwebbed_0141" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 0% / 900% 800%;" id="chequered_0121" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 14.2857% / 900% 800%;" id="chequered_0051" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 14.2857% / 900% 800%;" id="swirly_0071" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 14.2857% / 900% 800%;" id="veined_0141" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 14.2857% / 900% 800%;" id="woven_0121" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 14.2857% / 900% 800%;" id="banded_0037" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 14.2857% / 900% 800%;" id="bubbly_0117" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 14.2857% / 900% 800%;" id="bumpy_0169" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 14.2857% / 900% 800%;" id="chequered_0050" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 14.2857% / 900% 800%;" id="chequered_0088" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 28.5714% / 900% 800%;" id="cobwebbed_0059" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 28.5714% / 900% 800%;" id="cracked_0085" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 28.5714% / 900% 800%;" id="cracked_0122" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 28.5714% / 900% 800%;" id="grid_0002" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 28.5714% / 900% 800%;" id="grid_0040" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 28.5714% / 900% 800%;" id="grid_0049" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 28.5714% / 900% 800%;" id="interlaced_0163" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 28.5714% / 900% 800%;" id="polka-dotted_0121" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 42.8571% / 900% 800%;" id="spiralled_0040" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 42.8571% / 900% 800%;" id="spiralled_0112" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 42.8571% / 900% 800%;" id="spiralled_0124" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 42.8571% / 900% 800%;" id="veined_0106" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 42.8571% / 900% 800%;" id="fibrous_0145" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 42.8571% / 900% 800%;" id="chequered_0212" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 42.8571% / 900% 800%;" id="striped_0005" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 42.8571% / 900% 800%;" id="interlaced_0191" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 42.8571% / 900% 800%;" id="grid_0135" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 57.1429% / 900% 800%;" id="spiralled_0042" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 57.1429% / 900% 800%;" id="swirly_0005" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 57.1429% / 900% 800%;" id="mondrian" class="texture-square"></div><div class="whitespace"></div>
    </div>
    <div class="pattern-selector-title" id="inception_selector">
      <span>Inception</span>
    </div>
    <div class="inception-overlay overlaygrad">
    </div>
    <div class="inception-overlay overlayicon">
    </div>
    <div id="inception" class="pattern-selector">
      <div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 57.1429% / 900% 800%;" id="mixed4c_242" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 57.1429% / 900% 800%;" id="mixed4c_52" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 57.1429% / 900% 800%;" id="mixed4c_439" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 57.1429% / 900% 800%;" id="mixed4c_438" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 57.1429% / 900% 800%;" id="mixed4c_397" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 57.1429% / 900% 800%;" id="mixed4c_412" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 71.4286% / 900% 800%;" id="mixed4c_364" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 71.4286% / 900% 800%;" id="mixed4c_21" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 71.4286% / 900% 800%;" id="mixed4c_208" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 71.4286% / 900% 800%;" id="mixed4d_42" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 71.4286% / 900% 800%;" id="mixed4d_473" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 71.4286% / 900% 800%;" id="mixed4d_474" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 71.4286% / 900% 800%;" id="mixed4d_485" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 71.4286% / 900% 800%;" id="mixed4b_8" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 71.4286% / 900% 800%;" id="mixed4b_98" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 85.7143% / 900% 800%;" id="mixed4b_70" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 85.7143% / 900% 800%;" id="mixed4b_507" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 85.7143% / 900% 800%;" id="mixed4b_492" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 37.5% 85.7143% / 900% 800%;" id="mixed4b_486" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 50% 85.7143% / 900% 800%;" id="mixed4b_488" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 62.5% 85.7143% / 900% 800%;" id="mixed4a_1" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 75% 85.7143% / 900% 800%;" id="mixed4a_461" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 87.5% 85.7143% / 900% 800%;" id="mixed4a_472" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 100% 85.7143% / 900% 800%;" id="mixed4a_475" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 0% 100% / 900% 800%;" id="mixed3b_454" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 12.5% 100% / 900% 800%;" id="mixed4d_117" class="texture-square"></div><div style="background: rgba(0, 0, 0, 0) url(&quot;demo/sprites.jpeg&quot;) repeat scroll 25% 100% / 900% 800%;" id="mixed4d_313" class="texture-square"></div><div class="whitespace"></div>
    </div>
    <div id="texhint">
      <div id="origtex" style="background: rgba(0, 0, 0, 0) url(&quot;demo/dtd_sprites.jpeg&quot;) repeat scroll 87.5% 28.5714% / 900% 800%;">
      </div>
      <span id="texhinttext"><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/">interlaced_0172 (DTD)</a></span>
    </div>

    <div id="colab-hero-div">
      <a href="https://colab.research.google.com/github/google-research/self-organising-systems/blob/master/notebooks/texture_nca_tf2.ipynb" class="colab-root" id="colab-hero">Try in a <span class="colab-span"><span class="tf-span">Notebook</span></span></a>
      <a href="https://colab.research.google.com/github/google-research/self-organising-systems/blob/master/notebooks/texture_nca_pytorch.ipynb" class="colab-root" id="colab-hero">Try in a <span class="colab-span"><span class="pytorch-span">Notebook</span></span></a>
    </div>

  </div>

</div>

<script src="Self-Organising%20Textures_files/twgl.js"></script>
<script src="Self-Organising%20Textures_files/dat.js"></script>
<script type="module">
    import { createDemo } from './demo.js'
    createDemo('demo');
</script>

</d-title>

<d-byline>
  <div class="byline grid">
    <div class="authors-affiliations grid">
      <h3>Authors</h3>
      <h3>Affiliations</h3>
      
        <p class="author">
          
            <a class="name" href="https://eyvind.me/">Eyvind Niklasson</a>
        </p>
        <p class="affiliation">
        <a class="affiliation" href="https://ai.google/">Google</a>
        </p>
      
        <p class="author">
          
            <a class="name" href="https://znah.net/">Alexander Mordvintsev</a>
        </p>
        <p class="affiliation">
        <a class="affiliation" href="https://ai.google/">Google</a>
        </p>
      
        <p class="author">
          
            <span class="name">Ettore Randazzo</span>
        </p>
        <p class="affiliation">
        <a class="affiliation" href="https://ai.google/">Google</a>
        </p>
      
        <p class="author">
          
            <a class="name" href="https://ase.tufts.edu/biology/labs/levin/">Michael Levin</a>
        </p>
        <p class="affiliation">
        <a class="affiliation" href="https://tufts.edu/">Tufts</a>
        </p>
      
    </div>
    <div>
      <h3>Published</h3>
      
        <p>Feb. 11, 2021</p> 
    </div>
    <div>
      <h3>DOI</h3>
      
        <p><a href="https://doi.org/10.23915/distill.00027.003">10.23915/distill.00027.003</a></p>
    </div>
  </div>
</d-byline>


<d-article>

<d-contents>
  <nav class="l-text toc figcaption">
    <h3>Contents</h3>
    <div><a href="#patterns-textures-and-physical-processes">Patterns, textures and physical processes</a></div>
    <ul>
      <li><a href="#from-turing-to-cellular-automata-to-neural-networks">From Turing, to Cellular Automata, to Neural Networks</a></li>
      <li><a href="#nca-as-pattern-generators">NCA as pattern generators</a></li> 
      <li><a href="#related-work">Related work</a></li> 
    </ul>
    <div><a href="#feature-visualization">Feature Visualization</a></div>
    <ul>
      <li><a href="#nca-with-inception">NCA with Inception</a></li>
    </ul>
    <div><a href="#other-interesting-findings">Other interesting findings</a></div>
    <ul>
      <li><a href="#robustness">Robustness</a></li>
      <li><a href="#hidden-states">Hidden States</a></li>
    </ul>
    <div><a href="#conclusion">Conclusion</a></div>
  </nav>
</d-contents>
<section id="thread-nav" class="thread-info" style="margin-top: 10px; margin-bottom: 40px">
  <img class="thread-icon" src="Self-Organising%20Textures_files/multiple-pages.svg" width="43px" height="50px">
  <p class="explanation">
    This article is part of the
    <a href="https://distill.pub/2020/selforg/">Differentiable Self-organizing Systems Thread</a>,
    an experimental format collecting invited short articles delving into
    differentiable self-organizing systems, interspersed with critical
    commentary from several experts in adjacent fields.
  </p>
  <a class="prev" href="https://distill.pub/2020/selforg/mnist/">Self-classifying MNIST Digits</a>
  <a class="next" href="https://distill.pub/selforg/2021/adversarial/">Adversarial Reprogramming of Neural Cellular Automata</a>
</section>

<p>Neural Cellular Automata (NCA<d-footnote id="d-footnote-1"> We use NCA to refer to both <i>Neural Cellular Automata </i>and <i>Neural Cellular Automaton</i>.</d-footnote>) are capable of learning a diverse set of behaviours: from generating stable, regenerating, static images  <d-cite key="Mordvintsev_Randazzo_Niklasson_Levin_2020"></d-cite>, to segmenting images  <d-cite key="Sandler_Zhmoginov_Luo_Mordvintsev_Randazzo_Arcas_2020"></d-cite>, to learning to “self-classify” shapes <d-cite key="Randazzo_Mordvintsev_Niklasson_Levin_Greydanus_2020"></d-cite>.
 The inductive bias imposed by using cellular automata is powerful. A 
system of individual agents running the same learned local rule can 
solve surprisingly complex tasks. Moreover, individual agents, or cells,
 can learn to coordinate their behavior even when separated by large 
distances. By construction, they solve these tasks in a massively 
parallel and inherently degenerate<d-footnote id="d-footnote-2"> Degenerate in this case refers to the <a href="https://en.wikipedia.org/wiki/Degeneracy_(biology)">biological concept of degeneracy</a>.</d-footnote>
 way. Each cell must be able to take on the role of any other cell - as a
 result they tend to generalize well to unseen situations.</p>

<p>In this work, we apply NCA to the task of texture synthesis. This 
task involves reproducing the general appearance of a texture template, 
as opposed to making pixel-perfect copies. We are going to focus on 
texture losses that allow for a degree of ambiguity. After training NCA 
models to reproduce textures, we subsequently investigate their learned 
behaviors and observe a few surprising effects. Starting from these 
investigations, we make the case that the cells learn distributed, 
local, algorithms. </p>

<p>To do this, we apply an old trick: we employ neural cellular automata as a differentiable image parameterization <d-cite key="Mordvintsev_Pezzotti_Schubert_Olah_2018"></d-cite>.</p>

<h2 id="patterns-textures-and-physical-processes">Patterns, textures and physical processes</h2>
<p></p>
<figure>
<img src="Self-Organising%20Textures_files/zebra.jpg" style="width: 350px">
<figcaption>A pair of Zebra. Zebra are said to have unique stripes.</figcaption>
</figure>

<p>Zebra stripes are an iconic texture. Ask almost anyone to identify 
zebra stripes in a set of images, and they will have no trouble doing 
so. Ask them to describe what zebra stripes look like, and they will 
gladly tell you that they are parallel stripes of slightly varying 
width, alternating in black and white. And yet, they may also tell you 
that no two zebra have the same set of stripes<d-footnote id="d-footnote-3">
 Perhaps an apocryphal claim, but at the very lowest level every zebra 
will be unique. Ourp point is - “zebra stripes” as a concept in human 
understanding refers to the general structure of a black and white 
striped pattern and not to a specific mapping from location to colour.</d-footnote>.
 This is because evolution has programmed the cells responsible for 
creating the zebra pattern to generate a pattern of a certain quality, 
with certain characteristics, as opposed to programming them with the 
blueprints for an exact bitmap of the edges and locations of stripes to 
be moulded to the surface of the zebra’s body.</p>

<p>Put another way, patterns and textures are ill-defined concepts. The 
Cambridge English Dictionary defines a pattern as “any regularly 
repeated arrangement, especially a design made from repeated lines, 
shapes, or colours on a surface”. This definition falls apart rather 
quickly when looking at patterns and textures that impart a feeling or 
quality, rather than a specific repeating property. A coloured fuzzy 
rug, for instance, can be considered a pattern or a texture, but is 
composed of strands pointing in random directions with small random 
variations in size and color, and there is no discernable regularity to 
the pattern. Penrose tilings do not repeat (they are not translationally
 invariant), but show them to anyone and they’ll describe them as a 
pattern or a texture. Most patterns in nature are outputs of locally 
interacting processes that may or may not be stochastic in nature, but 
are often based on fairly simple rules. There is a large body of work on
 models which give rise to such patterns in nature; most of it is 
inspired by Turing’s seminal paper on morphogenesis. <d-cite key="Turing_1952"></d-cite> </p>

<p>Such patterns are very common in developmental biology <d-cite key="Marcon_Sharpe_2012"></d-cite>.
 In addition to coat colors and skin pigmentation, invariant large-scale
 patterns, arising in spite of stochastic low-level dynamics, are a key 
feature of peripheral nerve networks, vascular networks, somites (blocks
 of tissue demarcated in embryogenesis that give rise to many organs), 
and segments of anatomical and genetic-level features, including whole 
body plans (e.g., snakes and centipedes) and appendages (such as 
demarcation of digit fields within the vertebrate limb<d-cite key="Schaerli_Munteanu_Gili_Cotterell_Sharpe_Isalan_2014"></d-cite><d-cite key="Hiscock_Tschopp_Tabin_2017"></d-cite><d-cite key="Raspopovic_Marcon_Russo_Sharpe_2014"></d-cite>).
 These kinds of patterns are generated by reaction-diffusion processes, 
bioelectric signaling, planar polarity, and other cell-to-cell 
communication mechanisms<d-cite key="Landge_Jordan_Diego_Müller_2020"></d-cite><d-cite key="Pietak_Levin_2017"></d-cite><d-cite key="Brodsky"></d-cite><d-cite key="Goldbeter_2018"></d-cite>.
 Patterns in biology are not only structural, but also physiological, as
 in the waves of electrical activity in the brain and the dynamics of 
gene regulatory networks.  These gene regulatory networks, for example, 
can support computation sufficiently sophisticated as to be subject to 
Liar paradoxes<d-footnote id="d-footnote-4"> See <a href="https://en.wikipedia.org/wiki/Liar_paradox">liar paradox</a>.
 In principle, gene regulatory networks can express paradoxical 
behaviour, such as that expression of factor A represses the expression 
of factor A. <d-cite key="Isalan_2009"></d-cite> One result of such a paradox can be that a certain factor will oscillate with time. </d-footnote>.
 Studying the emergence and control of such patterns can help us to 
understand not only their evolutionary origins, but also how they are 
recognized (either in the visual system of a second observer or in 
adjacent cells during regeneration) and how they can be modulated for 
the purposes of regenerative medicine.</p>

<p>As a result, when having any model learn to produce textures or 
patterns, we want it to learn a generative process for the pattern. We 
can think of such a process as a means of sampling from the distribution
 governing this pattern. The first hurdle is to choose an appropriate 
loss function, or qualitative measure of the pattern. To do so, we 
employ ideas from Gatys et. al <d-cite key="Gatys_Ecker_Bethge_2015"></d-cite>.
 NCA become the parametrization for an image which we “stylize” in the 
style of the target pattern. In this case, instead of restyling an 
existing image, we begin with a fully unconstrained setting: the output 
of an untrained, randomly initialized, NCA. The NCA serve as the 
“renderer” or “generator”, and a pre-trained differentiable model serves
 as a distinguisher of the patterns, providing the gradient necessary 
for the renderer to learn to produce a pattern of a certain style.</p>
<h3 id="from-turing-to-cellular-automata-to-neural-networks">From Turing, to Cellular Automata, to Neural Networks</h3>
<p>NCA are well suited for generating textures. To understand why, we’ll
 demonstrate parallels between texture generation in nature and NCA. 
Given these parallels, we argue that NCA are a good model class for 
texture generation.</p>

<h4 id="pdes">PDEs</h4>
<p>In “The Chemical Basis of Morphogenesis” <d-cite key="Turing_1990"></d-cite>,
 Alan Turing suggested that simple physical processes of reaction and 
diffusion, modelled by partial differential equations, lie behind 
pattern formation in nature, such as the aforementioned zebra stripes. 
Extensive work has since been done to identify PDEs modeling 
reaction-diffusion and evaluating their behaviour. One of the more 
celebrated examples is the Gray-Scott model of reaction diffusion (<d-cite key="Lee_McCormick_Ouyang_Swinney_1993"></d-cite>,<d-cite key="Pearson_1993"></d-cite>).
 This process has a veritable zoo of interesting behaviour, explorable 
by simply tuning the two parameters. We strongly encourage readers to 
visit this <a href="http://mrob.com/pub/comp/xmorphia/">interactive atlas</a>
 of the different regions of the Gray-Scott reaction diffusion model to 
get a sense for the extreme variety of behaviour hidden behind two 
simple knobs. The more adventurous can even <a href="https://groups.csail.mit.edu/mac/projects/amorphous/jsim/sim/GrayScott.html">play with a simulation locally</a> or <a href="https://mrob.com/pub/comp/xmorphia/ogl/index.html">in the browser</a>.</p>

<p>To tackle the problem of reproducing our textures, we propose a more 
general version of the above systems, described by a simple Partial 
Differential Equation (PDE) over the state space of an image. </p>

<figure>
<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mrow><mi mathvariant="bold">s</mi></mrow></mrow><mrow><mi mathvariant="normal">∂</mi><mi>t</mi></mrow></mfrac><mo>=</mo><mi>f</mi><mo>(</mo><mtext>s</mtext><mo separator="true">,</mo><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold">x</mi></msub><mtext>s</mtext><mo separator="true">,</mo><msubsup><mi mathvariant="normal">∇</mi><mi mathvariant="bold">x</mi><mn>2</mn></msubsup><mtext>s</mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{s} }{\partial  t } = f(\textbf{s}, \nabla_\mathbf{x} \textbf{s}, \nabla_\mathbf{x}^{2}\textbf{s})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8801079999999999em;"></span><span class="strut bottom" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="base"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathit mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathbf mtight">s</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord text"><span class="mord mathbf">s</span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.161108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord text"><span class="mord mathbf">s</span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">x</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"></span></span></span></span></span><span class="mord text"><span class="mord mathbf">s</span></span><span class="mclose">)</span></span></span></span></span>
</figure>

<p>Here, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.10764em;">f</span></span></span></span></span> is a function that depends on the gradient (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold">x</mi></msub><mtext>s</mtext></mrow><annotation encoding="application/x-tex">\nabla_\mathbf{x} \textbf{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.161108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord text"><span class="mord mathbf">s</span></span></span></span></span></span>) and Laplacian  (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="normal">∇</mi><mi mathvariant="bold">x</mi><mn>2</mn></msubsup><mtext>s</mtext></mrow><annotation encoding="application/x-tex">\nabla_\mathbf{x}^{2}\textbf{s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.061108em;vertical-align:-0.247em;"></span><span class="base"><span class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">x</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"></span></span></span></span></span><span class="mord text"><span class="mord mathbf">s</span></span></span></span></span></span>) of the state space and determines the time evolution of this state space. <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">s</span></span></span></span></span> represents a k dimensional vector, whose first three components correspond to the visible RGB color channels. </p>

<p>Intuitively, we have defined a system where every point of the image 
changes with time, in a way that depends on how the image currently 
changes across space, with respect to its immediate neighbourhood. 
Readers may start to recognize the resemblance between this and another 
system based on immediately local interactions.</p>
<h4 id="to-cas">To CAs</h4>

<p>Differential equations governing natural phenomena are usually 
evaluated using numerical differential equation solvers. Indeed, this is
 sometimes the <strong>only</strong> way to solve them, as many PDEs and
 ODEs of interest do not have closed form solutions. This is even the 
case for some deceptively simple ones, such as the <a href="https://en.wikipedia.org/wiki/Three-body_problem">three-body problem</a>.
 Numerically solving PDEs and ODEs is a vast and well-established field.
 One of the biggest hammers in the metaphorical toolkit for numerically 
evaluating differential equations is discretization: the process of 
converting the variables of the system from continuous space to a 
discrete space, where numerical integration is tractable. When using 
some ODEs to model a change in a phenomena over time, for example, it 
makes sense to advance through time in discrete steps, possibly of 
variable size. </p>

<p>We now show that numerically integrating the aforementioned PDE is 
equivalent to reframing the problem as a Neural Cellular Automata, with <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.10764em;">f</span></span></span></span></span> assuming the role of the NCA rule. </p>

<p>The logical approach to discretizing the space the PDE operates on is
 to discretize the continuous 2D image space into a 2D raster grid. 
Boundary conditions are of concern but we can address them by moving to a
 toroidal world where each dimension wraps around on itself. </p>

<p>Similarly to space, we choose to treat time in a discretized fashion 
and evaluate our NCA at fixed-sized time steps. This is equivalent to 
explicit Euler integration. However, here we make an important deviation
 from traditional PDE numerical integration methods for two reasons. 
First, if all cells are updated synchronously, initial conditions <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">s_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span></span>
 must vary from cell-to-cell in order to break the symmetry. Second, the
 physical implementation of the synchronous model would require the 
existence of a global clock, shared by all cells. One way to work around
 the former is by initializing the grid with random noise, but in the 
spirit of self organisation we instead choose to decouple the cell 
updates by asynchronously evaluating the CA. We sample a subset of all 
cells at each time-step to update. This introduces both asynchronicity 
in time (cells will sometimes operate on information from their 
neighbours that is several timesteps old), and asymmetry in space, 
solving both aforementioned issues.</p>

<p>Our next step towards representing a PDE with cellular automata is to
 discretize the gradient and Laplacian operators. For this we use the <a href="https://en.wikipedia.org/wiki/Sobel_operator">sobel operator</a> and the <a href="https://en.wikipedia.org/wiki/Discrete_Laplace_operator">9-point variant</a> of the discrete Laplace operator, as below.</p>

<figure>
<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mi>o</mi><mi>b</mi><mi>e</mi><msub><mi>l</mi><mi>x</mi></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mi>o</mi><mi>b</mi><mi>e</mi><msub><mi>l</mi><mi>y</mi></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>L</mi><mi>a</mi><mi>p</mi><mi>l</mi><mi>a</mi><mi>c</mi><mi>i</mi><mi>a</mi><mi>n</mi></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex"> \begin{array}{ c c c }
\begin{bmatrix}
-1 &amp; 0 &amp; 1\\-2 &amp; 0 &amp; 2 \\-1 &amp; 0 &amp; 1
\end{bmatrix}
&amp;
\begin{bmatrix}
-1 &amp; -2 &amp; -1\\ 0 &amp; 0 &amp; 0 \\1 &amp; 2 &amp; 1
\end{bmatrix}
&amp;
\begin{bmatrix}
1 &amp; 2 &amp; 1\\2 &amp; -12 &amp; 2 \\1 &amp; 2 &amp; 1
\end{bmatrix}
\\
Sobel_x &amp; Sobel_y &amp; Laplacian
\end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:2.65002em;"></span><span class="strut bottom" style="height:4.80004em;vertical-align:-2.15002em;"></span><span class="base"><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65002em;"><span style="top:-4.65002em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">2</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span></span></span></span><span style="top:-2.26em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">o</span><span class="mord mathit">b</span><span class="mord mathit">e</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15002em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65002em;"><span style="top:-4.65002em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">2</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span></span></span></span><span style="top:-2.26em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">o</span><span class="mord mathit">b</span><span class="mord mathit">e</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15002em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65002em;"><span style="top:-4.65002em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord mathrm">1</span><span class="mord mathrm">2</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">2</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"></span></span></span></span></span></span></span></span><span style="top:-2.26em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="mord mathit">L</span><span class="mord mathit">a</span><span class="mord mathit">p</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit">c</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15002em;"></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span>
</figure>

<p>With all the pieces in place, we now have a space-discretized version
 of our PDE that looks very much like a Cellular Automata: the time 
evolution of each discrete point in the raster grid depends only on its 
immediate neighbours. These discrete operators allow us to formalize our
 PDE as a CA. To double check that this is true, simply observe that as 
our grid becomes very fine, and the asynchronous updates approach 
uniformity, the dynamics of these discrete operators will reproduce the 
continuous dynamics of the original PDE as we defined it.</p>
<h4 id="to-neural-networks">To Neural Networks</h4>
<p>The final step in implementing the above general PDE for texture 
generation is to translate it to the language of deep learning. 
Fortunately, all the operations involved in iteratively evaluating the 
generalized PDE exist as common operations in most deep learning 
frameworks. We provide both a Tensorflow and a minimal PyTorch 
implementation for reference, and refer readers to these for details on 
our implementation.  </p>
<h3 id="nca-as-pattern-generators">NCA as pattern generators</h3>
<h4 id="model">Model:</h4>
<p></p>
<figure style="margin-left: auto; margin-right: auto; grid-column: page; width: 100%; max-width: 800px">
<img src="Self-Organising%20Textures_files/texture_model.svg" style="width: 100%">
<figcaption>Texture NCA model.</figcaption>
</figure>


<p>We build on the Growing CA NCA model <d-cite key="Mordvintsev_Randazzo_Niklasson_Levin_2020"></d-cite>,
 complete with built-in quantization of weights, stochastic updates, and
 the batch pool mechanism to approximate long-term training. For further
 details on the model and motivation, we refer readers to this work.</p>
<h4 id="loss-function-">Loss function: </h4>
<p>	</p>

<figure style="margin-left: auto; margin-right: auto; grid-column: page; width: 100%; max-width: 800px">
<img src="Self-Organising%20Textures_files/texture_training.svg" style="width: 100%">
<figcaption>Texture NCA model.</figcaption>
</figure>

<p>We use a well known deep convolutional network for image recognition, VGG (Visual Geometry Group Net <d-cite key="Simonyan_Zisserman_2014"></d-cite>) as our differentiable discriminator of textures, for the same reasons outlined in Differentiable Parametrizations <d-cite key="Mordvintsev_Pezzotti_Schubert_Olah_2018"></d-cite>. We start with a template image, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>x</mi></mrow><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.71444em;"></span><span class="strut bottom" style="height:0.71444em;vertical-align:0em;"></span><span class="base"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.71444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathit">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-vec" style="margin-left:0.05556em;"><span>⃗</span></span></span></span></span></span></span></span></span></span></span>, which we feed into VGG. Then we collect statistics from certain layers (block[<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">1…5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base"><span class="mord mathrm">1</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span></span>]_conv1)
 in the form of the raw activation values of the neurons in these 
layers. Finally, we run our NCA forward for between 32 and 64 
iterations, feeding the resulting RGB image into VGG. Our loss is the <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span></span> distance between the gram matrix<d-footnote id="d-footnote-5"> For a brief definition of gram matrices, see <a href="https://www.tensorflow.org/tutorials/generative/style_transfer#calculate_style">here</a>.</d-footnote>
 of activations of these neurons with the NCA as input and their 
activations with the template image as input. We keep the weights of VGG
 frozen and use ADAM <d-cite key="Kingma_Ba_2014"></d-cite> to update the weights of the NCA.</p>
<h4 id="dataset-">Dataset: </h4>
<p>The template images for this dataset are from the Oxford Describable Textures Dataset <d-cite key="Cimpoi_Maji_Kokkinos_Mohamed_Vedaldi_2013"></d-cite>.
  The aim of this dataset is to provide a benchmark for measuring the 
ability of vision models to recognize and categorize textures and 
describe textures using words. The textures were collected to match 47 
“attributes” such as “bumpy” or “polka-dotted”. These 47 attributes were
 in turn distilled from a set of common words used to describe textures 
identified by Bhusan, Rao and Lohse <d-cite key="Bhushan_Rao_Lohse_1997"></d-cite>. </p>
<h4 id="results">Results:</h4>
<p>After a few iterations of training, we see the NCA converge to a 
solution that at first glance looks similar to the input template, but 
not pixel-wise identical. The very first thing to notice is that the 
solution learned by the NCA is <strong>not</strong> time-invariant if we continue to iterate the CA. In other words it is constantly changing! </p>

<p>This is not completely unexpected. In <i>Differentiable Parametrizations</i>,
 the authors noted that the images produced when backpropagating into 
image space would end up different each time the algorithm was run due 
to the stochastic nature of the parametrizations. To work around this, 
they introduced some tricks to maintain <strong>alignment</strong> 
between different visualizations. In our model, we find that we attain 
such alignment along the temporal dimension without optimizing for it; a
 welcome surprise. We believe the reason is threefold. First, reaching 
and maintaining a static state in an NCA appears to be non-trivial in 
comparison to a dynamic one, so much so that in Growing CA a pool of NCA
 states at various iteration times had to be maintained and sampled as 
starting states to simulate loss being applied after a time period 
longer than the NCAs iteration period, to achieve a static stability. We
 employ the same sampling mechanism here to prevent the pattern from 
decaying, but in this case the loss doesn’t enforce a static fixed 
target; rather it guides the NCA towards any one of a number of states 
that minimizes the style loss. Second, we apply our loss after a random 
number of iterations of the NCA. This means that, at any given time 
step, the pattern must be in a state that minimizes the loss. Third, the
 stochastic updates, local communication, and quantization all limit and
 regularize the magnitude of updates at each iteration. This encourages 
changes to be small between one iteration and the next. We hypothesize 
that these properties combined encourage the NCA to find a solution 
where each iteration is <strong>aligned</strong> with the previous 
iteration. We perceive this alignment through time as motion, and as we 
iterate the NCA we observe it traversing a manifold of locally aligned 
solutions. </p>

<p>We now <strong>posit</strong> <i>that finding temporally aligned solutions is equivalent to finding an algorithm, or process, that generates the template pattern</i>,
 based on the aforementioned findings and qualitative observation of the
 NCA. We proceed to demonstrate some exciting behaviours of NCA trained 
on different template images.  </p>

<p></p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/grid.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to create a pattern in the style of <b>chequered_0121.jpg</b>.</figcaption>
</figure>

<p>Here, we see that the NCA is trained using a template image of a simple black and white grid. </p>
<p>We notice that: </p>

<ul><li>Initially, a non-aligned grid of black and white quadrilaterals is formed. </li>
<li>As time progresses, the quadrilaterals seemingly grow or shrink in both <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>x</mi></mrow><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.71444em;"></span><span class="strut bottom" style="height:0.71444em;vertical-align:0em;"></span><span class="base"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.71444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathit">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-vec" style="margin-left:0.05556em;"><span>⃗</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>y</mi></mrow><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.71444em;"></span><span class="strut bottom" style="height:0.9088799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.71444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-vec" style="margin-left:0.11112em;"><span>⃗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"></span></span></span></span></span></span></span></span>
 to more closely approximate squares. Quadrilaterals of both colours 
either emerge or disappear. Both of these behaviours seem to be an 
attempt to find local consistency. </li>
<li>After a longer time, the grid tends to achieve perfect consistency.</li></ul>

<p>Such behaviour is not entirely unlike what one would expect in a 
hand-engineered algorithm to produce a consistent grid with local 
communication. For instance, one potential hand-engineered approach 
would be to have cells first try and achieve local consistency, by 
choosing the most common colour from the cells surrounding them, then 
attempting to form a diamond of correct size by measuring distance to 
the four edges of this patch of consistent colour, and moving this 
boundary if it were incorrect. Distance could be measured by using a 
hidden channel to encode a gradient in each direction of interest, with 
each cell decreasing the magnitude of this channel as compared to its 
neighbour in that direction. A cell could then localize itself within a 
diamond by measuring the value of two such gradient channels. The 
appearance of such an algorithm would bear resemblance to the above - 
with patches of cells becoming either black, or white, diamonds then 
resizing themselves to achieve consistency.</p>

<p></p>
<figure><div class="vsc-controller"></div>
<!--<img src='images/bubbly_0101.jpg' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/bubbles.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to create a pattern in the style of <b>bubbly_0101.jpg</b>.</figcaption>
</figure>

<p>In this video, the NCA has learned to reproduce a texture based on a 
template of clear bubbles on a blue background. One of the most 
interesting behaviours we observe is that the density of the bubbles 
remains fairly constant. If we re-initialize the grid states, or 
interactively destroy states, we see a multitude of bubbles re-forming. 
However, as soon as two bubbles get too close to each other, one of them
 spontaneously collapses and disappears, ensuring a constant density of 
bubbles throughout the entire image. We regard these bubbles as ”<a href="#an-aside-solitons-and-lenia">solitons</a>″ in the solution space of our NCA. This is a concept we will discuss and investigate at length below.</p>

<p>If we speed the animation up, we see that different bubbles move at 
different speeds, yet they never collide or touch each other. Bubbles 
also maintain their structure by self-correcting; a damaged bubble can 
re-grow.</p>

<p>This behaviour is remarkable because it arises spontaneously, without
 any external or auxiliary losses. All of these properties are learned 
from a combination of the template image, the information stored in the 
layers of VGG, and the inductive bias of the NCA. The NCA learned a rule
 that effectively approximates many of the properties of the bubbles in 
the original image. Moreover, it has learned a process that generates 
this pattern in a way that is robust to damage and looks realistic to 
humans. </p>

<p></p>
<figure><div class="vsc-controller"></div>
<!--<img src='images/interlaced_0172.jpg' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/viking.mp4" '="" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to create a pattern in the style of <b>interlaced_0172.jpg</b>.</figcaption>
</figure>

<p>Here we see one of our favourite patterns: a simple geometric 
“weave”. Again, we notice the NCA seems to have learned an algorithm for
 producing this pattern. Each “thread” alternately joins or detaches 
from other threads in order to produce the final pattern. This is 
strikingly similar to what one would attempt to implement, were one 
asked to programmatically generate the above pattern. One would try to 
design some sort of stochastic algorithm for weaving individual threads 
together with other nearby threads.</p>



<figure><div class="vsc-controller"></div>
<!--<img src='images/banded_0037.jpg' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/lines.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to create a pattern in the style of <b>banded_0037.jpg</b>.</figcaption>
</figure>

<p>Here, misaligned stripe fragments travel up or down the stripe until 
either they merge to form a single straight stripe or a stripe shrinks 
and disappears. Were this to be implemented algorithmically with local 
communication, it is not infeasible that a similar algorithm for finding
 consistency among the stripes would be used.</p>
<h3 id="related-work">Related work</h3>
<p>This foray into pattern generation is by no means the first. There 
has been extensive work predating deep-learning, in particular 
suggesting deep connections between spatial patterning of anatomical 
structure and temporal patterning of cognitive and computational 
processes (e.g., reviewed in <d-cite key="Pezzulo_Levin_2015"></d-cite>).
 Hans Spemann, one of the heroes of classical developmental biology, 
said “Again and again terms have been used which point not to physical 
but to psychical analogies. It was meant to be more than a poetical 
metaphor. It was meant to my conviction that the suitable reaction of a 
germ fragment, endowed with diverse potencies, in an embryonic ‘field’… 
is not a common chemical reaction, like all vital processes, are 
comparable, to nothing we know in such degree as to vital processes of 
which we have the most intimate knowledge.” <d-cite key="Speman_1938"></d-cite>.
  More recently, Grossberg quantitatively laid out important 
similarities between developmental patterning and computational 
neuroscience <d-cite key="Grossberg_1978"></d-cite>. As briefly touched 
upon, the inspiration for much of the work came from Turing’s work on 
pattern generation through local interaction, and later papers based on 
this principle. However, we also wish to acknowledge some works that we 
feel have a particular kinship with ours. </p>
<h4 id="patch-sampling">Patch sampling</h4>
<p>Early work in pattern generation focused on texture sampling. Patches
 were often sampled from the original image and reconstructed or 
rejoined in different ways to obtain an approximation of the texture. 
This method has also seen recent success with the work of Gumin <d-cite key="Gumin"></d-cite>.</p>
<h4 id="deep-learning">Deep learning</h4>
<p>Gatys et. al’s work <d-cite key="Gatys_Ecker_Bethge_2015"></d-cite>, 
referenced throughout, has been seminal with regards to the idea that 
statistics of certain layers in a pre-trained network can capture 
textures or styles in an image. There has been extensive work building 
on this idea, including playing with other parametrisations for image 
generation <d-cite key="Mordvintsev_Pezzotti_Schubert_Olah_2018"></d-cite> and optimizing the generation process <d-cite key="Ulyanov_Lebedev_Vedaldi_Lempitsky_2016"></d-cite>. </p>

<p>Other work has focused on using a convolutional generator combined 
with path sampling and trained using an adversarial loss to produce 
textures of similar quality <d-cite key="Xian_Sangkloy_Agrawal_Raj_Lu_Fang_Yu_Hays_2018"></d-cite>. </p>
<h4 id="interactive-evolution-of-camouflage">Interactive Evolution of Camouflage</h4>
<p>Perhaps the most unconventional approach, with which we find kinship, is laid out in <i>Interactive Evolution of Camouflage</i> <d-cite key="Reynolds_2011"></d-cite>.
 Craig Reynolds uses a texture description language, consisting of 
generators and operators, to parametrize a texture patch, which is 
presented to human viewers who have to decide which patches are the 
worst at “camouflaging” themselves against a chosen background texture. 
The population is updated in an evolutionary fashion to maximize 
“camouflage”, resulting in a texture exhibiting the most camouflage (to 
human eyes) after a number of iterations. We see strong parallels with 
our work - instead of a texture generation language, we have an NCA 
parametrize the texture, and instead of human reviewers we use VGG as an
 evaluator of the quality of a generated pattern. We believe a 
fundamental difference lies in the solution space of an NCA. A texture 
generation language comes with a number of inductive biases and learns a
 deterministic mapping from coordinates to colours. Our method appears 
to learn more general algorithms and behaviours giving rise to the 
target pattern.</p>

<p>Two other noteworthy examples of similar work are Portilla et. al’s work with the wavelet transform <d-cite key="Portilla_Simoncelli_2000"></d-cite>, and work by Chen et al with reaction diffusion <d-cite key="Chen_Pock_2017"></d-cite>.</p>
<h2 id="feature-visualization">Feature visualization</h2>

<p></p>
<figure>
<img src="Self-Organising%20Textures_files/butterfly_eye.jpg" style="width: 350px">
<figcaption>A butterfly with an “eye-spot” on the wings.</figcaption>
</figure>

<p>We have now explored some of the fascinating behaviours learned by 
the NCA when presented with a template image. What if we want to see 
them learn even more “unconstrained” behaviour? </p>

<p>Some butterflies have remarkably lifelike eyes on their wings. It’s 
unlikely the butterflies are even aware of this incredible artwork on 
their own bodies. Evolution placed these there to trigger a response of 
fear in potential predators or to deflect attacks from them <d-cite key="Kodandaramaiah_2011"></d-cite>.
 It is likely that neither the predator nor the butterfly has a concept 
for what an eye is or what an eye does, or even less so any <a href="https://en.wikipedia.org/wiki/Theory_of_mind">theory of mind</a>
 regarding the consciousness of the other, but evolution has identified a
 region of morphospace for this organism that exploits 
pattern-identifying features of predators to trick them into fearing a 
harmless bug instead of consuming it. </p>

<p>Even more remarkable is the fact that the individual cells composing 
the butterfly’s wings can self assemble into coherent, beautiful, shapes
 far larger than an individual cell - indeed a cell is on the order of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>1</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup><mi>m</mi></mrow><annotation encoding="application/x-tex">1^{-5}m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathrm">1</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">5</span></span></span></span></span></span></span></span></span><span class="mord mathit">m</span></span></span></span></span> <d-cite key="Ohno_Otaki_2015"></d-cite> while the features on the wings will grow to as large as <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>1</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup><mi>m</mi></mrow><annotation encoding="application/x-tex">1^{-3}m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathrm">1</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">3</span></span></span></span></span></span></span></span></span><span class="mord mathit">m</span></span></span></span></span> <d-cite key="Iwata_Otaki_2016"></d-cite>.
 The coordination required to produce these features implies  
self-organization over hundreds or thousands of cells to generate a 
coherent image of an eye that evolved simply to act as a visual stimuli 
for an entirely different species, because of the local nature of 
cell-to-cell communication. Of course, this pales in comparison to the 
morphogenesis that occurs in animal and plant bodies, where structures 
consisting of millions of cells will specialize and coordinate to 
generate the target morphology. </p>

<p>A common approach to investigating neural networks is to look at what inhibits or excites individual neurons in a network <d-cite key="Schubert_Petrov_Carter_Cammarata_Goh_Olah_2020"></d-cite>.
 Just as neuroscientists and biologists have often treated cells and 
cell structures and neurons as black-box models to be investigated, 
measured and reverse-engineered, there is a large contemporary body of 
work on doing the same with neural networks. For instance the work by 
Boettiger <d-cite key="Boettiger_Ermentrout_Oster_2009"></d-cite> <d-cite key="Boettiger_Oster_2009"></d-cite>.</p>

<p>We can explore this idea with minimal effort by taking our 
pattern-generating NCA and exploring what happens if we task it to enter
 a state that excites a given neuron in Inception. One of the common 
resulting NCAs we notice is eye and eye-related shapes - such as the 
video below - likely as a result of having to detect various animals in 
ImageNet. In the same way that cells form eye patterns on the wings of 
butterflies to excite neurons in the brains of predators, our NCA’s 
population of cells has learned to collaborate to produce a pattern that
 excites certain neurons in an external neural network.</p>

<p></p>
<figure><div class="vsc-controller"></div>
<!--<img src='images/mixed4a_472_microscope.png' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/eyes.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to excite <b>mixed4a_472</b> in Inception.</figcaption>
</figure>

<h3 id="nca-with-inception">NCA with Inception</h3>
<h4 id="model-">Model: </h4>
<p>We use a model identical to the one used for exploring pattern 
generation, but with a different discriminator network: Imagenet-trained
 Inception v1 network <d-cite key="szegedy2015going"></d-cite>.</p>
<h4 id="loss-function-">Loss function: </h4>
<p>Our loss maximizes the activations of chosen neurons, when evaluated 
on the output of the NCA. We add an auxiliary loss to encourage the 
outputs of the NCA to be <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">\in [0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mrel">∈</span><span class="mopen">[</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">]</span></span></span></span></span>, as this is not inherently built into the model. We keep the weights of the Inception frozen and use ADAM <d-cite key="Kingma_Ba_2014"></d-cite> to update the weights of the NCA.</p>
<h4 id="dataset-">Dataset: </h4>
<p>There is no explicit dataset for this task. Inception is trained on 
ImageNet. The layers and neurons we chose to excite are chosen 
qualitatively using OpenAI Microscope.</p>
<h4 id="results">Results:</h4>
<p>Similar to the pattern generation experiment, we see quick 
convergence and a tendency to find temporally dynamic solutions. In 
other words, resulting NCAs do not stay still. We also observe that the 
majority of the NCAs learn to produce solitons of various kinds. We 
discuss a few below, but encourage readers to explore them in the demo. </p>

<p></p>
<figure><div class="vsc-controller"></div>
<!--<img src='images/mixed4c_439_microscope.png' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/eyes.mov" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to excite <b>mixed4c_439</b> in Inception.</figcaption>
</figure>
<p>Solitons in the form of regular circle-like shapes with internal 
structure are quite commonly observed in the inception renderings. Two 
solitons approaching each other too closely may cause one or both of 
them to decay. We also observe that solitons can divide into two new 
solitons.</p>
<p></p>
<figure><div class="vsc-controller"></div>
<!--<img src='images/mixed3b_454_microscope.png' style='width: 325px'></img>-->
<video src="Self-Organising%20Textures_files/moving_thread.mov" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 325px"></video>
<figcaption>An NCA trained to excite <b>mixed3b_454</b> in Inception.</figcaption>
</figure>
<p>In textures that are composed of threads or lines, or in certain 
excitations of Inception neurons where the resulting NCA has a 
“thread-like” quality, the threads grow in their respective directions 
and will join other threads, or grow around them, as required. This 
behaviour is similar to the regular lines observed in the striped 
patterns during pattern generation.</p>

<h2 id="other-interesting-findings">Other interesting findings</h2>
<h3 id="robustness">Robustness</h3>
<h4 id="switching-manifolds">Switching manifolds</h4>

<p>We encode local information flow within the NCA using the same fixed 
Laplacian and gradient filters. As luck would have it, these can be 
defined for most underlying manifolds, giving us a way of placing our 
cells on various surfaces and in various configurations without having 
to modify the learned model. Suppose we want our cells to live in a 
hexagonal world. We can redefine our kernels as follows:</p>
<p></p>
<figure>
<img src="Self-Organising%20Textures_files/hex_kernels.svg" style="width: 450px">
<figcaption>Hexagonal grid convolutional filters.</figcaption>
</figure>
<p>Our model, trained in a purely square environment, works out of the 
box on a hexagonal grid! Play with the corresponding setting in the demo
 to experiment with this. Zooming in allows observation of the 
individual hexagonal or square cells. As can be seen in the demo, the 
cells have no problem adjusting to a hexagonal world and producing 
identical patterns after a brief period of re-alignment.</p>

<p> </p>
<figure>
<img src="Self-Organising%20Textures_files/coral_square.png" style="width: 450px">
<img src="Self-Organising%20Textures_files/coral_hex.png" style="width: 450px">
<figcaption>The same texture evaluated on a square and hexagonal grid, respectively.</figcaption>
</figure>
<h4 id="rotation">Rotation</h4>
<p></p>
<figure>
<img src="Self-Organising%20Textures_files/mond_rot0.png" style="width:40%;">
<img src="Self-Organising%20Textures_files/mond_rot1.png" style="width:40%;">
<img src="Self-Organising%20Textures_files/mond_rot2.png" style="width:40%;">
<img src="Self-Organising%20Textures_files/mond_rot3.png" style="width:40%;">
<figcaption>Mondrian pattern where the cells are rotated in various directions. Note that the NCA is not re-trained - it gen-
eralises to this new rotated paradigm without issue.
</figcaption>
</figure>

<p>In theory, the cells can be evaluated on any manifold where one can 
define approximations to the Sobel kernel and the Laplacian kernel. We 
demonstrate this in our demo by providing an aforementioned “hexagonal” 
world for the cells to live in. Instead of having eight equally-spaced 
neighbours, each cell now has six equally-spaced neighbours. We further 
demonstrate this versatility by rotating the Sobel and Laplacian 
kernels. Each cell receives an innate global orientation based on these 
kernels, because they are defined with respect to the coordinate system 
of the state. Redefining the Sobel and Laplacian kernel with a rotated 
coordinate system is straightforward and can even be done on a per-cell 
level. Such versatility is exciting because it mirrors the extreme 
robustness found in biological cells in nature. Cells in most tissues 
will generally continue to operate whatever their location, direction, 
or exact placement relative to their neighbours. We believe this 
versatility in our model could even extend to a setting where the cells 
are placed on a manifold at random, rather than on an ordered grid.</p>
<h4 id="timesynchronization-">Time-synchronization </h4>
<p></p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/time_unsynced.mp4" autoplay="autoplay" loop="" controls="controls" muted="muted" style="width: 450px"></video>
<figcaption>Two NCAs running next to each other, at different speeds, 
with some stochasticity in speed. They can communicate through their 
shared edge; the vertical boundary between them in the center of the 
state space.</figcaption>
</figure>

<p>Stochastic updates teach the cells to be robust to asynchronous 
updates. We investigate this property by taking it to an extreme and 
asking <i>how</i><i> do the cells react if two manifolds are allowed to communicate but one runs the NCA at a different speed than the other</i>?
 The result is surprisingly stable; the CA is still able to construct 
and maintain a consistent texture across the combined manifold. The time
 discrepancy between the two CAs sharing the state is far larger than 
anything the NCA experiences during training, showing remarkable 
robustness of the learned behaviour. Parallels can be drawn to organic 
matter self repairing, for instance a fingernail can regrow in adulthood
 despite the underlying finger already having fully developed; the two 
do not need to be sync. This result also hints at the possibility of 
designing distributed systems without having to engineer for a global 
clock, synchronization of compute units or even homogenous compute 
capacity. </p>

<p></p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/fig_13_chequered_0121.mp4" autoplay="autoplay" loop="" controls="controls" muted="muted" style="width: 450px"></video>
<figcaption>An NCA is evaluated for a number of steps. The surrounding 
border of cells are then also turned into NCA cells. The cells have no 
difficulty communicating with the “finished” pattern and achieving 
consistency. </figcaption>
</figure>

<p>An even more drastic example of this robustness to time 
asynchronicity can be seen above. Here, an NCA is iterated until it 
achieves perfect consistency in a pattern. Then, the state space is 
expanded, introducing a border of new cells around the existing state. 
This border quickly interfaces with the existing cells and settles in a 
consistent pattern, with almost no perturbation to the already-converged
 inner state.</p>
<h4 id="failure-cases">Failure cases</h4>
<p>The failure modes of a complex system can teach us a great deal about
 its internal structure and process. Our model has many quirks and 
sometimes these prevent it from learning certain patterns. Below are 
some examples.</p>
<p></p>
<figure>
<img src="Self-Organising%20Textures_files/fail_mondrian.jpeg" style="width:30%; max-width: 150px;">
<img src="Self-Organising%20Textures_files/fail_sprinkle.jpeg" style="width:30%; max-width: 150px;">
<img src="Self-Organising%20Textures_files/fail_chequerboard.jpeg" style="width:30%; max-width: 150px;">
<figcaption>Three failure cases of the NCA. Bottom row shows target 
texture samples, top row are corresponding NCA outputs. Failure modes 
include incorrect colours, chequerboard artefacts, and incoherent image 
structure.</figcaption>
</figure>

<p>Some patterns are reproduced somewhat accurately in terms of 
structure, but not in colour, while some are the opposite. Others fail 
completely. It is difficult to determine whether these failure cases 
have their roots in the parametrization (the NCA), or in the 
hard-to-interpret gradient signals from VGG, or Inception. Existing work
 with style transfer suggests that using a loss on Gram matrices in VGG 
can introduce instabilities <d-cite key="Risser_Wilmot_Barnes_2017"></d-cite>,
 that are similar to the ones we see here. We hypothesize that this 
effect explains the failures in reproducing colors. The structural 
failures, meanwhile, may be caused by the NCA parameterization, which 
makes it difficult for cells to establish long-distance communication 
with one another.</p>
<h3 id="hidden-states">Hidden states</h3>
<p>When biological cells communicate with each other, they do so through
 a multitude of available communication channels. Cells can emit or 
absorb different ions and proteins, sense physical motion or “stiffness”
 of other cells, and even emit different chemical signals to diffuse 
over the local substrate <d-cite key="Hadden_Young_2017"></d-cite>. </p>

<p>There are various ways to visualize communication channels in real 
cells. One of them is to add to cells a potential-activated dye. Doing 
so gives a clear picture of the voltage potential the cell is under with
 respect to the surrounding substrate. This technique provides useful 
insight into the communication patterns within groups of cells and helps
 scientists visualize both local and global communication over a variety
 of time-scales.</p>

<p>As luck would have it, we can do something similar with our Neural 
Cellular Automata. Our NCA model contains 12 channels. The first three 
are visible RGB channels and the rest we treat as latent channels which 
are visible to adjacent cells during update steps, but excluded from 
loss functions. Below we map the first three principle components of the
 hidden channels to the R,G, and B channels respectively. Hidden 
channels can be considered “floating,” to abuse a term from circuit 
theory. In other words, they are not pulled to any specific final state 
or intermediate state by the loss. Instead, they converge to some form 
of a dynamical system which assists the cell in fulfilling its objective
 with respect to its visible channels. There is no pre-defined 
assignment of different roles or meaning to different hidden channels, 
and there is almost certainly redundancy and correlation between 
different hidden channels. Such correlation may not be visible when we 
visualize the first three principal components in isolation. But this 
concern aside, the visualization yields some interesting insights 
anyways.</p>
<p>	</p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/hidden_pca.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 650px"></video>
<figcaption><b>Left:</b> RGB channels of NCA. <b>Right:</b> Intensities of top three principal components of hidden states. <br><br> An NCA trained to excite <b>mixed4b_70</b>
 in Inception. Notice the hidden states appear to encode information 
about structure. “Threads” along the major diagonal (NW - SE) appear 
primarily green, while those running along the anti-diagonal appear 
blue, indicating that these have differing internal states, despite 
being effectively indistinguishable in RGB space.</figcaption>
</figure>

<p>In the principal components of this coral-like texture, we see a 
pattern which is similar to the visible channels. However, the “threads”
 pointing in each diagonal direction have different colours - one 
diagonal is green and the other is a pale blue. This suggests that one 
of the things encoded into the hidden states is the direction of a 
“thread”, likely to allow cells that are inside one of these threads to 
keep track of which direction the thread is growing, or moving, in. </p>

<p></p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/chequered_hidden.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 650px"></video>
<figcaption><b>Left:</b> RGB channels of NCA. <b>Right:</b> Intensities of top three principal components of hidden states. <br><br> An NCA trained to produce a texture based on DTD image <b>cheqeuered_0121</b>.
 Notice the structure of squares - with a gradient occurring inside the 
structure of each square, evidencing that structure is being encoded in 
hidden state.</figcaption>
</figure>
<p>The chequerboard pattern likewise lends itself to some qualitative 
analysis and hints at a fairly simple mechanism for maintaining the 
shape of squares. Each square has a clear gradient in PCA space across 
the diagonal, and the values this gradient traverses differ for the 
white and black squares. We find it likely the gradient is used to 
provide a local coordinate system for creating and sizing the squares. </p>

<p></p>
<figure><div class="vsc-controller"></div>
<video src="Self-Organising%20Textures_files/eyes_hidden.mp4" autoplay="autoplay" loop="" muted="muted" controls="controls" style="width: 650px"></video>
<figcaption><b>Left:</b> RGB channels of NCA. <b>Right:</b> Intensities of top three principal components of hidden states. <br><br>  An NCA trained to excite <b>mixed4c_208</b>
 in Inception. The visible body of the eye is clearly demarcated in the 
hidden states. There is also a “halo” which appears to modulate growth 
of any solitons immediately next to each other. This halo is barely 
visible in the RGB channels.</figcaption>
</figure> 
<p>We find surprising insight in NCA trained on Inception as well. In 
this case, the structure of the eye is clearly encoded in the hidden 
state with the body composed primarily of one combination of principal 
components, and an halo, seemingly to prevent collisions of the eye 
solitons, composed of another set of principal components.</p>

<p>Analysis of these hidden states is something of a dark art; it is not
 always possible to draw rigorous conclusions about what is happening. 
We welcome future work in this direction, as we believe qualitative 
analysis of these behaviours will be useful for understanding more 
complex behaviours of CAs. We also hypothesize that it may be possible 
to modify or alter hidden states in order to affect the morphology and 
behaviour of NCA. </p>
<h2 id="conclusion">Conclusion</h2>
<p>In this work, we selected texture templates and individual neurons as
 targets and then optimized NCA populations so as to produce similar 
excitations in a pre-trained neural network. This procedure yielded NCAs
 that could render nuanced and hypnotic textures. During our analysis, 
we found that these NCAs have interesting and unexpected properties. 
Many of the solutions for generating certain patterns in an image appear
 similar to the underlying model or physical behaviour producing the 
pattern. For example, our learned NCAs seem to have a bias for treating 
objects in the pattern as individual objects and letting them move 
freely across space. While this effect was present in many of our 
models, it was particularly strong in the bubble and eye models. The NCA
 is forced to find algorithms that can produce such a pattern with 
purely local interaction. This constraint seems to produce models that 
favor high-level consistency and robustness.</p>

<section id="thread-nav" class="thread-info" style="margin-top: 10px; margin-bottom: 40px">
  <img class="thread-icon" src="Self-Organising%20Textures_files/multiple-pages.svg" width="43px" height="50px">
  <p class="explanation">
    This article is part of the
    <a href="https://distill.pub/2020/selforg/">Differentiable Self-organizing Systems Thread</a>,
    an experimental format collecting invited short articles delving into
    differentiable self-organizing systems, interspersed with critical
    commentary from several experts in adjacent fields.
  </p>
  <a class="prev" href="https://distill.pub/2020/selforg/mnist/">Self-classifying MNIST Digits</a>
  <a class="next" href="https://distill.pub/selforg/2021/adversarial/">Adversarial Reprogramming of Neural Cellular Automata</a>
</section>

</d-article>
<d-appendix>
<style>

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

</style>


<h3 id="acknowledgments">Acknowledgments</h3>
<p>We’d like to thank Sam Greydanus for especially thoughtful 
proofreading and giving extensive feedback throughout the article. We 
also extend our gratitude to the other reviewers; Maximilian Otte, 
Aleksandr Groznykh, and Smitty van Bodegom. Finally, we would like to 
acknowledge the continued support from Blaise Agüera y Arcas and Dominik
 Roblek, without whom this work wouldn’t be possible. </p>
<h3 id="author-contributions">Author Contributions</h3>
<p><strong>Research</strong>: Alexander proposed using Neural CA for 
texture synthesis and feature visualization and prototyped the TF and 
PyTorch implementations. Eyvind refined the implementation and performed
 most of the article experiments.</p>

<p><strong>Demos</strong>: Alexander implemented the WebGL NCA engine. Eyvind implemented the demo UI.</p>

<p><strong>Writing and Diagrams</strong>: Eyvind wrote most of the 
article text and created most of the diagrams and videos. Michael 
provided the biological context for the article. Alexander and Ettore 
contributed to the content.</p>
<h3 id="an-aside-solitons-and-lenia">An Aside: Solitons and Lenia</h3>
<p>The motion of waves propagating through a medium can be described 
using the classical wave equation. The equation below defines the change
 of some quantity <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">u</span></span></span></span></span> (be it the surface height map of a body of water, the position of a vibrating string, etc.) with respect to the laplacian of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">u</span></span></span></span></span>. <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">c</span></span></span></span></span> ends up being the propagation speed of the wave.</p>

<figure>
<p><span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>u</mi><mo>¨</mo></mover><mo>=</mo><msup><mi>c</mi><mn>2</mn></msup><msup><mi mathvariant="normal">∇</mi><mn>2</mn></msup><mi>u</mi></mrow><annotation encoding="application/x-tex">\ddot u = c^2 \nabla^2 u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathit">u</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="margin-left:0.05556em;"><span>¨</span></span></span></span></span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">2</span></span></span></span></span></span></span></span><span class="mord mathit">u</span></span></span></span></span></p>
</figure>

<p>One can imagine waves to come either as a single wave, or as a larger
 mixture of waves of different frequencies (a phenomenon referred to as a
 group or a packet). Physical phenomena, however, are rarely as 
structured and regular as we would like them to be. To describe the 
propagation of real-world waves in most physical media, such as waves in
 water, or sound, we must use somewhat more complex partial differential
 equations. Many of these systems, with the notable exception of light, 
share a property that waves of different frequencies will travel at 
different speeds. “Speed” in such a context is a tricky thing to define -
 however in this case we are referring to the speed of any localized 
quantity of energy - how fast its peak travels in space. In the above, 
classic, wave equation this corresponds to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">c</span></span></span></span></span>.
 However, in the real world, when waves of different frequencies have 
different speeds, groups of waves are no longer cohesive and will 
experience “dispersion”: the envelope of the group of waves will change 
shape over time and potentially not remain cohesive. Even in wave groups
 with dispersive properties, it is possible to find solutions to their 
partial differential equations where nonlinearities in the propagation 
and interaction between waves will counteract the dispersive properties 
of the wave group. This phenomenon, while lacking a strict definition, 
is called a “soliton”. It describes a wave packet which retains its 
shape during propagation.</p>

<p>Recall the idea (touched upon in <a href="https://distill.pub/2020/growing-ca/">Growing Neural Cellular Automata</a>)
 that a grid of communicating NCAs can be thought of as a finite 
difference approximation of a partial differential equation in both time
 and space. Several of the patterns we render in the pattern-generation 
experiment, as well as in  the inception experiment, consist of 
well-defined structures such as circles or polygons. We consider such 
structures to be functionally equivalent to solitons and refer to them 
as such. Such a classification is inspired by B. Chan’s reference to 
solitons in “Lenia.” He defines them as solid, self-maintaining 
structures which arise in the continuous approximation of the Game of 
Life.</p>
<h3 id="attribution">Attribution</h3>
<p>The ”<a href="https://thenounproject.com/term/mouse-scroll/496854/">mouse</a>″ and ”<a href="https://thenounproject.com/search/?q=swipe&amp;i=893260">swipe</a>″ icons in the demo are licensed under CC-BY.</p>

    <d-footnote-list style="">
<style>

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}

</style>

<h3>Footnotes</h3>
<ol><li id="d-footnote-1-listing"> We use NCA to refer to both <i>Neural Cellular Automata </i>and <i>Neural Cellular Automaton</i>.<a class="footnote-backlink" href="#d-footnote-1">[↩]</a></li><li id="d-footnote-2-listing"> Degenerate in this case refers to the <a href="https://en.wikipedia.org/wiki/Degeneracy_(biology)">biological concept of degeneracy</a>.<a class="footnote-backlink" href="#d-footnote-2">[↩]</a></li><li id="d-footnote-3-listing">
 Perhaps an apocryphal claim, but at the very lowest level every zebra 
will be unique. Ourp point is - “zebra stripes” as a concept in human 
understanding refers to the general structure of a black and white 
striped pattern and not to a specific mapping from location to colour.<a class="footnote-backlink" href="#d-footnote-3">[↩]</a></li><li id="d-footnote-4-listing"> See <a href="https://en.wikipedia.org/wiki/Liar_paradox">liar paradox</a>.
 In principle, gene regulatory networks can express paradoxical 
behaviour, such as that expression of factor A represses the expression 
of factor A. <d-cite key="Isalan_2009"></d-cite> One result of such a paradox can be that a certain factor will oscillate with time. <a class="footnote-backlink" href="#d-footnote-4">[↩]</a></li><li id="d-footnote-5-listing"> For a brief definition of gram matrices, see <a href="https://www.tensorflow.org/tutorials/generative/style_transfer#calculate_style">here</a>.<a class="footnote-backlink" href="#d-footnote-5">[↩]</a></li></ol>
</d-footnote-list>
    <d-citation-list distill-prerendered="true"><style>
d-citation-list {
  contain: style;
}

d-citation-list .references {
  grid-column: text;
}

d-citation-list .references .title {
  font-weight: 500;
}
</style><h3 id="references">References</h3><ol id="references-list" class="references"><li id="Mordvintsev_Randazzo_Niklasson_Levin_2020"><span class="title">Growing Neural Cellular Automata</span>   <a href="https://distill.pub/2020/growing-ca">[link]</a><br>Mordvintsev, A., Randazzo, E., Niklasson, E. and Levin, M., 2020. Distill, Vol 5(2), pp. e23.  <a href="https://doi.org/10.23915/distill.00023" style="text-decoration:inherit;">DOI: 10.23915/distill.00023</a></li><li id="Sandler_Zhmoginov_Luo_Mordvintsev_Randazzo_Arcas_2020"><span class="title">Image segmentation via Cellular Automata</span>   <a href="http://arxiv.org/pdf/2008.04965.pdf">[PDF]</a><br>Sandler, M., Zhmoginov, A., Luo, L., Mordvintsev, A., Randazzo, E. and Arcas, B.A.y., 2020. arXiv [cs.CV]. </li><li id="Randazzo_Mordvintsev_Niklasson_Levin_Greydanus_2020"><span class="title">Self-classifying MNIST Digits</span>   <a href="https://distill.pub/2020/selforg/mnist">[link]</a><br>Randazzo, E., Mordvintsev, A., Niklasson, E., Levin, M. and Greydanus, S., 2020. Distill, Vol 5(8).  <a href="https://doi.org/10.23915/distill.00027.002" style="text-decoration:inherit;">DOI: 10.23915/distill.00027.002</a></li><li id="Mordvintsev_Pezzotti_Schubert_Olah_2018"><span class="title">Differentiable Image Parameterizations</span>   <a href="https://distill.pub/2018/differentiable-parameterizations">[link]</a><br>Mordvintsev, A., Pezzotti, N., Schubert, L. and Olah, C., 2018. Distill, Vol 3(7).  <a href="https://doi.org/10.23915/distill.00012" style="text-decoration:inherit;">DOI: 10.23915/distill.00012</a></li><li id="Turing_1952"><span class="title">The chemical basis of morphogenesis</span>   <a href="https://doi.org/10.1098/rstb.1952.0012">[link]</a><br>Turing,
 A.M., 1952. Philosophical transactions of the Royal Society of London. 
Series B, Biological sciences, Vol 237(641), pp. 37–72. Royal Society. <a href="https://doi.org/10.1098/rstb.1952.0012" style="text-decoration:inherit;">DOI: 10.1098/rstb.1952.0012</a></li><li id="Marcon_Sharpe_2012"><span class="title">Turing patterns in development: what about the horse part?</span>   <a href="http://dx.doi.org/10.1016/j.gde.2012.11.013">[link]</a><br>Marcon, L. and Sharpe, J., 2012. Current opinion in genetics &amp; development, Vol 22(6), pp. 578–584.  <a href="https://doi.org/10.1016/j.gde.2012.11.013" style="text-decoration:inherit;">DOI: 10.1016/j.gde.2012.11.013</a></li><li id="Schaerli_Munteanu_Gili_Cotterell_Sharpe_Isalan_2014"><span class="title">A unified design space of synthetic stripe-forming networks</span>   <a href="http://dx.doi.org/10.1038/ncomms5905">[link]</a><br>Schaerli, Y., Munteanu, A., Gili, M., Cotterell, J., Sharpe, J. and Isalan, M., 2014. Nature communications, Vol 5, pp. 4905.  <a href="https://doi.org/10.1038/ncomms5905" style="text-decoration:inherit;">DOI: 10.1038/ncomms5905</a></li><li id="Hiscock_Tschopp_Tabin_2017"><span class="title">On the Formation of Digits and Joints during Limb Development</span>   <a href="http://dx.doi.org/10.1016/j.devcel.2017.04.021">[link]</a><br>Hiscock, T.W., Tschopp, P. and Tabin, C.J., 2017. Developmental cell, Vol 41(5), pp. 459–465.  <a href="https://doi.org/10.1016/j.devcel.2017.04.021" style="text-decoration:inherit;">DOI: 10.1016/j.devcel.2017.04.021</a></li><li id="Raspopovic_Marcon_Russo_Sharpe_2014"><span class="title">Modeling digits. Digit patterning is controlled by a Bmp-Sox9-Wnt Turing network modulated by morphogen gradients</span>   <a href="http://dx.doi.org/10.1126/science.1252960">[link]</a><br>Raspopovic, J., Marcon, L., Russo, L. and Sharpe, J., 2014. Science, Vol 345(6196), pp. 566–570.  <a href="https://doi.org/10.1126/science.1252960" style="text-decoration:inherit;">DOI: 10.1126/science.1252960</a></li><li id="Landge_Jordan_Diego_Müller_2020"><span class="title">Pattern formation mechanisms of self-organizing reaction-diffusion systems</span>   <a href="http://dx.doi.org/10.1016/j.ydbio.2019.10.031">[link]</a><br>Landge, A.N., Jordan, B.M., Diego, X. and Müller, P., 2020. Developmental biology, Vol 460(1), pp. 2–11.  <a href="https://doi.org/10.1016/j.ydbio.2019.10.031" style="text-decoration:inherit;">DOI: 10.1016/j.ydbio.2019.10.031</a></li><li id="Pietak_Levin_2017"><span class="title">Bioelectric
 gene and reaction networks: computational modelling of genetic, 
biochemical and bioelectrical dynamics in pattern regulation</span>   <a href="http://dx.doi.org/10.1098/rsif.2017.0425">[link]</a><br>Pietak, A. and Levin, M., 2017. Journal of the Royal Society, Interface / the Royal Society, Vol 14(134).  <a href="https://doi.org/10.1098/rsif.2017.0425" style="text-decoration:inherit;">DOI: 10.1098/rsif.2017.0425</a></li><li id="Brodsky"><span class="title">Turing-like patterns can arise from purely bioelectric mechanisms</span>   <a href="http://dx.doi.org/10.1101/336461">[link]</a><br>Brodsky, M.. Draft.  <a href="https://doi.org/10.1101/336461" style="text-decoration:inherit;">DOI: 10.1101/336461</a></li><li id="Goldbeter_2018"><span class="title">Dissipative structures in biological systems: bistability, oscillations, spatial patterns and waves</span>   <a href="http://dx.doi.org/10.1098/rsta.2017.0376">[link]</a><br>Goldbeter, A., 2018. Philosophical transactions. Series A, Mathematical, physical, and engineering sciences, Vol 376(2124).  <a href="https://doi.org/10.1098/rsta.2017.0376" style="text-decoration:inherit;">DOI: 10.1098/rsta.2017.0376</a></li><li id="Isalan_2009"><span class="title">Gene networks and liar paradoxes</span>   <a href="http://dx.doi.org/10.1002/bies.200900072">[link]</a><br>Isalan, M., 2009. BioEssays: news and reviews in molecular, cellular and developmental biology, Vol 31(10), pp. 1110–1115.  <a href="https://doi.org/10.1002/bies.200900072" style="text-decoration:inherit;">DOI: 10.1002/bies.200900072</a></li><li id="Gatys_Ecker_Bethge_2015"><span class="title">Texture Synthesis Using Convolutional Neural Networks</span>   <a href="http://arxiv.org/pdf/1505.07376.pdf">[PDF]</a><br>Gatys, L.A., Ecker, A.S. and Bethge, M., 2015. arXiv [cs.CV]. </li><li id="Turing_1990"><span class="title">The chemical basis of morphogenesis. 1953</span>   <a href="http://dx.doi.org/10.1007/BF02459572">[link]</a><br>Turing, A.M., 1990. Bulletin of mathematical biology, Vol 52(1-2), pp. 153–97; discussion 119–52.  <a href="https://doi.org/10.1007/BF02459572" style="text-decoration:inherit;">DOI: 10.1007/BF02459572</a></li><li id="Lee_McCormick_Ouyang_Swinney_1993"><span class="title">Pattern formation by interacting chemical fronts</span>   <a href="http://dx.doi.org/10.1126/science.261.5118.192">[link]</a><br>Lee, K.J., McCormick, W.D., Ouyang, Q. and Swinney, H.L., 1993. Science, Vol 261(5118), pp. 192–194.  <a href="https://doi.org/10.1126/science.261.5118.192" style="text-decoration:inherit;">DOI: 10.1126/science.261.5118.192</a></li><li id="Pearson_1993"><span class="title">Complex patterns in a simple system</span>   <a href="http://dx.doi.org/10.1126/science.261.5118.189">[link]</a><br>Pearson, J.E., 1993. Science, Vol 261(5118), pp. 189–192.  <a href="https://doi.org/10.1126/science.261.5118.189" style="text-decoration:inherit;">DOI: 10.1126/science.261.5118.189</a></li><li id="Simonyan_Zisserman_2014"><span class="title">Very Deep Convolutional Networks for Large-Scale Image Recognition</span>   <a href="http://arxiv.org/pdf/1409.1556.pdf">[PDF]</a><br>Simonyan, K. and Zisserman, A., 2014. arXiv [cs.CV]. </li><li id="Kingma_Ba_2014"><span class="title">Adam: A Method for Stochastic Optimization</span>   <a href="http://arxiv.org/pdf/1412.6980.pdf">[PDF]</a><br>Kingma, D.P. and Ba, J., 2014. arXiv [cs.LG]. </li><li id="Cimpoi_Maji_Kokkinos_Mohamed_Vedaldi_2013"><span class="title">Describing Textures in the Wild</span>   <a href="http://arxiv.org/pdf/1311.3618.pdf">[PDF]</a><br>Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S. and Vedaldi, A., 2013. arXiv [cs.CV]. </li><li id="Bhushan_Rao_Lohse_1997"><span class="title">The texture lexicon: Understanding the categorization of visual texture terms and their relationship to texture images</span>   <a href="http://doi.wiley.com/10.1207/s15516709cog2102_4">[link]</a><br>Bhushan, N., Rao, A.R. and Lohse, G.L., 1997. Cognitive science, Vol 21(2), pp. 219–246. Wiley. <a href="https://doi.org/10.1207/s15516709cog2102_4" style="text-decoration:inherit;">DOI: 10.1207/s15516709cog2102_4</a></li><li id="Pezzulo_Levin_2015"><span class="title">Re-membering
 the body: applications of computational neuroscience to the top-down 
control of regeneration of limbs and other complex organs</span>   <a href="http://dx.doi.org/10.1039/c5ib00221d">[link]</a><br>Pezzulo, G. and Levin, M., 2015. Integrative biology: quantitative biosciences from nano to macro, Vol 7(12), pp. 1487–1517.  <a href="https://doi.org/10.1039/c5ib00221d" style="text-decoration:inherit;">DOI: 10.1039/c5ib00221d</a></li><li id="Speman_1938"><span class="title">Embryonic Development and Induction</span>   <a href="http://dx.doi.org/10.1097/00000441-193811000-00047">[link]</a><br>Speman, H., 1938. The American Journal of the Medical Sciences, Vol 196(5), pp. 738.  <a href="https://doi.org/10.1097/00000441-193811000-00047" style="text-decoration:inherit;">DOI: 10.1097/00000441-193811000-00047</a></li><li id="Grossberg_1978"><span class="title">Communication, Memory, and Development</span>   <a href="https://linkinghub.elsevier.com/retrieve/pii/B9780125431057500129">[link]</a><br>Grossberg, S., 1978. Progress in Theoretical Biology, pp. 183–232. Elsevier. <a href="https://doi.org/10.1016/b978-0-12-543105-7.50012-9" style="text-decoration:inherit;">DOI: 10.1016/b978-0-12-543105-7.50012-9</a></li><li id="Gumin"><span class="title">WaveFunctionCollapse</span>   <a href="https://github.com/mxgmn/WaveFunctionCollapse">[link]</a><br>Gumin, M.. Github.</li><li id="Ulyanov_Lebedev_Vedaldi_Lempitsky_2016"><span class="title">Texture Networks: Feed-forward Synthesis of Textures and Stylized Images</span>   <a href="http://arxiv.org/pdf/1603.03417.pdf">[PDF]</a><br>Ulyanov, D., Lebedev, V., Vedaldi, A. and Lempitsky, V., 2016. arXiv [cs.CV]. </li><li id="Xian_Sangkloy_Agrawal_Raj_Lu_Fang_Yu_Hays_2018"><span class="title">TextureGAN: Controlling deep image synthesis with texture patches</span>   <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.pdf">[PDF]</a><br>Xian,
 W., Sangkloy, P., Agrawal, V., Raj, A., Lu, J., Fang, C., Yu, F. and 
Hays, J., 2018. 2018 IEEE/CVF Conference on Computer Vision and Pattern 
Recognition. IEEE. <a href="https://doi.org/10.1109/cvpr.2018.00882" style="text-decoration:inherit;">DOI: 10.1109/cvpr.2018.00882</a></li><li id="Reynolds_2011"><span class="title">Interactive evolution of camouflage</span>   <a href="http://dx.doi.org/10.1162/artl_a_00023">[link]</a><br>Reynolds, C., 2011. Artificial life, Vol 17(2), pp. 123–136.  <a href="https://doi.org/10.1162/artl_a_00023" style="text-decoration:inherit;">DOI: 10.1162/artl_a_00023</a></li><li id="Portilla_Simoncelli_2000"><span class="title">A parametric texture model based on joint statistics of complex wavelet coefficients</span>   <a href="https://www.cns.nyu.edu/pub/eero/portilla99-reprint.pdf">[PDF]</a><br>Portilla, J. and Simoncelli, E.P., 2000. </li><li id="Chen_Pock_2017"><span class="title">Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration</span>   <a href="http://dx.doi.org/10.1109/TPAMI.2016.2596743">[link]</a><br>Chen, Y. and Pock, T., 2017. IEEE transactions on pattern analysis and machine intelligence, Vol 39(6), pp. 1256–1272.  <a href="https://doi.org/10.1109/TPAMI.2016.2596743" style="text-decoration:inherit;">DOI: 10.1109/TPAMI.2016.2596743</a></li><li id="Kodandaramaiah_2011"><span class="title">The evolutionary significance of butterfly eyespots</span>   <a href="https://www.researchgate.net/publication/227464385_The_evolutionary_significance_of_butterfly_eyespots">[link]</a><br>Kodandaramaiah,
 U., 2011. Behavioral ecology: official journal of the International 
Society for Behavioral Ecology, Vol 22(6), pp. 1264–1271. Oxford 
University Press (OUP). <a href="https://doi.org/10.1093/beheco/arr123" style="text-decoration:inherit;">DOI: 10.1093/beheco/arr123</a></li><li id="Ohno_Otaki_2015"><span class="title">Live Cell Imaging of Butterfly Pupal and Larval Wings In Vivo</span>   <a href="http://dx.doi.org/10.1371/journal.pone.0128332">[link]</a><br>Ohno, Y. and Otaki, J.M., 2015. PloS one, Vol 10(6), pp. e0128332.  <a href="https://doi.org/10.1371/journal.pone.0128332" style="text-decoration:inherit;">DOI: 10.1371/journal.pone.0128332</a></li><li id="Iwata_Otaki_2016"><span class="title">Focusing on butterfly eyespot focus: uncoupling of white spots from eyespot bodies in nymphalid butterflies</span>   <a href="http://dx.doi.org/10.1186/s40064-016-2969-8">[link]</a><br>Iwata, M. and Otaki, J.M., 2016. SpringerPlus, Vol 5(1), pp. 1287.  <a href="https://doi.org/10.1186/s40064-016-2969-8" style="text-decoration:inherit;">DOI: 10.1186/s40064-016-2969-8</a></li><li id="Schubert_Petrov_Carter_Cammarata_Goh_Olah_2020"><span class="title">OpenAI Microscope</span>   <a href="https://openai.com/blog/microscope/">[link]</a><br>Schubert, L., Petrov, M., Carter, S., Cammarata, N., Goh, G. and Olah, C., 2020. OpenAI.</li><li id="Boettiger_Ermentrout_Oster_2009"><span class="title">The neural origins of shell structure and pattern in aquatic mollusks</span>   <a href="http://dx.doi.org/10.1073/pnas.0810311106">[link]</a><br>Boettiger,
 A., Ermentrout, B. and Oster, G., 2009. Proceedings of the National 
Academy of Sciences of the United States of America, Vol 106(16), pp. 
6837–6842.  <a href="https://doi.org/10.1073/pnas.0810311106" style="text-decoration:inherit;">DOI: 10.1073/pnas.0810311106</a></li><li id="Boettiger_Oster_2009"><span class="title">Emergent complexity in simple neural systems</span>   <a href="http://dx.doi.org/10.4161/cib.2.6.9260">[link]</a><br>Boettiger, A.N. and Oster, G., 2009. Communicative &amp; integrative biology, Vol 2(6), pp. 467–470.  <a href="https://doi.org/10.4161/cib.2.6.9260" style="text-decoration:inherit;">DOI: 10.4161/cib.2.6.9260</a></li><li id="szegedy2015going"><span class="title">Going deeper with convolutions</span>   <a href="https://arxiv.org/pdf/1409.4842.pdf">[PDF]</a><br>Szegedy,
 C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., 
Vanhoucke, V. and Rabinovich, A., 2015. Proceedings of the IEEE 
conference on computer vision and pattern recognition, pp. 1--9. </li><li id="Risser_Wilmot_Barnes_2017"><span class="title">Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses</span>   <a href="http://arxiv.org/pdf/1701.08893.pdf">[PDF]</a><br>Risser, E., Wilmot, P. and Barnes, C., 2017. arXiv [cs.GR]. </li><li id="Hadden_Young_2017"><span class="title">Stem cell migration and mechanotransduction on linear stiffness gradient hydrogels</span>   <a href="http://dx.doi.org/10.1073/pnas.1618239114">[link]</a><br>Hadden,
 W.J., Young, J.L., Holle, A.W., McFetridge, M.L., Kim, D.Y., 
Wijesinghe, P., Taylor-Weiner, H., Wen, J.H., Lee, A.R., Bieback, K. and
 al., e., 2017. Proceedings of the National Academy of Sciences of the 
United States of America, Vol 114(22), pp. 5647–5652.  <a href="https://doi.org/10.1073/pnas.1618239114" style="text-decoration:inherit;">DOI: 10.1073/pnas.1618239114</a></li></ol></d-citation-list>
<d-appendix>
<style>

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

</style>


  <d-bibliography><script type="text/json">[["Bhushan_Rao_Lohse_1997",{"title":"The texture lexicon: Understanding the categorization of visual texture terms and their relationship to texture images","volume":"21","ISSN":"0364-0213","url":"http://doi.wiley.com/10.1207/s15516709cog2102_4","DOI":"10.1207/s15516709cog2102_4","abstractNote":"In this paper we present the results of two experiments. The first is on the categorization of texture words in the English language. The goal was to determine whether there is a common basis for subjects’ groupings of words related to visual texture, and if so, to identify the underlying dimensions used to categorize those words. Eleven major clusters were identified through hierarchical cluster analysis, ranging from ?random? to ?repetitive?. These clusters remained intact in a multidimensional scaling solution. The stress for a three-dimensional solution obtained through multidimensional scaling was 0.18, meaning that 82% of the variance in the data is explained through the use of three dimensions. It appears that the major dimensions of texture descriptors are repetitive versus nonrepetitive; linearly oriented versus circularly oriented; and simple versus complex. In the second experiment we measured the strength of association between texture words and texture images. The goal was to determine whether there is any systematic correspondence between the domains of texture words and texture images. Pearson's coefficient of contingency, a measure of the strength of association, was found to be 0.63 for words corresponding to given images and 0.56 for images corresponding to given words. Thus the texture categories in the verbal space and those in the visual space are strongly tied. In sum, our two experiments show (a) that despite the tremendous variety in the words we have to describe textures, there is an underlying structure to the lexical space which can be derived from the experimental data; and (b) that the association between a category of words and a category of images was strongest when both categories represent the same underlying property. This suggests that subjects' organizations of texture terms are systematically tied to their organization of texture images.","number":"2","journal":"Cognitive science","publisher":"Wiley","author":"Bhushan, Nalini and Rao, A. Ravishankar and Lohse, Gerald L.","year":"1997","month":"Apr","pages":"219–246","issn":"0364-0213","doi":"10.1207/s15516709cog2102_4","abstractnote":"In this paper we present the results of two experiments. The first is on the categorization of texture words in the English language. The goal was to determine whether there is a common basis for subjects’ groupings of words related to visual texture, and if so, to identify the underlying dimensions used to categorize those words. Eleven major clusters were identified through hierarchical cluster analysis, ranging from ?random? to ?repetitive?. These clusters remained intact in a multidimensional scaling solution. The stress for a three-dimensional solution obtained through multidimensional scaling was 0.18, meaning that 82% of the variance in the data is explained through the use of three dimensions. It appears that the major dimensions of texture descriptors are repetitive versus nonrepetitive; linearly oriented versus circularly oriented; and simple versus complex. In the second experiment we measured the strength of association between texture words and texture images. The goal was to determine whether there is any systematic correspondence between the domains of texture words and texture images. Pearson's coefficient of contingency, a measure of the strength of association, was found to be 0.63 for words corresponding to given images and 0.56 for images corresponding to given words. Thus the texture categories in the verbal space and those in the visual space are strongly tied. In sum, our two experiments show (a) that despite the tremendous variety in the words we have to describe textures, there is an underlying structure to the lexical space which can be derived from the experimental data; and (b) that the association between a category of words and a category of images was strongest when both categories represent the same underlying property. This suggests that subjects' organizations of texture terms are systematically tied to their organization of texture images.","type":"article"}],["Brodsky",{"title":"Turing-like patterns can arise from purely bioelectric mechanisms","url":"http://dx.doi.org/10.1101/336461","DOI":"10.1101/336461","journal":"Draft","author":"Brodsky, Micah","doi":"10.1101/336461","type":"article"}],["Chen_Pock_2017",{"title":"Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration","volume":"39","ISSN":"0162-8828","url":"http://dx.doi.org/10.1109/TPAMI.2016.2596743","DOI":"10.1109/TPAMI.2016.2596743","abstractNote":"Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (i.e., linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD-Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.","number":"6","journal":"IEEE transactions on pattern analysis and machine intelligence","author":"Chen, Yunjin and Pock, Thomas","year":"2017","month":"Jun","pages":"1256–1272","issn":"0162-8828","doi":"10.1109/TPAMI.2016.2596743","abstractnote":"Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (i.e., linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD-Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.","type":"article"}],["Cimpoi_Maji_Kokkinos_Mohamed_Vedaldi_2013",{"title":"Describing Textures in the Wild","url":"http://arxiv.org/abs/1311.3618","abstractNote":"Patterns and textures are defining characteristics of many natural objects: a shirt can be striped, the wings of a butterfly can be veined, and the skin of an animal can be scaly. Aiming at supporting this analytical dimension in image understanding, we address the challenging problem of describing textures with semantic attributes. We identify a rich vocabulary of forty-seven texture terms and use them to describe a large dataset of patterns collected in the wild.The resulting Describable Textures Dataset (DTD) is the basis to seek for the best texture representation for recognizing describable texture attributes in images. We port from object recognition to texture recognition the Improved Fisher Vector (IFV) and show that, surprisingly, it outperforms specialized texture descriptors not only on our problem, but also in established material recognition datasets. We also show that the describable attributes are excellent texture descriptors, transferring between datasets and tasks; in particular, combined with IFV, they significantly outperform the state-of-the-art by more than 8 percent on both FMD and KTHTIPS-2b benchmarks. We also demonstrate that they produce intuitive descriptions of materials and Internet images.","journal":"arXiv [cs.CV]","author":"Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea","year":"2013","month":"Nov","abstractnote":"Patterns and textures are defining characteristics of many natural objects: a shirt can be striped, the wings of a butterfly can be veined, and the skin of an animal can be scaly. Aiming at supporting this analytical dimension in image understanding, we address the challenging problem of describing textures with semantic attributes. We identify a rich vocabulary of forty-seven texture terms and use them to describe a large dataset of patterns collected in the wild.The resulting Describable Textures Dataset (DTD) is the basis to seek for the best texture representation for recognizing describable texture attributes in images. We port from object recognition to texture recognition the Improved Fisher Vector (IFV) and show that, surprisingly, it outperforms specialized texture descriptors not only on our problem, but also in established material recognition datasets. We also show that the describable attributes are excellent texture descriptors, transferring between datasets and tasks; in particular, combined with IFV, they significantly outperform the state-of-the-art by more than 8 percent on both FMD and KTHTIPS-2b benchmarks. We also demonstrate that they produce intuitive descriptions of materials and Internet images.","type":"unpublished"}],["Gatys_Ecker_Bethge_2015",{"title":"Texture Synthesis Using Convolutional Neural Networks","url":"http://arxiv.org/abs/1505.07376","abstractNote":"Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.","journal":"arXiv [cs.CV]","author":"Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias","year":"2015","month":"May","abstractnote":"Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.","type":"unpublished"}],["Goldbeter_2018",{"title":"Dissipative structures in biological systems: bistability, oscillations, spatial patterns and waves","volume":"376","ISSN":"1364-503X","url":"http://dx.doi.org/10.1098/rsta.2017.0376","DOI":"10.1098/rsta.2017.0376","abstractNote":"The goal of this review article is to assess how relevant is the concept of dissipative structure for understanding the dynamical bases of non-equilibrium self-organization in biological systems, and to see where it has been applied in the five decades since it was initially proposed by Ilya Prigogine. Dissipative structures can be classified into four types, which will be considered, in turn, and illustrated by biological examples: (i) multistability, in the form of bistability and tristability, which involve the coexistence of two or three stable steady states, or in the form of birhythmicity, which involves the coexistence between two stable rhythms; (ii) temporal dissipative structures in the form of sustained oscillations, illustrated by biological rhythms; (iii) spatial dissipative structures, known as Turing patterns; and (iv) spatio-temporal structures in the form of propagating waves. Rhythms occur with widely different periods at all levels of biological organization, from neural, cardiac and metabolic oscillations to circadian clocks and the cell cycle; they play key roles in physiology and in many disorders. New rhythms are being uncovered while artificial ones are produced by synthetic biology. Rhythms provide the richest source of examples of dissipative structures in biological systems. Bistability has been observed experimentally, but has primarily been investigated in theoretical models in an increasingly wide range of biological contexts, from the genetic to the cell and animal population levels, both in physiological conditions and in disease. Bistable transitions have been implicated in the progression between the different phases of the cell cycle and, more generally, in the process of cell fate specification in the developing embryo. Turing patterns are exemplified by the formation of some periodic structures in the course of development and by skin stripe patterns in animals. Spatio-temporal patterns in the form of propagating waves are observed within cells as well as in intercellular communication. This review illustrates how dissipative structures of all sorts abound in biological systems.This article is part of the theme issue “Dissipative structures in matter out of equilibrium: from chemistry, photonics and biology (part 1)”.","number":"2124","journal":"Philosophical transactions. Series A, Mathematical, physical, and engineering sciences","author":"Goldbeter, Albert","year":"2018","month":"Jul","issn":"1364-503X","doi":"10.1098/rsta.2017.0376","abstractnote":"The goal of this review article is to assess how relevant is the concept of dissipative structure for understanding the dynamical bases of non-equilibrium self-organization in biological systems, and to see where it has been applied in the five decades since it was initially proposed by Ilya Prigogine. Dissipative structures can be classified into four types, which will be considered, in turn, and illustrated by biological examples: (i) multistability, in the form of bistability and tristability, which involve the coexistence of two or three stable steady states, or in the form of birhythmicity, which involves the coexistence between two stable rhythms; (ii) temporal dissipative structures in the form of sustained oscillations, illustrated by biological rhythms; (iii) spatial dissipative structures, known as Turing patterns; and (iv) spatio-temporal structures in the form of propagating waves. Rhythms occur with widely different periods at all levels of biological organization, from neural, cardiac and metabolic oscillations to circadian clocks and the cell cycle; they play key roles in physiology and in many disorders. New rhythms are being uncovered while artificial ones are produced by synthetic biology. Rhythms provide the richest source of examples of dissipative structures in biological systems. Bistability has been observed experimentally, but has primarily been investigated in theoretical models in an increasingly wide range of biological contexts, from the genetic to the cell and animal population levels, both in physiological conditions and in disease. Bistable transitions have been implicated in the progression between the different phases of the cell cycle and, more generally, in the process of cell fate specification in the developing embryo. Turing patterns are exemplified by the formation of some periodic structures in the course of development and by skin stripe patterns in animals. Spatio-temporal patterns in the form of propagating waves are observed within cells as well as in intercellular communication. This review illustrates how dissipative structures of all sorts abound in biological systems.This article is part of the theme issue “Dissipative structures in matter out of equilibrium: from chemistry, photonics and biology (part 1)”.","type":"article"}],["Grossberg_1978",{"title":"Communication, Memory, and Development","ISBN":"9780125431057","url":"https://linkinghub.elsevier.com/retrieve/pii/B9780125431057500129","DOI":"10.1016/b978-0-12-543105-7.50012-9","abstractNote":"Semantic Scholar extracted view of “Communication, Memory, and Development” by S. Grossberg","booktitle":"Progress in Theoretical Biology","publisher":"Elsevier","author":"Grossberg, Stephen","year":"1978","pages":"183–232","isbn":"9780125431057","doi":"10.1016/b978-0-12-543105-7.50012-9","abstractnote":"Semantic Scholar extracted view of “Communication, Memory, and Development” by S. Grossberg","type":"inbook"}],["Gumin",{"title":"WaveFunctionCollapse","url":"https://github.com/mxgmn/WaveFunctionCollapse","abstractNote":"Bitmap & tilemap generation from a single example with the help of ideas from quantum mechanics - mxgmn/WaveFunctionCollapse","publisher":"Github","author":"Gumin, Maxim","abstractnote":"Bitmap & tilemap generation from a single example with the help of ideas from quantum mechanics - mxgmn/WaveFunctionCollapse","type":"book"}],["Hadden_Young_2017",{"title":"Stem cell migration and mechanotransduction on linear stiffness gradient hydrogels","volume":"114","ISSN":"0027-8424","url":"http://dx.doi.org/10.1073/pnas.1618239114","DOI":"10.1073/pnas.1618239114","abstractNote":"The spatial presentation of mechanical information is a key parameter for cell behavior. We have developed a method of polymerization control in which the differential diffusion distance of unreacted cross-linker and monomer into a prepolymerized hydrogel sink results in a tunable stiffness gradient at the cell-matrix interface. This simple, low-cost, robust method was used to produce polyacrylamide hydrogels with stiffness gradients of 0.5, 1.7, 2.9, 4.5, 6.8, and 8.2 kPa/mm, spanning the in vivo physiological and pathological mechanical landscape. Importantly, three of these gradients were found to be nondurotactic for human adipose-derived stem cells (hASCs), allowing the presentation of a continuous range of stiffnesses in a single well without the confounding effect of differential cell migration. Using these nondurotactic gradient gels, stiffness-dependent hASC morphology, migration, and differentiation were studied. Finally, the mechanosensitive proteins YAP, Lamin A/C, Lamin B, MRTF-A, and MRTF-B were analyzed on these gradients, providing higher-resolution data on stiffness-dependent expression and localization.","number":"22","journal":"Proceedings of the National Academy of Sciences of the United States of America","author":"Hadden, William J. and Young, Jennifer L. and Holle, Andrew W. and McFetridge, Meg L. and Kim, Du Yong and Wijesinghe, Philip and Taylor-Weiner, Hermes and Wen, Jessica H. and Lee, Andrew R. and Bieback, Karen and et al.","year":"2017","month":"May","pages":"5647–5652","issn":"0027-8424","doi":"10.1073/pnas.1618239114","abstractnote":"The spatial presentation of mechanical information is a key parameter for cell behavior. We have developed a method of polymerization control in which the differential diffusion distance of unreacted cross-linker and monomer into a prepolymerized hydrogel sink results in a tunable stiffness gradient at the cell-matrix interface. This simple, low-cost, robust method was used to produce polyacrylamide hydrogels with stiffness gradients of 0.5, 1.7, 2.9, 4.5, 6.8, and 8.2 kPa/mm, spanning the in vivo physiological and pathological mechanical landscape. Importantly, three of these gradients were found to be nondurotactic for human adipose-derived stem cells (hASCs), allowing the presentation of a continuous range of stiffnesses in a single well without the confounding effect of differential cell migration. Using these nondurotactic gradient gels, stiffness-dependent hASC morphology, migration, and differentiation were studied. Finally, the mechanosensitive proteins YAP, Lamin A/C, Lamin B, MRTF-A, and MRTF-B were analyzed on these gradients, providing higher-resolution data on stiffness-dependent expression and localization.","type":"article"}],["Hiscock_Tschopp_Tabin_2017",{"title":"On the Formation of Digits and Joints during Limb Development","volume":"41","ISSN":"1534-5807","url":"http://dx.doi.org/10.1016/j.devcel.2017.04.021","DOI":"10.1016/j.devcel.2017.04.021","abstractNote":"Critical steps in forming the vertebrate limb include the positioning of digits and the positioning of joints within each digit. Recent studies have proposed that the iterative series of digits is established by a Turing-like mechanism generating stripes of chondrogenic domains. However, re-examination of available data suggest that digits are actually patterned as evenly spaced spots, not stripes, which then elongate into rod-shaped digit rays by incorporating new cells at their tips. Moreover, extension of the digit rays and the patterning of the joints occur simultaneously at the distal tip, implying that an integrated model is required to fully understand these processes.","number":"5","journal":"Developmental cell","author":"Hiscock, Tom W. and Tschopp, Patrick and Tabin, Clifford J.","year":"2017","month":"Jun","pages":"459–465","issn":"1534-5807","doi":"10.1016/j.devcel.2017.04.021","abstractnote":"Critical steps in forming the vertebrate limb include the positioning of digits and the positioning of joints within each digit. Recent studies have proposed that the iterative series of digits is established by a Turing-like mechanism generating stripes of chondrogenic domains. However, re-examination of available data suggest that digits are actually patterned as evenly spaced spots, not stripes, which then elongate into rod-shaped digit rays by incorporating new cells at their tips. Moreover, extension of the digit rays and the patterning of the joints occur simultaneously at the distal tip, implying that an integrated model is required to fully understand these processes.","type":"article"}],["Isalan_2009",{"title":"Gene networks and liar paradoxes","volume":"31","ISSN":"0265-9247","url":"http://dx.doi.org/10.1002/bies.200900072","DOI":"10.1002/bies.200900072","abstractNote":"Network motifs are small patterns of connections, found over-represented in gene regulatory networks. An example is the negative feedback loop (e.g. factor A represses itself). This opposes its own state so that when “on” it tends towards “off” - and vice versa. Here, we argue that such self-opposition, if considered dimensionlessly, is analogous to the liar paradox: “This statement is false”. When “true” it implies “false” - and vice versa. Such logical constructs have provided philosophical consternation for over 2000 years. Extending the analogy, other network topologies give strikingly varying outputs over different dimensions. For example, the motif “A activates B and A. B inhibits A” can give switches or oscillators with time only, or can lead to Turing-type patterns with both space and time (spots, stripes or waves). It is argued here that the dimensionless form reduces to a variant of “The following statement is true. The preceding statement is false”. Thus, merely having a static topological description of a gene network can lead to a liar paradox. Network diagrams are only snapshots of dynamic biological processes and apparent paradoxes can reveal important biological mechanisms that are far from paradoxical when considered explicitly in time and space.","number":"10","journal":"BioEssays: news and reviews in molecular, cellular and developmental biology","author":"Isalan, Mark","year":"2009","month":"Oct","pages":"1110–1115","issn":"0265-9247","doi":"10.1002/bies.200900072","abstractnote":"Network motifs are small patterns of connections, found over-represented in gene regulatory networks. An example is the negative feedback loop (e.g. factor A represses itself). This opposes its own state so that when “on” it tends towards “off” - and vice versa. Here, we argue that such self-opposition, if considered dimensionlessly, is analogous to the liar paradox: “This statement is false”. When “true” it implies “false” - and vice versa. Such logical constructs have provided philosophical consternation for over 2000 years. Extending the analogy, other network topologies give strikingly varying outputs over different dimensions. For example, the motif “A activates B and A. B inhibits A” can give switches or oscillators with time only, or can lead to Turing-type patterns with both space and time (spots, stripes or waves). It is argued here that the dimensionless form reduces to a variant of “The following statement is true. The preceding statement is false”. Thus, merely having a static topological description of a gene network can lead to a liar paradox. Network diagrams are only snapshots of dynamic biological processes and apparent paradoxes can reveal important biological mechanisms that are far from paradoxical when considered explicitly in time and space.","type":"article"}],["Iwata_Otaki_2016",{"title":"Focusing on butterfly eyespot focus: uncoupling of white spots from eyespot bodies in nymphalid butterflies","volume":"5","ISSN":"2193-1801","url":"http://dx.doi.org/10.1186/s40064-016-2969-8","DOI":"10.1186/s40064-016-2969-8","abstractNote":"BACKGROUND: Developmental studies on butterfly wing color patterns often focus on eyespots. A typical eyespot (such as that of Bicyclus anynana) has a few concentric rings of dark and light colors and a white spot (called a focus) at the center. The prospective eyespot center during the early pupal stage is known to act as an organizing center. It has often been assumed, according to gradient models for positional information, that a white spot in adult wings corresponds to an organizing center and that the size of the white spot indicates how active that organizing center was. However, there is no supporting evidence for these assumptions. To evaluate the feasibility of these assumptions in nymphalid butterflies, we studied the unique color patterns of Calisto tasajera (Nymphalidae, Satyrinae), which have not been analyzed before in the literature. RESULTS: In the anterior forewing, one white spot was located at the center of an eyespot, but another white spot associated with either no or only a small eyespot was present in the adjacent compartment. The anterior hindwing contained two adjacent white spots not associated with eyespots, one of which showed a sparse pattern. The posterior hindwing contained two adjacent pear-shaped eyespots, and the white spots were located at the proximal side or even outside the eyespot bodies. The successive white spots within a single compartment along the midline in the posterior hindwing showed a possible trajectory of a positional determination process for the white spots. Several cases of focus-less eyespots in other nymphalid butterflies were also presented. CONCLUSIONS: These results argue for the uncoupling of white spots from eyespot bodies, suggesting that an eyespot organizing center does not necessarily differentiate into a white spot and that a prospective white spot does not necessarily signify organizing activity for an eyespot. Incorporation of these results in future models for butterfly wing color pattern formation is encouraged.","number":"1","journal":"SpringerPlus","author":"Iwata, Masaki and Otaki, Joji M.","year":"2016","month":"Aug","pages":"1287","issn":"2193-1801","doi":"10.1186/s40064-016-2969-8","abstractnote":"BACKGROUND: Developmental studies on butterfly wing color patterns often focus on eyespots. A typical eyespot (such as that of Bicyclus anynana) has a few concentric rings of dark and light colors and a white spot (called a focus) at the center. The prospective eyespot center during the early pupal stage is known to act as an organizing center. It has often been assumed, according to gradient models for positional information, that a white spot in adult wings corresponds to an organizing center and that the size of the white spot indicates how active that organizing center was. However, there is no supporting evidence for these assumptions. To evaluate the feasibility of these assumptions in nymphalid butterflies, we studied the unique color patterns of Calisto tasajera (Nymphalidae, Satyrinae), which have not been analyzed before in the literature. RESULTS: In the anterior forewing, one white spot was located at the center of an eyespot, but another white spot associated with either no or only a small eyespot was present in the adjacent compartment. The anterior hindwing contained two adjacent white spots not associated with eyespots, one of which showed a sparse pattern. The posterior hindwing contained two adjacent pear-shaped eyespots, and the white spots were located at the proximal side or even outside the eyespot bodies. The successive white spots within a single compartment along the midline in the posterior hindwing showed a possible trajectory of a positional determination process for the white spots. Several cases of focus-less eyespots in other nymphalid butterflies were also presented. CONCLUSIONS: These results argue for the uncoupling of white spots from eyespot bodies, suggesting that an eyespot organizing center does not necessarily differentiate into a white spot and that a prospective white spot does not necessarily signify organizing activity for an eyespot. Incorporation of these results in future models for butterfly wing color pattern formation is encouraged.","type":"article"}],["Kingma_Ba_2014",{"title":"Adam: A Method for Stochastic Optimization","url":"http://arxiv.org/abs/1412.6980","abstractNote":"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.","journal":"arXiv [cs.LG]","author":"Kingma, Diederik P. and Ba, Jimmy","year":"2014","month":"Dec","abstractnote":"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.","type":"unpublished"}],["Kodandaramaiah_2011",{"title":"The evolutionary significance of butterfly eyespots","volume":"22","ISSN":"1045-2249","url":"https://www.researchgate.net/publication/227464385_The_evolutionary_significance_of_butterfly_eyespots","DOI":"10.1093/beheco/arr123","abstractNote":"Download Citation | The evolutionary significance of butterfly eyespots | Numerous butterflies have circular patterns called eyespots on their wings. Explanations for their functional value have until recently remained... | Find, read and cite all the research you need on ResearchGate","number":"6","journal":"Behavioral ecology: official journal of the International Society for Behavioral Ecology","publisher":"Oxford University Press (OUP)","author":"Kodandaramaiah, Ullasa","year":"2011","month":"Oct","pages":"1264–1271","issn":"1045-2249","doi":"10.1093/beheco/arr123","abstractnote":"Download Citation | The evolutionary significance of butterfly eyespots | Numerous butterflies have circular patterns called eyespots on their wings. Explanations for their functional value have until recently remained... | Find, read and cite all the research you need on ResearchGate","type":"article"}],["Landge_Jordan_Diego_Müller_2020",{"title":"Pattern formation mechanisms of self-organizing reaction-diffusion systems","volume":"460","ISSN":"0012-1606","url":"http://dx.doi.org/10.1016/j.ydbio.2019.10.031","DOI":"10.1016/j.ydbio.2019.10.031","abstractNote":"Embryonic development is a largely self-organizing process, in which the adult body plan arises from a ball of cells with initially nearly equal potency. The reaction-diffusion theory first proposed by Alan Turing states that the initial symmetry in embryos can be broken by the interplay between two diffusible molecules, whose interactions lead to the formation of patterns. The reaction-diffusion theory provides a valuable framework for self-organized pattern formation, but it has been difficult to relate simple two-component models to real biological systems with multiple interacting molecular species. Recent studies have addressed this shortcoming and extended the reaction-diffusion theory to realistic multi-component networks. These efforts have challenged the generality of previous central tenets derived from the analysis of simplified systems and guide the way to a new understanding of self-organizing processes. Here, we discuss the challenges in modeling multi-component reaction-diffusion systems and how these have recently been addressed. We present a synthesis of new pattern formation mechanisms derived from these analyses, and we highlight the significance of reaction-diffusion principles for developmental and synthetic pattern formation.","number":"1","journal":"Developmental biology","author":"Landge, Amit N. and Jordan, Benjamin M. and Diego, Xavier and Müller, Patrick","year":"2020","month":"Apr","pages":"2–11","issn":"0012-1606","doi":"10.1016/j.ydbio.2019.10.031","abstractnote":"Embryonic development is a largely self-organizing process, in which the adult body plan arises from a ball of cells with initially nearly equal potency. The reaction-diffusion theory first proposed by Alan Turing states that the initial symmetry in embryos can be broken by the interplay between two diffusible molecules, whose interactions lead to the formation of patterns. The reaction-diffusion theory provides a valuable framework for self-organized pattern formation, but it has been difficult to relate simple two-component models to real biological systems with multiple interacting molecular species. Recent studies have addressed this shortcoming and extended the reaction-diffusion theory to realistic multi-component networks. These efforts have challenged the generality of previous central tenets derived from the analysis of simplified systems and guide the way to a new understanding of self-organizing processes. Here, we discuss the challenges in modeling multi-component reaction-diffusion systems and how these have recently been addressed. We present a synthesis of new pattern formation mechanisms derived from these analyses, and we highlight the significance of reaction-diffusion principles for developmental and synthetic pattern formation.","type":"article"}],["Lee_McCormick_Ouyang_Swinney_1993",{"title":"Pattern formation by interacting chemical fronts","volume":"261","ISSN":"0036-8075","url":"http://dx.doi.org/10.1126/science.261.5118.192","DOI":"10.1126/science.261.5118.192","abstractNote":"Experiments on a bistable chemical reaction in a continuously fed thin gel layer reveal a new type of spatiotemporal pattern, one in which fronts propagate at a constant speed until they reach a critical separation (typically 0.4 millimeter) and stop. The resulting asymptotic state is a highly irregular stationary pattern that contrasts with the regular patterns such as hexagons, squares, and stripes that have been observed in many nonequilibrium systems. The observed patterns are initiated by a finite amplitude perturbation rather than through spontaneous symmetry breaking.","number":"5118","journal":"Science","author":"Lee, K. J. and McCormick, W. D. and Ouyang, Q. and Swinney, H. L.","year":"1993","month":"Jul","pages":"192–194","issn":"0036-8075","doi":"10.1126/science.261.5118.192","abstractnote":"Experiments on a bistable chemical reaction in a continuously fed thin gel layer reveal a new type of spatiotemporal pattern, one in which fronts propagate at a constant speed until they reach a critical separation (typically 0.4 millimeter) and stop. The resulting asymptotic state is a highly irregular stationary pattern that contrasts with the regular patterns such as hexagons, squares, and stripes that have been observed in many nonequilibrium systems. The observed patterns are initiated by a finite amplitude perturbation rather than through spontaneous symmetry breaking.","type":"article"}],["Marcon_Sharpe_2012",{"title":"Turing patterns in development: what about the horse part?","volume":"22","ISSN":"0959-437X","url":"http://dx.doi.org/10.1016/j.gde.2012.11.013","DOI":"10.1016/j.gde.2012.11.013","abstractNote":"For many years Turing patterns-the repetitive patterns which Alan Turing proved could arise from simple diffusing and interacting factors-have remained an interesting theoretical possibility, rather than a central concern of the developmental biology community. Recently however, this has started to change, with an increasing number of studies combining both experimental and theoretical work to reveal how Turing models may underlie a variety of patterning or morphogenetic processes. We review here the recent developments in this field across a wide range of model systems.","number":"6","journal":"Current opinion in genetics & development","author":"Marcon, Luciano and Sharpe, James","year":"2012","month":"Dec","pages":"578–584","issn":"0959-437X","doi":"10.1016/j.gde.2012.11.013","abstractnote":"For many years Turing patterns-the repetitive patterns which Alan Turing proved could arise from simple diffusing and interacting factors-have remained an interesting theoretical possibility, rather than a central concern of the developmental biology community. Recently however, this has started to change, with an increasing number of studies combining both experimental and theoretical work to reveal how Turing models may underlie a variety of patterning or morphogenetic processes. We review here the recent developments in this field across a wide range of model systems.","type":"article"}],["Mordvintsev_Pezzotti_Schubert_Olah_2018",{"title":"Differentiable Image Parameterizations","volume":"3","ISSN":"2476-0757","url":"https://distill.pub/2018/differentiable-parameterizations","DOI":"10.23915/distill.00012","number":"7","journal":"Distill","author":"Mordvintsev, Alexander and Pezzotti, Nicola and Schubert, Ludwig and Olah, Chris","year":"2018","month":"Jul","issn":"2476-0757","doi":"10.23915/distill.00012","type":"article"}],["Mordvintsev_Randazzo_Niklasson_Levin_2020",{"title":"Growing Neural Cellular Automata","volume":"5","ISSN":"2476-0757","url":"https://distill.pub/2020/growing-ca","DOI":"10.23915/distill.00023","number":"2","journal":"Distill","author":"Mordvintsev, Alexander and Randazzo, Ettore and Niklasson, Eyvind and Levin, Michael","year":"2020","month":"Feb","pages":"e23","issn":"2476-0757","doi":"10.23915/distill.00023","type":"article"}],["Ohno_Otaki_2015",{"title":"Live Cell Imaging of Butterfly Pupal and Larval Wings In Vivo","volume":"10","ISSN":"1932-6203","url":"http://dx.doi.org/10.1371/journal.pone.0128332","DOI":"10.1371/journal.pone.0128332","abstractNote":"Butterfly wing color patterns are determined during the late larval and early pupal stages. Characterization of wing epithelial cells at these stages is thus critical to understand how wing structures, including color patterns, are determined. Previously, we successfully recorded real-time in vivo images of developing butterfly wings over time at the tissue level. In this study, we employed similar in vivo fluorescent imaging techniques to visualize developing wing epithelial cells in the late larval and early pupal stages 1 hour post-pupation. Both larval and pupal epithelial cells were rich in mitochondria and intracellular networks of endoplasmic reticulum, suggesting high metabolic activities, likely in preparation for cellular division, polyploidization, and differentiation. Larval epithelial cells in the wing imaginal disk were relatively large horizontally and tightly packed, whereas pupal epithelial cells were smaller and relatively loosely packed. Furthermore, larval cells were flat, whereas pupal cells were vertically elongated as deep as 130 μm. In pupal cells, many endosome-like or autophagosome-like structures were present in the cellular periphery down to approximately 10 μm in depth, and extensive epidermal feet or filopodia-like processes were observed a few micrometers deep from the cellular surface. Cells were clustered or bundled from approximately 50 μm in depth to deeper levels. From 60 μm to 80 μm in depth, horizontal connections between these clusters were observed. The prospective eyespot and marginal focus areas were resistant to fluorescent dyes, likely because of their non-flat cone-like structures with a relatively thick cuticle. These in vivo images provide important information with which to understand processes of epithelial cell differentiation and color pattern determination in butterfly wings.","number":"6","journal":"PloS one","author":"Ohno, Yoshikazu and Otaki, Joji M.","year":"2015","month":"Jun","pages":"e0128332","issn":"1932-6203","doi":"10.1371/journal.pone.0128332","abstractnote":"Butterfly wing color patterns are determined during the late larval and early pupal stages. Characterization of wing epithelial cells at these stages is thus critical to understand how wing structures, including color patterns, are determined. Previously, we successfully recorded real-time in vivo images of developing butterfly wings over time at the tissue level. In this study, we employed similar in vivo fluorescent imaging techniques to visualize developing wing epithelial cells in the late larval and early pupal stages 1 hour post-pupation. Both larval and pupal epithelial cells were rich in mitochondria and intracellular networks of endoplasmic reticulum, suggesting high metabolic activities, likely in preparation for cellular division, polyploidization, and differentiation. Larval epithelial cells in the wing imaginal disk were relatively large horizontally and tightly packed, whereas pupal epithelial cells were smaller and relatively loosely packed. Furthermore, larval cells were flat, whereas pupal cells were vertically elongated as deep as 130 μm. In pupal cells, many endosome-like or autophagosome-like structures were present in the cellular periphery down to approximately 10 μm in depth, and extensive epidermal feet or filopodia-like processes were observed a few micrometers deep from the cellular surface. Cells were clustered or bundled from approximately 50 μm in depth to deeper levels. From 60 μm to 80 μm in depth, horizontal connections between these clusters were observed. The prospective eyespot and marginal focus areas were resistant to fluorescent dyes, likely because of their non-flat cone-like structures with a relatively thick cuticle. These in vivo images provide important information with which to understand processes of epithelial cell differentiation and color pattern determination in butterfly wings.","type":"article"}],["Pearson_1993",{"title":"Complex patterns in a simple system","volume":"261","ISSN":"0036-8075","url":"http://dx.doi.org/10.1126/science.261.5118.189","DOI":"10.1126/science.261.5118.189","abstractNote":"Numerical simulations of a simple reaction-diffusion model reveal a surprising variety of irregular spatiotemporal patterns. These patterns arise in response to finite-amplitude perturbations. Some of them resemble the steady irregular patterns recently observed in thin gel reactor experiments. Others consist of spots that grow until they reach a critical size, at which time they divide in two. If in some region the spots become overcrowded, all of the spots in that region decay into the uniform background.","number":"5118","journal":"Science","author":"Pearson, J. E.","year":"1993","month":"Jul","pages":"189–192","issn":"0036-8075","doi":"10.1126/science.261.5118.189","abstractnote":"Numerical simulations of a simple reaction-diffusion model reveal a surprising variety of irregular spatiotemporal patterns. These patterns arise in response to finite-amplitude perturbations. Some of them resemble the steady irregular patterns recently observed in thin gel reactor experiments. Others consist of spots that grow until they reach a critical size, at which time they divide in two. If in some region the spots become overcrowded, all of the spots in that region decay into the uniform background.","type":"article"}],["Pezzulo_Levin_2015",{"title":"Re-membering the body: applications of computational neuroscience to the top-down control of regeneration of limbs and other complex organs","volume":"7","ISSN":"1757-9694","url":"http://dx.doi.org/10.1039/c5ib00221d","DOI":"10.1039/c5ib00221d","abstractNote":"A major goal of regenerative medicine and bioengineering is the regeneration of complex organs, such as limbs, and the capability to create artificial constructs (so-called biobots) with defined morphologies and robust self-repair capabilities. Developmental biology presents remarkable examples of systems that self-assemble and regenerate complex structures toward their correct shape despite significant perturbations. A fundamental challenge is to translate progress in molecular genetics into control of large-scale organismal anatomy, and the field is still searching for an appropriate theoretical paradigm for facilitating control of pattern homeostasis. However, computational neuroscience provides many examples in which cell networks - brains - store memories (e.g., of geometric configurations, rules, and patterns) and coordinate their activity towards proximal and distant goals. In this Perspective, we propose that programming large-scale morphogenesis requires exploiting the information processing by which cellular structures work toward specific shapes. In non-neural cells, as in the brain, bioelectric signaling implements information processing, decision-making, and memory in regulating pattern and its remodeling. Thus, approaches used in computational neuroscience to understand goal-seeking neural systems offer a toolbox of techniques to model and control regenerative pattern formation. Here, we review recent data on developmental bioelectricity as a regulator of patterning, and propose that target morphology could be encoded within tissues as a kind of memory, using the same molecular mechanisms and algorithms so successfully exploited by the brain. We highlight the next steps of an unconventional research program, which may allow top-down control of growth and form for numerous applications in regenerative medicine and synthetic bioengineering.","number":"12","journal":"Integrative biology: quantitative biosciences from nano to macro","author":"Pezzulo, G. and Levin, M.","year":"2015","month":"Dec","pages":"1487–1517","issn":"1757-9694","doi":"10.1039/c5ib00221d","abstractnote":"A major goal of regenerative medicine and bioengineering is the regeneration of complex organs, such as limbs, and the capability to create artificial constructs (so-called biobots) with defined morphologies and robust self-repair capabilities. Developmental biology presents remarkable examples of systems that self-assemble and regenerate complex structures toward their correct shape despite significant perturbations. A fundamental challenge is to translate progress in molecular genetics into control of large-scale organismal anatomy, and the field is still searching for an appropriate theoretical paradigm for facilitating control of pattern homeostasis. However, computational neuroscience provides many examples in which cell networks - brains - store memories (e.g., of geometric configurations, rules, and patterns) and coordinate their activity towards proximal and distant goals. In this Perspective, we propose that programming large-scale morphogenesis requires exploiting the information processing by which cellular structures work toward specific shapes. In non-neural cells, as in the brain, bioelectric signaling implements information processing, decision-making, and memory in regulating pattern and its remodeling. Thus, approaches used in computational neuroscience to understand goal-seeking neural systems offer a toolbox of techniques to model and control regenerative pattern formation. Here, we review recent data on developmental bioelectricity as a regulator of patterning, and propose that target morphology could be encoded within tissues as a kind of memory, using the same molecular mechanisms and algorithms so successfully exploited by the brain. We highlight the next steps of an unconventional research program, which may allow top-down control of growth and form for numerous applications in regenerative medicine and synthetic bioengineering.","type":"article"}],["Pietak_Levin_2017",{"title":"Bioelectric gene and reaction networks: computational modelling of genetic, biochemical and bioelectrical dynamics in pattern regulation","volume":"14","ISSN":"1742-5689","url":"http://dx.doi.org/10.1098/rsif.2017.0425","DOI":"10.1098/rsif.2017.0425","abstractNote":"Gene regulatory networks (GRNs) describe interactions between gene products and transcription factors that control gene expression. In combination with reaction-diffusion models, GRNs have enhanced comprehension of biological pattern formation. However, although it is well known that biological systems exploit an interplay of genetic and physical mechanisms, instructive factors such as transmembrane potential (Vmem) have not been integrated into full GRN models. Here we extend regulatory networks to include bioelectric signalling, developing a novel synthesis: the bioelectricity-integrated gene and reaction (BIGR) network. Using in silico simulations, we highlight the capacity for Vmem to alter steady-state concentrations of key signalling molecules inside and out of cells. We characterize fundamental feedbacks where Vmem both controls, and is in turn regulated by, biochemical signals and thereby demonstrate Vmem homeostatic control, Vmem memory and Vmem controlled state switching. BIGR networks demonstrating hysteresis are identified as a mechanisms through which more complex patterns of stable Vmem spots and stripes, along with correlated concentration patterns, can spontaneously emerge. As further proof of principle, we present and analyse a BIGR network model that mechanistically explains key aspects of the remarkable regenerative powers of creatures such as planarian flatworms. The functional properties of BIGR networks generate the first testable, quantitative hypotheses for biophysical mechanisms underlying the stability and adaptive regulation of anatomical bioelectric pattern.","number":"134","journal":"Journal of the Royal Society, Interface / the Royal Society","author":"Pietak, Alexis and Levin, Michael","year":"2017","month":"Sep","issn":"1742-5689","doi":"10.1098/rsif.2017.0425","abstractnote":"Gene regulatory networks (GRNs) describe interactions between gene products and transcription factors that control gene expression. In combination with reaction-diffusion models, GRNs have enhanced comprehension of biological pattern formation. However, although it is well known that biological systems exploit an interplay of genetic and physical mechanisms, instructive factors such as transmembrane potential (Vmem) have not been integrated into full GRN models. Here we extend regulatory networks to include bioelectric signalling, developing a novel synthesis: the bioelectricity-integrated gene and reaction (BIGR) network. Using in silico simulations, we highlight the capacity for Vmem to alter steady-state concentrations of key signalling molecules inside and out of cells. We characterize fundamental feedbacks where Vmem both controls, and is in turn regulated by, biochemical signals and thereby demonstrate Vmem homeostatic control, Vmem memory and Vmem controlled state switching. BIGR networks demonstrating hysteresis are identified as a mechanisms through which more complex patterns of stable Vmem spots and stripes, along with correlated concentration patterns, can spontaneously emerge. As further proof of principle, we present and analyse a BIGR network model that mechanistically explains key aspects of the remarkable regenerative powers of creatures such as planarian flatworms. The functional properties of BIGR networks generate the first testable, quantitative hypotheses for biophysical mechanisms underlying the stability and adaptive regulation of anatomical bioelectric pattern.","type":"article"}],["Portilla_Simoncelli_2000",{"title":"A parametric texture model based on joint statistics of complex wavelet coefficients","url":"https://www.cns.nyu.edu/pub/eero/portilla99-reprint.pdf","author":"Portilla, Javier and Simoncelli, Eero P.","year":"2000","type":"misc"}],["Randazzo_Mordvintsev_Niklasson_Levin_Greydanus_2020",{"title":"Self-classifying MNIST Digits","volume":"5","ISSN":"2476-0757","url":"https://distill.pub/2020/selforg/mnist","DOI":"10.23915/distill.00027.002","number":"8","journal":"Distill","author":"Randazzo, Ettore and Mordvintsev, Alexander and Niklasson, Eyvind and Levin, Michael and Greydanus, Sam","year":"2020","month":"Aug","issn":"2476-0757","doi":"10.23915/distill.00027.002","type":"article"}],["Raspopovic_Marcon_Russo_Sharpe_2014",{"title":"Modeling digits. Digit patterning is controlled by a Bmp-Sox9-Wnt Turing network modulated by morphogen gradients","volume":"345","ISSN":"0036-8075","url":"http://dx.doi.org/10.1126/science.1252960","DOI":"10.1126/science.1252960","abstractNote":"During limb development, digits emerge from the undifferentiated mesenchymal tissue that constitutes the limb bud. It has been proposed that this process is controlled by a self-organizing Turing mechanism, whereby diffusible molecules interact to produce a periodic pattern of digital and interdigital fates. However, the identities of the molecules remain unknown. By combining experiments and modeling, we reveal evidence that a Turing network implemented by Bmp, Sox9, and Wnt drives digit specification. We develop a realistic two-dimensional simulation of digit patterning and show that this network, when modulated by morphogen gradients, recapitulates the expression patterns of Sox9 in the wild type and in perturbation experiments. Our systems biology approach reveals how a combination of growth, morphogen gradients, and a self-organizing Turing network can achieve robust and reproducible pattern formation.","number":"6196","journal":"Science","author":"Raspopovic, J. and Marcon, L. and Russo, L. and Sharpe, J.","year":"2014","month":"Aug","pages":"566–570","issn":"0036-8075","doi":"10.1126/science.1252960","abstractnote":"During limb development, digits emerge from the undifferentiated mesenchymal tissue that constitutes the limb bud. It has been proposed that this process is controlled by a self-organizing Turing mechanism, whereby diffusible molecules interact to produce a periodic pattern of digital and interdigital fates. However, the identities of the molecules remain unknown. By combining experiments and modeling, we reveal evidence that a Turing network implemented by Bmp, Sox9, and Wnt drives digit specification. We develop a realistic two-dimensional simulation of digit patterning and show that this network, when modulated by morphogen gradients, recapitulates the expression patterns of Sox9 in the wild type and in perturbation experiments. Our systems biology approach reveals how a combination of growth, morphogen gradients, and a self-organizing Turing network can achieve robust and reproducible pattern formation.","type":"article"}],["Reynolds_2011",{"title":"Interactive evolution of camouflage","volume":"17","ISSN":"1064-5462","url":"http://dx.doi.org/10.1162/artl_a_00023","DOI":"10.1162/artl_a_00023","abstractNote":"This article presents an abstract computation model of the evolution of camouflage in nature. The 2D model uses evolved textures for prey, a background texture representing the environment, and a visual predator. A human observer, acting as the predator, is shown a cohort of 10 evolved textures overlaid on the background texture. The observer clicks on the five most conspicuous prey to remove (“eat”) them. These lower-fitness textures are removed from the population and replaced with newly bred textures. Biological morphogenesis is represented in this model by procedural texture synthesis. Nested expressions of generators and operators form a texture description language. Natural evolution is represented by genetic programming (GP), a variant of the genetic algorithm. GP searches the space of texture description programs for those that appear least conspicuous to the predator.","number":"2","journal":"Artificial life","author":"Reynolds, Craig","year":"2011","month":"Mar","pages":"123–136","issn":"1064-5462","doi":"10.1162/artl_a_00023","abstractnote":"This article presents an abstract computation model of the evolution of camouflage in nature. The 2D model uses evolved textures for prey, a background texture representing the environment, and a visual predator. A human observer, acting as the predator, is shown a cohort of 10 evolved textures overlaid on the background texture. The observer clicks on the five most conspicuous prey to remove (“eat”) them. These lower-fitness textures are removed from the population and replaced with newly bred textures. Biological morphogenesis is represented in this model by procedural texture synthesis. Nested expressions of generators and operators form a texture description language. Natural evolution is represented by genetic programming (GP), a variant of the genetic algorithm. GP searches the space of texture description programs for those that appear least conspicuous to the predator.","type":"article"}],["Risser_Wilmot_Barnes_2017",{"title":"Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses","url":"http://arxiv.org/abs/1701.08893","abstractNote":"Recently, methods have been proposed that perform texture synthesis and style transfer by using convolutional neural networks (e.g. Gatys et al. [2015,2016]). These methods are exciting because they can in some cases create results with state-of-the-art quality. However, in this paper, we show these methods also have limitations in texture quality, stability, requisite parameter tuning, and lack of user controls. This paper presents a multiscale synthesis pipeline based on convolutional neural networks that ameliorates these issues. We first give a mathematical explanation of the source of instabilities in many previous approaches. We then improve these instabilities by using histogram losses to synthesize textures that better statistically match the exemplar. We also show how to integrate localized style losses in our multiscale framework. These losses can improve the quality of large features, improve the separation of content and style, and offer artistic controls such as paint by numbers. We demonstrate that our approach offers improved quality, convergence in fewer iterations, and more stability over the optimization.","journal":"arXiv [cs.GR]","author":"Risser, Eric and Wilmot, Pierre and Barnes, Connelly","year":"2017","month":"Jan","abstractnote":"Recently, methods have been proposed that perform texture synthesis and style transfer by using convolutional neural networks (e.g. Gatys et al. [2015,2016]). These methods are exciting because they can in some cases create results with state-of-the-art quality. However, in this paper, we show these methods also have limitations in texture quality, stability, requisite parameter tuning, and lack of user controls. This paper presents a multiscale synthesis pipeline based on convolutional neural networks that ameliorates these issues. We first give a mathematical explanation of the source of instabilities in many previous approaches. We then improve these instabilities by using histogram losses to synthesize textures that better statistically match the exemplar. We also show how to integrate localized style losses in our multiscale framework. These losses can improve the quality of large features, improve the separation of content and style, and offer artistic controls such as paint by numbers. We demonstrate that our approach offers improved quality, convergence in fewer iterations, and more stability over the optimization.","type":"unpublished"}],["Sandler_Zhmoginov_Luo_Mordvintsev_Randazzo_Arcas_2020",{"title":"Image segmentation via Cellular Automata","url":"http://arxiv.org/abs/2008.04965","abstractNote":"In this paper, we propose a new approach for building cellular automata to solve real-world segmentation problems. We design and train a cellular automaton that can successfully segment high-resolution images. We consider a colony that densely inhabits the pixel grid, and all cells are governed by a randomized update that uses the current state, the color, and the state of the $3times 3$ neighborhood. The space of possible rules is defined by a small neural network. The update rule is applied repeatedly in parallel to a large random subset of cells and after convergence is used to produce segmentation masks that are then back-propagated to learn the optimal update rules using standard gradient descent methods. We demonstrate that such models can be learned efficiently with only limited trajectory length and that they show remarkable ability to organize the information to produce a globally consistent segmentation result, using only local information exchange. From a practical perspective, our approach allows us to build very efficient models -- our smallest automaton uses less than 10,000 parameters to solve complex segmentation tasks.","journal":"arXiv [cs.CV]","author":"Sandler, Mark and Zhmoginov, Andrey and Luo, Liangcheng and Mordvintsev, Alexander and Randazzo, Ettore and Arcas, Blaise Agúera y.","year":"2020","month":"Aug","abstractnote":"In this paper, we propose a new approach for building cellular automata to solve real-world segmentation problems. We design and train a cellular automaton that can successfully segment high-resolution images. We consider a colony that densely inhabits the pixel grid, and all cells are governed by a randomized update that uses the current state, the color, and the state of the $3times 3$ neighborhood. The space of possible rules is defined by a small neural network. The update rule is applied repeatedly in parallel to a large random subset of cells and after convergence is used to produce segmentation masks that are then back-propagated to learn the optimal update rules using standard gradient descent methods. We demonstrate that such models can be learned efficiently with only limited trajectory length and that they show remarkable ability to organize the information to produce a globally consistent segmentation result, using only local information exchange. From a practical perspective, our approach allows us to build very efficient models -- our smallest automaton uses less than 10,000 parameters to solve complex segmentation tasks.","type":"unpublished"}],["Schaerli_Munteanu_Gili_Cotterell_Sharpe_Isalan_2014",{"title":"A unified design space of synthetic stripe-forming networks","volume":"5","ISSN":"2041-1723","url":"http://dx.doi.org/10.1038/ncomms5905","DOI":"10.1038/ncomms5905","abstractNote":"Synthetic biology is a promising tool to study the function and properties of gene regulatory networks. Gene circuits with predefined behaviours have been successfully built and modelled, but largely on a case-by-case basis. Here we go beyond individual networks and explore both computationally and synthetically the design space of possible dynamical mechanisms for 3-node stripe-forming networks. First, we computationally test every possible 3-node network for stripe formation in a morphogen gradient. We discover four different dynamical mechanisms to form a stripe and identify the minimal network of each group. Next, with the help of newly established engineering criteria we build these four networks synthetically and show that they indeed operate with four fundamentally distinct mechanisms. Finally, this close match between theory and experiment allows us to infer and subsequently build a 2-node network that represents the archetype of the explored design space.","journal":"Nature communications","author":"Schaerli, Yolanda and Munteanu, Andreea and Gili, Magüi and Cotterell, James and Sharpe, James and Isalan, Mark","year":"2014","month":"Sep","pages":"4905","issn":"2041-1723","doi":"10.1038/ncomms5905","abstractnote":"Synthetic biology is a promising tool to study the function and properties of gene regulatory networks. Gene circuits with predefined behaviours have been successfully built and modelled, but largely on a case-by-case basis. Here we go beyond individual networks and explore both computationally and synthetically the design space of possible dynamical mechanisms for 3-node stripe-forming networks. First, we computationally test every possible 3-node network for stripe formation in a morphogen gradient. We discover four different dynamical mechanisms to form a stripe and identify the minimal network of each group. Next, with the help of newly established engineering criteria we build these four networks synthetically and show that they indeed operate with four fundamentally distinct mechanisms. Finally, this close match between theory and experiment allows us to infer and subsequently build a 2-node network that represents the archetype of the explored design space.","type":"article"}],["Schubert_Petrov_Carter_Cammarata_Goh_Olah_2020",{"title":"OpenAI Microscope","url":"https://openai.com/blog/microscope/","abstractNote":"We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability.","publisher":"OpenAI","author":"Schubert, Ludwig and Petrov, Michael and Carter, Shan and Cammarata, Nick and Goh, Gabriel and Olah, Chris","year":"2020","month":"Apr","abstractnote":"We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability.","type":"misc"}],["Simonyan_Zisserman_2014",{"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition","url":"http://arxiv.org/abs/1409.1556","abstractNote":"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","journal":"arXiv [cs.CV]","author":"Simonyan, Karen and Zisserman, Andrew","year":"2014","month":"Sep","abstractnote":"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","type":"unpublished"}],["Speman_1938",{"title":"Embryonic Development and Induction","volume":"196","url":"http://dx.doi.org/10.1097/00000441-193811000-00047","DOI":"10.1097/00000441-193811000-00047","number":"5","journal":"The American Journal of the Medical Sciences","author":"Speman, Hans","year":"1938","pages":"738","doi":"10.1097/00000441-193811000-00047","type":"article"}],["Turing_1990",{"title":"The chemical basis of morphogenesis. 1953","volume":"52","ISSN":"0092-8240","url":"http://dx.doi.org/10.1007/BF02459572","DOI":"10.1007/BF02459572","number":"1-2","journal":"Bulletin of mathematical biology","author":"Turing, A. M.","year":"1990","pages":"153–97; discussion 119–52","issn":"0092-8240","doi":"10.1007/BF02459572","type":"article"}],["Turing_1952",{"title":"The chemical basis of morphogenesis","volume":"237","ISSN":"0962-8436","url":"https://doi.org/10.1098/rstb.1952.0012","DOI":"10.1098/rstb.1952.0012","number":"641","journal":"Philosophical transactions of the Royal Society of London. Series B, Biological sciences","publisher":"Royal Society","author":"Turing, Alan Mathison","year":"1952","month":"Aug","pages":"37–72","issn":"0962-8436","doi":"10.1098/rstb.1952.0012","type":"article"}],["Ulyanov_Lebedev_Vedaldi_Lempitsky_2016",{"title":"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images","url":"http://arxiv.org/abs/1603.03417","abstractNote":"Gatys et al. recently demonstrated that deep networks can generate beautiful textures and stylized images from a single texture example. However, their methods requires a slow and memory-consuming optimization process. We propose here an alternative approach that moves the computational burden to a learning stage. Given a single example of a texture, our approach trains compact feed-forward convolutional networks to generate multiple samples of the same texture of arbitrary size and to transfer artistic style from a given image to any other image. The resulting networks are remarkably light-weight and can generate textures of quality comparable to Gatys~et~al., but hundreds of times faster. More generally, our approach highlights the power and flexibility of generative feed-forward models trained with complex and expressive loss functions.","journal":"arXiv [cs.CV]","author":"Ulyanov, Dmitry and Lebedev, Vadim and Vedaldi, Andrea and Lempitsky, Victor","year":"2016","month":"Mar","abstractnote":"Gatys et al. recently demonstrated that deep networks can generate beautiful textures and stylized images from a single texture example. However, their methods requires a slow and memory-consuming optimization process. We propose here an alternative approach that moves the computational burden to a learning stage. Given a single example of a texture, our approach trains compact feed-forward convolutional networks to generate multiple samples of the same texture of arbitrary size and to transfer artistic style from a given image to any other image. The resulting networks are remarkably light-weight and can generate textures of quality comparable to Gatys~et~al., but hundreds of times faster. More generally, our approach highlights the power and flexibility of generative feed-forward models trained with complex and expressive loss functions.","type":"unpublished"}],["Xian_Sangkloy_Agrawal_Raj_Lu_Fang_Yu_Hays_2018",{"title":"TextureGAN: Controlling deep image synthesis with texture patches","ISBN":"9781538664209","url":"https://openaccess.thecvf.com/content_cvpr_2018/papers/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.pdf","DOI":"10.1109/cvpr.2018.00882","booktitle":"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","publisher":"IEEE","author":"Xian, Wenqi and Sangkloy, Patsorn and Agrawal, Varun and Raj, Amit and Lu, Jingwan and Fang, Chen and Yu, Fisher and Hays, James","year":"2018","month":"Jun","isbn":"9781538664209","doi":"10.1109/cvpr.2018.00882","type":"inproceedings"}],["szegedy2015going",{"title":"Going deeper with convolutions","author":"Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew","booktitle":"Proceedings of the IEEE conference on computer vision and pattern recognition","pages":"1--9","year":"2015","url":"https://arxiv.org/pdf/1409.4842.pdf","type":"inproceedings"}],["Boettiger_Ermentrout_Oster_2009",{"title":"The neural origins of shell structure and pattern in aquatic mollusks","volume":"106","ISSN":"0027-8424","url":"http://dx.doi.org/10.1073/pnas.0810311106","DOI":"10.1073/pnas.0810311106","abstractNote":"We present a model to explain how the neurosecretory system of aquatic mollusks generates their diversity of shell structures and pigmentation patterns. The anatomical and physiological basis of this model sets it apart from other models used to explain shape and pattern. The model reproduces most known shell shapes and patterns and accurately predicts how the pattern alters in response to environmental disruption and subsequent repair. Finally, we connect the model to a larger class of neural models.","number":"16","journal":"Proceedings of the National Academy of Sciences of the United States of America","author":"Boettiger, Alistair and Ermentrout, Bard and Oster, George","year":"2009","month":"Apr","pages":"6837–6842","issn":"0027-8424","doi":"10.1073/pnas.0810311106","abstractnote":"We present a model to explain how the neurosecretory system of aquatic mollusks generates their diversity of shell structures and pigmentation patterns. The anatomical and physiological basis of this model sets it apart from other models used to explain shape and pattern. The model reproduces most known shell shapes and patterns and accurately predicts how the pattern alters in response to environmental disruption and subsequent repair. Finally, we connect the model to a larger class of neural models.","type":"article"}],["Boettiger_Oster_2009",{"title":"Emergent complexity in simple neural systems","volume":"2","ISSN":"1942-0889","url":"http://dx.doi.org/10.4161/cib.2.6.9260","DOI":"10.4161/cib.2.6.9260","abstractNote":"The ornate and diverse patterns of seashells testify to the complexity of living systems. Provocative computational explorations have shown that similarly complex patterns may arise from the collective interaction of a small number of rules. This suggests that, although a system may appear complex, it may still be understood in terms of simple principles. It is still debatable whether shell patterns emerge from some undiscovered simple principles, or are the consequence of an irreducibly complex interaction of many effects. Recent work by Boettiger, Ermentrout and Oster on the biological mechanisms of shell patterning has provided compelling evidence that, at least for this system, simplicity produces diversity and complexity.","number":"6","journal":"Communicative & integrative biology","author":"Boettiger, Alistair N. and Oster, George","year":"2009","month":"Nov","pages":"467–470","issn":"1942-0889","doi":"10.4161/cib.2.6.9260","abstractnote":"The ornate and diverse patterns of seashells testify to the complexity of living systems. Provocative computational explorations have shown that similarly complex patterns may arise from the collective interaction of a small number of rules. This suggests that, although a system may appear complex, it may still be understood in terms of simple principles. It is still debatable whether shell patterns emerge from some undiscovered simple principles, or are the consequence of an irreducibly complex interaction of many effects. Recent work by Boettiger, Ermentrout and Oster on the biological mechanisms of shell patterning has provided compelling evidence that, at least for this system, simplicity produces diversity and complexity.","type":"article"}]]</script></d-bibliography>

</d-appendix><distill-appendix>
<style>
  distill-appendix {
    contain: layout style;
  }

  distill-appendix .citation {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  distill-appendix > * {
    grid-column: text;
  }
</style>

    <h3 id="updates-and-corrections">Updates and Corrections</h3>
    <p>
    If you see mistakes or want to suggest changes, please <a href="https://github.com/distillpub/post--selforg-textures/issues/new">create an issue on GitHub</a>. </p>
    
    <h3 id="reuse">Reuse</h3>
    <p>Diagrams and text are licensed under Creative Commons Attribution <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a> with the <a class="github" href="https://github.com/distillpub/post--selforg-textures">source available on GitHub</a>,
 unless noted otherwise. The figures that have been reused from other 
sources don’t fall under this license and can be recognized by a note in
 their caption: “Figure from …”.</p>
    
    <h3 id="citation">Citation</h3>
    <p>For attribution in academic contexts, please cite this work as</p>
    <pre class="citation short">Niklasson, et al., "Self-Organising Textures", Distill, 2021.</pre>
    <p>BibTeX citation</p>
    <pre class="citation long">@article{niklasson2021self-organising,
  author = {Niklasson, Eyvind and Mordvintsev, Alexander and Randazzo, Ettore and Levin, Michael},
  title = {Self-Organising Textures},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/selforg/2021/textures},
  doi = {10.23915/distill.00027.003}
}</pre>
    </distill-appendix></d-appendix><distill-footer>
<style>

:host {
  color: rgba(255, 255, 255, 0.5);
  font-weight: 300;
  padding: 2rem 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  background-color: hsl(180, 5%, 15%); /*hsl(200, 60%, 15%);*/
  text-align: left;
  contain: content;
}

.footer-container .logo svg {
  width: 24px;
  position: relative;
  top: 4px;
  margin-right: 2px;
}

.footer-container .logo svg path {
  fill: none;
  stroke: rgba(255, 255, 255, 0.8);
  stroke-width: 3px;
}

.footer-container .logo {
  font-size: 17px;
  font-weight: 200;
  color: rgba(255, 255, 255, 0.8);
  text-decoration: none;
  margin-right: 6px;
}

.footer-container {
  grid-column: text;
}

.footer-container .nav {
  font-size: 0.9em;
  margin-top: 1.5em;
}

.footer-container .nav a {
  color: rgba(255, 255, 255, 0.8);
  margin-right: 6px;
  text-decoration: none;
}

</style>

<div class="footer-container">

  <a href="https://distill.pub/" class="logo">
    <svg viewBox="-607 419 64 64">
  <path d="M-573.4,478.9c-8,0-14.6-6.4-14.6-14.5s14.6-25.9,14.6-40.8c0,14.9,14.6,32.8,14.6,40.8S-565.4,478.9-573.4,478.9z"></path>
</svg>

    Distill
  </a> is dedicated to clear explanations of machine learning

  <div class="nav">
    <a href="https://distill.pub/about/">About</a>
    <a href="https://distill.pub/journal/">Submit</a>
    <a href="https://distill.pub/prize/">Prize</a>
    <a href="https://distill.pub/archive/">Archive</a>
    <a href="https://distill.pub/rss.xml">RSS</a>
    <a href="https://github.com/distillpub">GitHub</a>
    <a href="https://twitter.com/distillpub">Twitter</a>
    &nbsp;&nbsp;&nbsp;&nbsp; ISSN 2476-0757
  </div>

</div>

</distill-footer><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-83741880-1', 'auto');
  ga('send', 'pageview');
</script><div class="dg ac"><div class="dg main a" style="user-select: none; width: 245px; display: none;"><div style="width: 6px; margin-left: -3px; height: 0px; cursor: ew-resize; position: absolute;"></div><ul style="height: auto;"><li class="cr number has-slider"><div><span class="property-name">brushSize</span><div class="c"><div><input type="text" value="20"></div><div class="slider"><div class="slider-fg" style="width: 61.2903%;"></div></div></div></div></li><li class="cr number has-slider"><div><span class="property-name">zoom</span><div class="c"><div><input type="text" value="1"></div><div class="slider"><div class="slider-fg" style="width: 0%;"></div></div></div></div></li><li class="cr number has-slider"><div><span class="property-name">rotationAngle</span><div class="c"><div><input type="text" value="0"></div><div class="slider"><div class="slider-fg" style="width: 0%;"></div></div></div></div></li><li class="cr number"><div><span class="property-name">alignment</span><div class="c"><select><option value="0" selected="selected">cartesian</option><option value="1">polar</option><option value="2">bipolar</option></select></div></div></li><li class="cr boolean"><div><span class="property-name">hexGrid</span><div class="c"><input type="checkbox"></div></div></li></ul><div class="close-button close-bottom" style="width: 245px;">Close Controls</div></div></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>